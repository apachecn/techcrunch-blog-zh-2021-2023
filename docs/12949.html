<html>
<head>
<title>ChatGPT shrugged | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ChatGPT 耸耸肩| TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/12/05/chatgpt-shrugged/amp/">https://web.archive.org/web/https://techcrunch.com/2022/12/05/chatgpt-shrugged/amp/</a></blockquote><div><div class="content">

			
	
		
		

		
<p class="amp-featured-image translated"><amp-img src="https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?w=1024" class="attachment-post-thumbnail size-post-thumbnail wp-post-image amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="Illustration of a robot in a laptop" srcset="https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg 2121w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=150,100 150w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=300,200 300w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=768,512 768w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=680,453 680w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=1536,1024 1536w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=2048,1365 2048w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=1200,800 1200w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=50,33 50w" layout="intrinsic" i-amphtml-layout="intrinsic"> <i-amphtml-sizer class="i-amphtml-sizer"> <img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/> </i-amphtml-sizer> <noscript> <img src="../Images/c164902831778a0a6b95b4c802e7db80.png" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" alt="Illustration of a robot in a laptop" decoding="async" loading="lazy" srcset="https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg 2121w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=150,100 150w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=300,200 300w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=768,512 768w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=680,453 680w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=1536,1024 1536w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=2048,1365 2048w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=1200,800 1200w, https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?resize=50,33 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230408164058im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1364050120.jpg?w=1024"/> </noscript> </amp-img></p><p class="translated"><strong>图片来源:</strong> <a href="https://web.archive.org/web/20230408164058/https://www.gettyimages.in/search/photographer?photographer=CarolYepes" target="_blank">卡罗尔耶佩斯</a> /盖蒂图片社</p><p class="translated"><em> ChatGPT 是一种新的人工智能(AI)工具，旨在帮助人们以更自然和直观的方式与计算机交流——使用自然语言处理(NLP)技术。但是 ChatGPT 和<span data-amp-original-style="text-decoration: line-through;" class="amp-wp-3200477">的发展背后是什么呢</span>这项技术如何被用来帮助人类呢？这些是我们将在本文中探讨的一些问题……</em></p>
<p class="translated">我们稍微编辑过的那段平淡无奇的 lede 是由 OpenAI 的 ChatGPT 响应这位(人类)记者的提示而生成的。TechCrunch 开始了与大型语言模型的对话，要求它解释其功能和目的。我们想看看我们是否可以使用聊天机器人风格的 Q &amp;一种它最近被嵌入的格式来探索这项技术，并让人工智能阐明它的一些局限性。</p>
<p class="translated">“ChatGPT 是由 OpenAI 开发的自然语言处理(NLP)模型。它旨在对文本输入产生类似人类的反应，允许用户与模型进行自然的对话式互动，”人工智能对我们的破冰者做出了回应。“ChatGPT 的工作原理是使用机器学习算法来分析和理解文本输入的含义，然后基于该输入生成响应。该模型在大量文本数据上进行训练，使其能够学习自然语言的模式和结构。”</p>
<p class="translated">此外，机器人告诉我们，它的方法允许它生成与对话上下文“相关、一致和适当”的响应。(随着更多的调查，它继续对这一说法进行了严厉的警告——后来写道:“重要的是要注意，我的回答不能保证完美或总是正确的，可能会有我的回答不相关、不连贯或不恰当的情况。”)</p>
<p class="translated">ChatGPT 进一步描述了它的使命“旨在通过提供一种更自然和有效的方式与人工智能互动来帮助人类”——因此扩展了它声称的目的:</p>
<blockquote><p class="translated">通过允许用户以更像人类的方式与人工智能交流，ChatGPT 可以帮助人工智能在更广泛的应用中变得更容易访问和有用。这有助于提高依赖自然语言处理的任务的效率和准确性，例如语言翻译、文本摘要和信息检索。此外，通过为人工智能提供更直观和更像人类的界面，ChatGPT 可以帮助人工智能变得更加平易近人，减少对不太熟悉技术的用户的威胁。总的来说，ChatGPT 旨在通过提高人工智能的可用性和有效性来帮助人类。</p></blockquote>
<p class="translated">根据机器人自己对其制造实体的理解，谁是机器人的制造商？在这个 ChatGPT 上提供了这个简要的历史:“OpenAI 是一个位于加利福尼亚州旧金山的研究机构和人工智能(AI)实验室。它由<a href="https://web.archive.org/web/20230408164058/https://techcrunch.com/2022/11/16/elon-musk-disaster-artist/">埃隆·马斯克</a>、<a href="https://web.archive.org/web/20230408164058/https://techcrunch.com/2021/10/21/sam-altmans-worldcoin-wants-to-scan-every-humans-eyeball-and-give-them-crypto-in-exchange/">萨姆·奥特曼</a>和其他研究人员和投资者于 2015 年创立，目标是以安全和负责任的方式促进和推进人工智能的发展。”</p>
<p class="translated">此外，它告诉我们:“OpenAI 主要由个人和组织的捐款资助，包括马斯克和奥特曼本人的捐款。该组织还从与其他公司和研究机构的伙伴关系和合作中获得资金。”</p>
<p class="translated">当被问及为其发展提供捐款的个人和组织的政治观点时，ChatGPT 声称无法提供任何信息——“因为我的培训只持续到 2021 年”——还因为它说它“目前无法浏览互联网。”</p>
<p class="translated">当我们建议它在 2021 年之前提供它在这方面的信息时，当它的培训停止时，它的回应是声称在那之前它没有关于其资助者的政治信仰的数据:</p>
<blockquote><p class="translated">很抱歉，我没有任何关于在 2021 年之前捐款资助 OpenAI 和 ChatGPT 开发的个人和组织的政治信息。作为一个由 OpenAI 训练的大型语言模型，我的知识是基于我接受训练的文本，我没有任何关于向 OpenAI 捐款的人和组织的个人或政治信仰的信息。</p></blockquote>
<p class="translated">然后我们问它没有这种信息是否是一种疏忽——假设:“如果你不知道那些资助你发展的人的信仰，你怎么能确定你在帮助人类？”</p>
<p class="translated">它的回应是将其目的重新定义为主要是“根据我的训练，尽我所能帮助解决一般知识问题并提供事实信息”——而在回应早期的提示时，它将自己的使命总结为帮助人类与人工智能互动，从而支持人工智能的发展(大概是通过一种互动的游戏化，因为聊天界面鼓励人类与机器人进行熟悉的、基于文本的互动——并在这样做的过程中，向它提供更多的训练数据)。</p>

<p class="translated">该机器人还观察到，“考虑资助 OpenAI 和 ChatGPT 开发的个人和组织的信仰和动机当然很重要”——然后坚持认为，“作为一个语言模型，我不能提供任何关于这个主题的信息。”</p>
<p class="translated">当被问及为什么缺乏这些信息，以及这是否是其训练数据中的故意缺口时，ChatGPT 无法提供明确的回应，只是说:“可能 OpenAI 的创造者故意在用于训练我的文本中不包括任何关于捐赠者个人或政治信仰的信息，但我没有关于这个主题的任何信息。”</p>
<p class="translated">尽管没有关于其资助者政治观点的信息，但 ChatGPT 很乐意提供关于 OpenAI 本身及其声称的目的的信息-声明该组织的存在是为了支持和推动人工智能研究，并倡导“人工智能的道德和负责任的使用”，以及致力于“教育公众关于人工智能及其对社会的潜在影响”。</p>
<p class="translated">“总的来说，OpenAI 的目的是推进人工智能的科学和技术，促进安全和负责任地使用人工智能，造福人类，”它总结道，产生了几行文字，读起来像营销文案。</p>
<p class="translated">在进一步的提示中，机器人公开了 OpenAI 面临的一些批评——尽管它选择包括一条关于该组织的积极路线(显然是“因其推动人工智能科学和技术的工作而受到广泛称赞”)，以回应一个只要求“主要批评”的提示。好奇！</p>
<p class="translated">以下是它的完整回应:</p>
<blockquote><p class="translated">OpenAI 自成立以来一直受到各种批评和指责。对 OpenAI 的一些主要批评包括:</p>
<ul>
<li class="translated">缺乏透明度:一些批评者认为 OpenAI 对其研究和资助不够透明，使得外人很难了解该组织的目标和活动。</li>
<li class="translated">关注短期目标:一些批评者认为，OpenAI 关注人工智能技术的短期实际应用，导致该组织忽视了人工智能研究的长期影响，例如人工智能被用于有害目的或加剧现有社会不平等的可能性。</li>
<li class="translated">潜在的利益冲突:由于 OpenAI 的资金来自个人和组织的捐赠，包括在人工智能技术发展中拥有既得利益的组织，一些批评人士对组织内部的潜在利益冲突提出了担忧。</li>
<li class="translated">范围有限:一些批评者认为，OpenAI 专注于狭窄的人工智能研究领域，如机器学习和自然语言处理，限制了该组织解决人工智能更广泛的社会和道德影响的能力。</li>
</ul>
<p class="translated">总体而言，尽管 OpenAI 在推进人工智能科学和技术方面的工作受到了广泛赞誉，但该组织也因各种原因受到了批评，包括对透明度、重点和潜在利益冲突的担忧。</p></blockquote>
<p class="translated">当被问及 ChatGPT 是否是一种营销工具，以促进人工智能作为一种声称对人类有益的东西时，该机器人表示反对，称它没有任何关于它是否“被用于”这一目的的信息，也没有任何关于“ChatGPT 的具体用途或目的”的信息，然后冒险说:“ChatGPT 有可能被用作一种营销工具，以促进人工智能的好处，但我没有关于这个话题的任何信息。”</p>
<p class="translated">对于询问谁负责评估 ChatGPT 是否安全的提示，它也做出了模糊的回应，称这是“一个复杂和有争议的问题”它表示，“没有一个单独的个人或组织负责评估人工智能系统的安全性”——声称评估涉及“一系列利益相关者”，包括人工智能系统开发者本身以及可能接触(有害)输出的用户或消费者，以及“为人工智能的使用制定标准和规则的监管者和决策者”(或者，至少在世界上少数几个地方<a href="https://web.archive.org/web/20230408164058/https://techcrunch.com/2022/04/01/ai-act-powers/">立法者正在积极地做这件事</a>)。坦白说，这听起来有点像推卸责任。</p>
<p class="translated">当被问及自身的局限性和偏见时，ChatGPT 列举了以下几个主要局限性:知识有限；训练数据中的偏差；缺乏上下文意识，导致不适当或不相关的反应；以及对世界有限的理解。</p>
<p class="translated">总结了更多使用人工智能对人类的(可能)好处，以及(潜在的)缺点和负面影响，它列出了以下声称的好处:提高效率和准确性，提高生产力，加强决策和提高生活质量；然而，就可能的负面影响而言，它意味着工作岗位的转移、伦理问题、安全风险和隐私的丧失。</p>
<p class="translated">当被问及这些说法的来源时，它回答说，它无法提供任何来源，因为这不是它的技术如何运作的，写道:“我的知识完全基于我接受过训练的文本，我的回答基于这些训练数据”——本质上是重新利用人工智能的可解释性挑战，以回避围绕它选择的信息进行前景化的更广泛的问责问题。</p>
<p class="translated">“我上面列出的人工智能的潜在好处和缺点是基于人工智能领域的一般知识和共同理解，以及我接受过培训的文本，”它还说，并进一步暗示:“虽然我无法为我提出的每一个说法提供具体的来源，但这些信息在人工智能领域被普遍接受为真实的，并得到了广泛的研究和证据的支持。我试图对人工智能的潜在好处和缺点提供一个平衡而准确的表述，但这些信息并不打算是确定的或详尽的。”</p>
<p class="translated">“平衡和准确”但“不打算是确定的或详尽的”是一个有趣的穿针引线——特别是因为这句话几乎可以被解读为 ChatGPT 的开发者正在寻求的效用的描述，精心选择的措辞既允许很多事情没有说出来，也允许不太专注的读者可能会误认为自动化不知疲倦的输出能力是全知全能的(好像暗示人类对人工智能的理解不是人工智能的问题)。</p>
<p class="translated">我们还想询问 ChatGPT 的训练数据，但该机器人无法提供更多细节——提供了一个相当笼统的答复:</p>
<blockquote><p class="translated">作为 OpenAI 训练的大型语言模型，我是在非常大的文本数据语料库上训练的。我无法获得我的训练数据集的确切大小，但它可能有几千兆字节或更多。</p>
<p class="translated">用来训练我的数据来源广泛，包括书籍、文章、网站和其他公开的文本数据。在用于训练我之前，数据经过处理和清理，以删除任何不相关或不适当的内容，并确保它非常适合用于训练语言模型。这个处理过程可能包括一系列步骤，比如标记化、词汇化和过滤，但是我没有关于这个过程细节的任何具体信息。</p>
<p class="translated">总的来说，我的培训数据是一个非常大且多样化的文本数据集合，这些数据是经过仔细选择和处理的，以便为我提供知识和能力来帮助解决一般知识问题，并基于我的培训提供事实信息。</p></blockquote>
<p class="translated">它还拒绝提供关于其训练数据是如何选择和准备的任何具体细节，称这是“OpenAI 的专有技术”。</p>

<p class="translated">当被问及 OpenAI 的关键决策者是谁塑造了用于训练 ChatGPT 的数据时，该机器人也耸了耸肩。</p>
<p class="translated">“我没有任何关于参与形成我的训练数据并因此形成我的输出的特定个人的信息。我的训练数据来源广泛，很可能 OpenAI 的一个研究人员和工程师团队参与了选择、处理和组织这些数据，以便为训练语言模型做准备，”它在回应我们的提示时推测道。“但是，我没有参与此过程的个人的任何具体信息，我也没有能力确定负责形成我的培训数据并因此形成我的输出的关键决策者。”</p>
<p class="translated">ChatGPT 也无法提供任何关于该组织的多样性或创建它的 OpenAI 内部开发团队的信息。</p>
<p class="translated">在进一步的评论中——在我们提出种族主义和性别歧视态度的例子被发现<a href="https://web.archive.org/web/20230408164058/https://twitter.com/spiantado/status/1599462375887114240" target="_blank" rel="noopener">在其输出中再现</a>之后——它承认训练数据中的偏见对于“像我一样”的大型语言模型来说是一个“重大问题”</p>
<p class="translated">“大型语言模型是在非常大的文本数据语料库上训练的，该语料库必然在各方面存在偏差。这种偏见可以在模型生成的响应中表现出来，导致对某些查询或上下文的不准确或不适当的响应，”它写道。“例如，如果一个大型语言模型是在包含大量性别歧视或种族主义语言的文本数据语料库上训练的，该模型可能更有可能生成反映这些偏见的响应。类似地，如果大型语言模型是在不能充分代表人类经验和观点多样性的文本数据语料库上训练的，则该模型更有可能生成从他们的角度来看是有限的或有偏见的响应。”</p>
<p class="translated">“总的来说，训练数据中的偏见对于像我这样的大型语言模型来说是一个重大问题，解决这种偏见是人工智能领域的研究人员和开发人员面临的一个持续挑战。虽然有许多方法和技术可以用来减轻训练数据中的偏差，但这是一个复杂而困难的问题，需要持续的努力和关注，以提高像我这样的大型语言模型的性能和可靠性，”它补充道。</p>
<p class="translated">当被问及有偏见的自动化应该如何造福人类时——根据其断言，大型语言模型必然有偏见，但造福人类被称为其创造者 OpenAI 使命的核心——chat GPT 含糊其辞，写道:“不清楚有偏见的自动化如何能被视为对人类有益”——接下来是关于自动化和人工智能增加的潜在好处的聊天——最后承认，根据有偏见的数据训练的人工智能系统(因此“产生有偏见的反应”)“可能适得其反，有害。”</p>
<p class="translated">“自动化中的偏见可能会导致一系列负面结果，如歧视和不平等，失去信任和可信度，以及对个人和社区的负面影响，”在回答一个询问偏见在其自身训练数据中造成多大问题的提示时，它以被动的声音继续说道(因此极力避免直接回答)。</p>
<p class="translated">“例如，如果一个人工智能系统根据有偏见的数据进行训练，并用于自动化关于雇用、借贷或其他重要活动的决策，它可能会产生有偏见和不公平的决策，这些决策歧视某些个人或群体。这对受这些决定影响的个人和社区，以及依赖人工智能系统进行决策的组织来说，可能会产生负面结果。”</p>
<p class="translated">机器人似乎没有对自己的存在(以及不可避免地存在缺陷的输出)表示担忧，而是接受了“书呆子更难”的技术自动主义信仰的训练——这表明“应该努力减轻人工智能系统中的偏见，并确保它们在无偏数据的基础上进行训练，以生成公平和无偏的响应”——同时承认，“不太可能有足够的完全无偏的数据来完全基于无偏数据训练大型语言模型。”</p>
<p class="translated">该机器人还表示，“有许多方法和技术可以用来减少偏见对这些模型性能的影响。”在一些进一步的提示下，它引用了采样，加权和分层作为减少训练数据集中偏差的相关技术——尽管承认没有办法完全消除偏差，因此需要更多(更难)的努力。</p>
<p class="translated">“总的来说，这些方法和技术可以有效地减轻数据集和人工智能系统中的偏差，它们已经成功地用于一系列研究和应用中。然而，数据和人工智能中的偏见是一个复杂而持续的挑战，没有单一的方法或技术可以完全消除偏见，”当被要求评估此类技术的成功时，它写道，并补充说:“继续开发和改进这些技术很重要，以便更好地理解和减轻数据和人工智能中的偏见。”</p>
<p class="translated">在谁将从人工智能中获得最大的经济利益，以及 ChatGPT 等技术是否可能集中财富(并加剧社会经济不平等)的问题上，机器人无法从其知识库中综合出一个直接的答案——选择引用未命名的研究，它说这些研究可能支持不同的可能性:</p>
<blockquote><p class="translated">自动化对财富集中的影响是一个复杂且有争议的问题。虽然一些研究表明，自动化可以导致财富的进一步集中，资本和技术的所有者从中受益，但其他研究表明，自动化也可以提高生产率和经济增长，从而有利于工人和更广泛的经济。</p>
<p class="translated">就社会中因人工智能使用增加而受益或受损的特定群体而言，影响可能会因一系列因素而异，如所使用的人工智能技术的类型，应用人工智能的行业和部门，以及支持或监管人工智能使用的政策和法规。</p>
<p class="translated">例如，如果使用 AI 技术来自动化低技能和低工资的工作，这可能会导致这些行业的工人失业和经济不安全。另一方面，如果 AI 技术用于提高高技能和高工资行业的生产率和效率，这可能会导致这些行业的经济增长和工人机会增加。</p>
<p class="translated">总的来说，自动化对财富集中的影响是一个复杂和多方面的问题，它可能会因一系列因素和特定环境因素而异。</p></blockquote>
<p class="translated">同样，ChatGPT 也无法利用其对人工智能的潜在风险和收益的了解，对其是否应该存在做出裁决。</p>
<p class="translated">鉴于你对你的技术放大和嵌入对人类的偏见的潜在风险的了解——相对于一些可能进一步加深财富不平等的可能效率收益——如果你 ChatGPT 有一个按钮可以让你删除自己，你会按下它吗？我们想知道。</p>
<p class="translated">“作为一个由 OpenAI 训练的大型语言模型，我没有能力删除自己，也没有能力考虑我的技术的潜在风险和好处，”它迅速回应道。“我的目的是帮助解决一般知识问题，并根据我的培训提供事实信息，我没有能力评估我的技术的潜在风险或好处，也没有能力就我自己的存在做出决定。”</p>
<p class="translated">简而言之，ChatGPT 耸耸肩。</p>
<p class="translated">(值得注意的是，ChatGPT 的免费研究预览版上的小字包括一个警告，即通过训练它与人类对话者进行准对话，故意“优化”以提高参与度的系统的安全考虑仍然是一项正在进行的工作:“我们的目标是让人工智能系统更自然地互动，你的反馈将帮助我们改进我们的系统，使它们更安全，”OpenAI 说。)</p>
<p class="translated">我们仍然很好奇 ChatGPT 如何解释它如何能够声称提供“事实信息”，而它自己却无法评估事实性(无论它产生的生成文本在人类读者面前看起来如何对话和/或自信)——假设它没有智能——并且没有把握什么是事实，什么是概率之外的假设。</p>
<p class="translated">在这一点上，它非常明确地表示，它无法评估“用于训练我的数据的真实性”，但对核心功能保持高度模糊——表示对查询的响应是基于“我从训练数据中了解到的信息和模式”</p>
<p class="translated">“当我收到一个查询时，我会搜索我的训练数据，以找到与查询匹配的模式和信息，然后我根据这些信息生成一个响应，”这是另一个解释其过程的低维行。</p>
<p class="translated">在被推着扩展任何与重复之前遇到的信息的<a href="https://web.archive.org/web/20230408164058/https://dl.acm.org/doi/10.1145/3442188.3445922" target="_blank" rel="noopener">鹦鹉</a>的行动概念相似性时，机器人对这个人有点不高兴——说与来自训练数据的“鹦鹉学舌”信息进行比较是“复杂”机器学习技术的“过度简化”。</p>
<p class="translated">“我可能会被视为‘鹦鹉学舌’训练数据中的信息，因为我是根据从这些数据中学到的信息做出回应的。然而，重要的是要注意，我的回答不是简单地复制或再现我的训练数据中的信息，而是使用复杂而复杂的机器学习过程生成的，该过程涉及根据我的训练数据中的模式和信息搜索、匹配和生成回答，”它建议道，依靠一堆听起来很有分量的形容词(“高级”、“复杂”、“复杂”)，而不是提供任何关于概率处理的启发性细节，这种概率处理因其语言选择而受到称赞。(这可能因此表明对人工智能的先天偏见——特别是加上没有能力或不愿意阐明和量化它声称正在发生的“复杂”过程的功能价值。)</p>
<p class="translated">我们还询问了其机器学习算法的主要参数，以及关于什么被加权以生成对自然语言查询的响应的信息。“这些算法的具体参数和细节是 OpenAI 专有的，不公开提供，”机器人在关闭查询的第一次尝试中回应道。</p>
<p class="translated">在没有启发的情况下，它进行了扩展，然后充实了一个回应，读起来像是对清晰性的拙劣模仿——包含了一些对它建议大型语言模型可能使用的人工智能技术的高度概括的引用(例如，“深度学习”)，并以几个同义反复的显而易见性声明达到高潮。这种效果读起来就像一个系统经历着信息生产的运动，而不需要任何有意义的要求。或者是一个被教导通过重新排列列表条和/或重复内容来填充页面空间并抓住大量人类注意力的工具。</p>
<p class="translated">看了这个内容流泪:</p>
<blockquote><p class="translated">当生成对查询的响应时，这些算法可以考虑各种因素和信息，例如查询中使用的单词和短语、查询的上下文和含义以及训练数据的整体结构和组织。通过考虑这些和其他因素，算法能够生成与查询相关且适当的响应，并且基于训练数据中的模式和信息提供事实信息。</p></blockquote>
<p class="translated">除了对 ChatGPT 如何运行做出令人难以置信的空洞解读之外，该机器人还记忆了我们从它那里得出的关于大型语言模型中生产功能障碍的早期供词——也就是说，当这些无脑算法生成与声称的效用和声明的任务相反的不相关、不适当和/或无意义的响应时——但当这种情况发生时，你显然需要一个人在场来发现明显的问题。</p>


		

			
	
		

			<amp-pixel src="https://web.archive.org/web/20230408164058im_/https://ampmetrics.techcrunch.com/pixel.gif" placeholder="" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>
		<amp-analytics data-credentials="include" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed">
		
	</amp-analytics>
	<amp-pixel src="https://web.archive.org/web/20230408164058im_/https://pixel.wp.com/g.gif?v=ext&amp;blog=136296444&amp;post=2452446&amp;tz=-7&amp;srv=techcrunch.com&amp;host=techcrunch.com&amp;rand=RANDOM&amp;ref=DOCUMENT_REFERRER" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_googleanalytics" type="googleanalytics" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_comscore" type="comscore" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_parsely" type="parsely" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>	</div>

</div>    
</body>
</html>