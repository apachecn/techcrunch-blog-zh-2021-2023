<html>
<head>
<title>VALL-E's quickie voice deepfakes should worry you, if you weren't worried already | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">VALL-E 的快速声音 deepfakes 应该让你担心，如果你还不担心的话</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/01/12/vall-es-quickie-voice-deepfakes-should-worry-you-if-you-werent-worried-already/">https://web.archive.org/web/https://techcrunch.com/2023/01/12/vall-es-quickie-voice-deepfakes-should-worry-you-if-you-werent-worried-already/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">上周出现了一种特别有效的语音合成机器学习模型，名为 VALL-E，这引发了新一轮的关注，即快速而简单地制造深度假语音的可能性——如果你愿意，可以说是快速假语音。但是 VALL-E 更多的是迭代而不是突破，而且功能也没有你想象的那么新。这是否意味着你应该或多或少的担心取决于你自己。</p>
<p class="translated">语音复制多年来一直是一个激烈研究的主题，其结果足以推动许多初创公司，如<a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/2020/09/22/wellsaid-labs-research-takes-synthetic-speech-from-seconds-long-clips-to-hours/"> WellSaid </a>、<a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/2022/06/09/papercup-raises-20m-for-ai-that-automatically-dubs-videos/"> Papercup </a>和 Respeecher。后者甚至被用于制作演员<a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/2022/09/26/ai-is-taking-over-the-iconic-voice-of-darth-vader-with-the-blessing-of-james-earl-jones/">如詹姆斯·厄尔·琼斯</a>的授权配音。是的:从现在开始，达斯·维德将由人工智能生成。</p>
<p class="translated">VALL-E，<a href="https://web.archive.org/web/20230403132723/https://valle-demo.github.io/" target="_blank" rel="noopener">上周由微软的创造者发布在 GitHub </a>上，它是一个“神经编解码器语言模型”,使用了一种不同于以前的方法来渲染声音。它更大的训练语料库和一些新方法使它能够使用来自目标说话者的三秒钟的音频来创建“高质量的个性化语音”。</p>
<p class="translated">也就是说，你需要的只是一个像下面这样的极短的剪辑(全部剪辑自微软的论文):</p>
<p class="translated"><audio class="wp-audio-shortcode" id="audio-2467777-6" preload="none" controls="controls"><source type="audio/wav" src="https://web.archive.org/web/20230403132723im_/https://techcrunch.com/wp-content/uploads/2023/01/in1.wav?_=6"/><a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/wp-content/uploads/2023/01/in1.wav">https://techcrunch.com/wp-content/uploads/2023/01/in1.wav</a></audio></p>
<p class="translated"><audio class="wp-audio-shortcode" id="audio-2467777-7" preload="none" controls="controls"><source type="audio/wav" src="https://web.archive.org/web/20230403132723im_/https://techcrunch.com/wp-content/uploads/2023/01/in2.wav?_=7"/><a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/wp-content/uploads/2023/01/in2.wav">https://techcrunch.com/wp-content/uploads/2023/01/in2.wav</a></audio></p>
<p class="translated">产生听起来非常相似的合成声音:</p>
<p class="translated"><audio class="wp-audio-shortcode" id="audio-2467777-8" preload="none" controls="controls"> <source type="audio/wav" src="https://web.archive.org/web/20230403132723im_/https://techcrunch.com/wp-content/uploads/2023/01/outcome1.wav?_=8"/> <a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/wp-content/uploads/2023/01/outcome1.wav"/></audio></p>
<p class="translated"><audio class="wp-audio-shortcode" id="audio-2467777-9" preload="none" controls="controls"><source type="audio/wav" src="https://web.archive.org/web/20230403132723im_/https://techcrunch.com/wp-content/uploads/2023/01/outcome2.wav?_=9"/><a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/wp-content/uploads/2023/01/outcome2.wav">https://tech crunch . com/WP-content/uploads/2023/01/outcome 2 . wav</a></audio></p>
<p class="translated">正如你所听到的，它保持了音调、音色、口音甚至“听觉环境”(例如，压缩成手机通话的声音)。我懒得给它们贴标签，因为你很容易分辨出上面哪个是哪个。这是相当令人印象深刻的！</p>
<p class="translated">事实上，令人印象深刻的是，这种特殊的模式似乎已经穿透了研究团体的伪装，并“成为主流”。昨晚，当我在当地一家酒吧喝酒时，酒吧招待着重描述了语音合成的新人工智能威胁。这就是为什么我知道我误判了时代精神。</p>
<p class="translated">但是如果你稍微回顾一下，早在 2017 年<a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/2017/04/25/lyrebird-is-a-voice-mimic-for-the-fake-news-era/">你所需要的只是一分钟的声音</a>来制作一个足够令人信服的假版本，以至于它会被随意使用。这远不是唯一的项目。</p>

<p class="translated">我们在诸如 DALL-E 2 和 Stable Diffusion 之类的图像生成模型中，或者在诸如 ChatGPT 之类的语言模型中看到的改进，是一个变革性的、质的改进:一两年前，这种详细的、令人信服的人工智能生成内容是不可能的。围绕这些模型的担忧(和恐慌)是可以理解的，也是有道理的。</p>
<p class="translated">相反，VALL-E 提供的改进是<em>定量的</em>而非定性的。对激增的假语音内容感兴趣的坏演员可能在很久以前就已经这样做了，只是计算成本更高，这在现在并不是特别难找到。尤其是国家资助的演员，手头会有大量的资源来做必要的计算工作，比如，制作一个总统在热麦克风上说一些有损健康的话的假音频剪辑。</p>
<p class="translated">我和詹姆斯·贝特克聊了聊，他是一名工程师，曾在另一个名为“乌龟-TTS”的文本语音转换系统<a href="https://web.archive.org/web/20230403132723/https://github.com/neonbjb/tortoise-tts" target="_blank" rel="noopener"/>上工作过一段时间。</p>
<p class="translated">Betker 说，VALL E 确实是迭代的，像其他流行的模型一样，现在它的力量来自它的大小。</p>

<p class="translated">“这是一个大模型，像 ChatGPT 或稳定扩散；它对人类如何形成语言有一些固有的理解。然后，你可以在特定的扬声器上微调乌龟和其他模型，这使得它们非常非常好。不是“听起来有点像”；<em>好的</em>，”他解释道。</p>
<p class="translated">当你“微调”特定艺术家作品的稳定扩散时，你并没有重新训练整个庞大的模型(这需要更多的能量)，但你仍然可以极大地提高其复制内容的能力。</p>
<p class="translated">但是仅仅因为它是熟悉的，并不意味着它应该被驳回，Betker 澄清说。</p>
<p class="translated">“我很高兴它得到了一些关注，因为我真的希望人们谈论这件事。实际上，我觉得言论是神圣的，这是我们的文化所认为的，”由于这些担忧，他实际上停止了他自己的模型的工作。DALL-E 2 创造的一个假 Dali 对人们来说，并不像听到自己的声音一样具有发自内心的效果，那是一个心爱的人或崇拜的人的声音。</p>
<p class="translated">贝特克推测，VALL-E 让我们离无处不在又近了一步，尽管它不是你在手机或家用电脑上运行的那种模型，但也不会太远。几年，也许，自己经营类似的东西；举个例子，他发了这个他在自己的电脑上用塞缪尔·L·杰克逊的 Tortoise-TTS 根据他的有声读物制作的剪辑:</p>
<p class="translated">【T2<source type="audio/mpeg" src="https://web.archive.org/web/20230403132723im_/https://techcrunch.com/wp-content/uploads/2023/01/samuel_jackson.mp3?_=10"/><a href="https://web.archive.org/web/20230403132723/https://techcrunch.com/wp-content/uploads/2023/01/samuel_jackson.mp3">https://TechCrunch . com/WP-content/uploads/2023/01/Samuel _ Jackson . MP3</a></p>
<p class="translated">很好，对吧？几年前，你可能能够完成类似的事情，尽管需要付出更大的努力。</p>
<p class="translated">这只是说，虽然 VALL-E 和三秒钟的快速造假绝对值得注意，但它们只是研究人员已经走了十多年的漫长道路上的一小步。</p>
<p class="translated">这种威胁已经存在很多年了，如果有人想要复制你的声音，他们很久以前就可以这么做了。这并没有让它变得更令人不安，而且被它吓到也没什么不对。我也是！</p>
<p class="translated">但是对恶意行为者的好处是可疑的。例如，基于一个错误的电话号码使用一个尚可的快速伪造的小骗局已经非常容易，因为许多公司的安全措施已经很松懈了。身份盗窃不需要依靠声音复制，因为有太多更容易的途径来赚钱和访问。</p>
<p class="translated">与此同时，好处可能是巨大的——想想那些因疾病或事故而失去说话能力的人。这些事情发生得太快了，以至于他们没有时间记录一个小时的演讲来训练一个模型(这种能力并不是广泛可用的，尽管几年前就可以实现)。但是有了像 all 这样的东西，你只需要从某人的手机上截取一些他们在晚餐时祝酒或与朋友交谈的片段。</p>
<p class="translated">诈骗和冒名顶替的机会总是存在的——尽管越来越多的人通过更加平淡无奇的方式放弃了他们的金钱和身份，比如简单的电话或网络钓鱼诈骗。这项技术的潜力是巨大的，但我们也应该听从我们的集体直觉，说这里有危险的东西。只是不要惊慌——暂时不要。</p>
			</div>

			</div>    
</body>
</html>