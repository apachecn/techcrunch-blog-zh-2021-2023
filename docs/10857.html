<html>
<head>
<title>Google answers Meta's video-generating AI with its own, dubbed Imagen Video | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌用自己的名为 Imagen Video | TechCrunch 的人工智能回答了 Meta 的视频生成问题</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/10/05/google-answers-metas-video-generating-ai-with-its-own-dubbed-imagen-video/amp/">https://web.archive.org/web/https://techcrunch.com/2022/10/05/google-answers-metas-video-generating-ai-with-its-own-dubbed-imagen-video/amp/</a></blockquote><div><div class="content">

			
	
		
		

		
<p class="amp-featured-image translated"><amp-img src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?w=1024" class="attachment-post-thumbnail size-post-thumbnail wp-post-image amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="Google logo sign with white backlighting on dark background" srcset="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg 4500w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=150,84 150w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=300,169 300w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=768,432 768w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=680,382 680w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=1536,864 1536w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=2048,1152 2048w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=1200,675 1200w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=50,28 50w" layout="intrinsic" i-amphtml-layout="intrinsic"> <i-amphtml-sizer class="i-amphtml-sizer"> <img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/> </i-amphtml-sizer> <noscript> <img src="../Images/8df119f9d4419382a8c738ecdbb78320.png" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" alt="Google logo sign with white backlighting on dark background" decoding="async" loading="lazy" srcset="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg 4500w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=150,84 150w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=300,169 300w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=768,432 768w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=680,382 680w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=1536,864 1536w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=2048,1152 2048w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=1200,675 1200w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-1230444599-1-e1660816546129.jpg?w=1024"/> </noscript> </amp-img></p><p class="translated"><strong>图片来源:</strong>Artur Widak/Nur photo/Getty Images</p><p class="translated">不甘落后于 Meta 的视频制作，谷歌今天详细介绍了其在<a href="https://web.archive.org/web/20230311084019/https://imagen.research.google/" target="_blank" rel="noopener"> Imagen Video、</a>一个人工智能系统上的工作，该系统可以根据文本提示生成视频剪辑(例如，“一只泰迪熊在洗碗”)。虽然结果并不完美——系统生成的循环片段往往会有伪像和噪声——但谷歌声称，Imagen Video 是向具有“高度可控性”和世界知识的系统迈出的一步，包括生成一系列艺术风格的镜头的能力。</p>
<p class="translated">正如我的同事 Devin Coldewey 在他关于制作视频的<a href="https://web.archive.org/web/20230311084019/https://techcrunch.com/2022/09/29/meta-make-a-video-ai-achieves-a-new-creepy-state-of-the-art/">文章</a>中提到的，文本到视频系统并不新鲜。今年早些时候，来自清华大学和北京人工智能研究院的一组研究人员发布了 CogVideo，它可以将文本翻译成相当高保真的短片。但 Imagen Video 似乎是对之前最先进技术的重大飞跃，显示了现有系统难以理解的动画字幕能力。</p>
<p class="translated">“这绝对是一个进步，”艾伯塔大学研究人工智能和机器学习的助理教授马修·古兹戴尔(Matthew Guzdial)通过电子邮件告诉 TechCrunch。“正如您从视频示例中看到的那样，尽管通信团队选择了最佳输出，但仍然存在奇怪的模糊和假像。所以这肯定不会很快被直接用在动画或电视上。但它或类似的东西肯定可以嵌入到工具中，帮助加快一些事情的速度。”</p>
<p/><div id="attachment_2419538" class="wp-caption aligncenter amp-wp-82d21b4" data-amp-original-style="width: 410px"><amp-anim aria-describedby="caption-attachment-2419538" class="size-full wp-image-2419538 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/52.gif" alt="Google Imagen Video" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2419538" decoding="async" loading="lazy" class="size-full wp-image-2419538" src="../Images/8f4aef37e6623b62ef4e699d43f43cf1.png" alt="Google Imagen Video" data-original-src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/52.gif"/></noscript></amp-anim><p id="caption-attachment-2419538" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div>
<p/><div id="attachment_2419543" class="wp-caption aligncenter amp-wp-82d21b4" data-amp-original-style="width: 410px"><amp-anim aria-describedby="caption-attachment-2419543" class="size-full wp-image-2419543 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/31.gif" alt="Google Imagen Video" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2419543" decoding="async" loading="lazy" class="size-full wp-image-2419543" src="../Images/e8616b2989cb7d5cbb311e9a9962e789.png" alt="Google Imagen Video" data-original-src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/31.gif"/></noscript></amp-anim><p id="caption-attachment-2419543" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div>
<p class="translated">Imagen Video 建立在谷歌的<a href="https://web.archive.org/web/20230311084019/https://techcrunch.com/2022/05/23/openai-look-at-our-awesome-image-generator-google-hold-my-shiba-inu/"> Imagen </a>之上，这是一个可与 OpenAI 的<a href="https://web.archive.org/web/20230311084019/https://techcrunch.com/2022/07/20/openai-expands-access-to-dall-e-2-its-powerful-image-generating-ai-system/"> DALL-E 2 </a>和<a href="https://web.archive.org/web/20230311084019/https://techcrunch.com/tag/stable-diffusion/">稳定扩散</a>相媲美的图像生成系统。Imagen 是一种“扩散”模型，通过学习如何“破坏”和“恢复”许多现有的数据样本来生成新数据(如视频)。由于它提供了现有的样本，该模型在恢复之前被破坏的数据以创建新作品方面变得更好。</p>
<p/><div id="attachment_2419548" class="wp-caption aligncenter amp-wp-82d21b4" data-amp-original-style="width: 410px"><amp-anim aria-describedby="caption-attachment-2419548" class="size-full wp-image-2419548 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/39.gif" alt="Google Imagen Video" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2419548" decoding="async" loading="lazy" class="size-full wp-image-2419548" src="../Images/ed18e14c42ae91a3f735b7d5c5190df6.png" alt="Google Imagen Video" data-original-src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/39.gif"/></noscript></amp-anim><p id="caption-attachment-2419548" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div>
<p class="translated">正如 Imagen Video 背后的谷歌研究团队在<a href="https://web.archive.org/web/20230311084019/https://imagen.research.google/video/paper.pdf" target="_blank" rel="noopener">论文</a>中解释的那样，该系统采用文本描述，并以 24x 48 像素的分辨率生成 16 帧、每秒 3 帧的视频。然后，系统升级并“预测”额外的帧，以 720p (1280×768)产生最终的 128 帧、每秒 24 帧的视频。</p>
<p/><div id="attachment_2419542" class="wp-caption aligncenter amp-wp-82d21b4" data-amp-original-style="width: 410px"><amp-anim aria-describedby="caption-attachment-2419542" class="size-full wp-image-2419542 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/fairytale-2.gif" alt="Google Imagen Video" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2419542" decoding="async" loading="lazy" class="size-full wp-image-2419542" src="../Images/a214208ddcfe3fbb2edd37c96157ce8b.png" alt="Google Imagen Video" data-original-src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/fairytale-2.gif"/></noscript></amp-anim><p id="caption-attachment-2419542" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div>
<p/><div id="attachment_2419545" class="wp-caption aligncenter amp-wp-82d21b4" data-amp-original-style="width: 410px"><amp-anim aria-describedby="caption-attachment-2419545" class="size-full wp-image-2419545 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/16.gif" alt="Google Imagen Video" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2419545" decoding="async" loading="lazy" class="size-full wp-image-2419545" src="../Images/674f716a43f394166132546e542566b4.png" alt="Google Imagen Video" data-original-src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/16.gif"/></noscript></amp-anim><p id="caption-attachment-2419545" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div>
<p class="translated">谷歌表示，Imagen Video 在 1400 万个视频-文本对和 6000 万个图像-文本对以及公开可用的 LAION-400M 图像-文本数据集上进行了训练，这使它能够概括一系列美学。(并非巧合的是，一部分介子被用来训练稳定扩散。)在实验中，他们发现 Imagen Video 可以创建梵高画作和水彩风格的视频。或许更令人印象深刻的是，他们声称 Imagen Video 展示了对深度和三维的理解，使其能够创建像无人机飞越一样的视频，这些视频可以从不同角度旋转并捕捉物体，而不会扭曲它们。</p>
<p class="translated">Imagen Video 对目前可用的图像生成系统进行了重大改进，它还可以正确呈现文本。虽然 Stable Diffusion 和 DALL-E 2 都很难将类似“Diffusion 的标志”这样的提示转换为可读类型，但 Imagen Video 可以毫无问题地呈现它——至少从论文来看是这样的。</p>
<p class="translated">这并不是说 Imagen Video 没有局限性。就像制作视频一样，即使是从 Imagen Video 中截取的剪辑也会有些抖动和失真，正如 Guzdial 暗示的那样，这些对象以物理上不自然的方式混合在一起。</p>
<p class="translated">“总的来说，文本到视频的问题仍然没有解决，我们不太可能很快达到像 DALL-E 2 或<a href="https://web.archive.org/web/20230311084019/https://techcrunch.com/2022/08/02/ai-art-generated/">midway</a>那样的质量，”Guzdial 继续说道。</p>
<p class="translated">为了改进这一点，Imagen 视频团队计划<a href="https://web.archive.org/web/20230311084019/https://twitter.com/hojonathanho/status/1577713864812236817" target="_blank" rel="noopener">联合</a>与<a href="https://web.archive.org/web/20230311084019/https://phenaki.github.io/" target="_blank" rel="noopener"> Phenaki </a>背后的研究人员，Phenaki 是今天推出的另一个谷歌文本到视频系统，可以将长时间的详细提示转换成超过两分钟的视频——尽管质量较低。</p>
<p class="translated">有必要揭开 Phenaki 的面纱，看看这两个团队之间的合作可能会带来什么。Imagen Video 注重质量，而 Phenaki 则注重连贯性和长度。该系统可以将大段的提示转换成任意长度的电影，从一个人骑摩托车的场景到外星人飞船飞过未来城市的场景。Phenaki 生成的剪辑与 Imagen Video 的剪辑有着相同的缺陷，但令我惊讶的是，它们如此紧密地遵循了提示它们的冗长而微妙的文本描述。</p>
<p class="translated">例如，这里有一个给 Phenaki 的提示:</p>
<blockquote><p class="translated">未来城市的交通繁忙。一艘外星飞船抵达未来城市。摄像机进入了外星飞船。镜头向前移动，直到显示一名宇航员在蓝色房间里。宇航员正在键盘上打字。镜头从宇航员身上移开。宇航员离开键盘，走到左边。宇航员离开键盘，走开了。镜头移过宇航员，看着屏幕。宇航员身后的屏幕显示鱼在海里游泳。放大蓝色的鱼。当蓝色的鱼在黑暗的海洋中游泳时，我们跟着它。镜头透过水面指向天空。未来城市的海洋和海岸线。急速冲向未来的摩天大楼。摄像机会放大许多窗口中的一个。我们在一间空桌子的办公室里。一只狮子在办公桌上奔跑。镜头拉近办公室里狮子的脸。放大到办公室里穿着深色西装的狮子。穿着的狮子看着镜头笑了。镜头慢慢缩小到摩天大楼的外部。现代城市日落的时间流逝。</p></blockquote>
<p class="translated">这是生成的视频:</p>
<p/><div id="attachment_2419589" class="wp-caption aligncenter amp-wp-7d2fa7a" data-amp-original-style="width: 266px"><amp-img aria-describedby="caption-attachment-2419589" class="size-full wp-image-2419589 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp" alt="Phenaki" srcset="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp 256w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=150,150 150w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=32,32 32w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=50,50 50w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=64,64 64w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=96,96 96w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=128,128 128w" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2419589" decoding="async" loading="lazy" class="size-full wp-image-2419589" src="../Images/93f2d451336df637a6cd1d3bba86779c.png" alt="Phenaki" srcset="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp 256w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=150,150 150w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=32,32 32w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=50,50 50w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=64,64 64w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=96,96 96w, https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp?resize=128,128 128w" sizes="(max-width: 256px) 100vw, 256px" data-original-src="https://web.archive.org/web/20230311084019im_/https://techcrunch.com/wp-content/uploads/2022/10/ezgif-2-badf7ec41e.webp"/></noscript></amp-img><p id="caption-attachment-2419589" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div>
<p class="translated"><span data-amp-original-style="font-size: 1rem; letter-spacing: -0.1px;" class="amp-wp-c9d2de0">回到 Imagen Video，研究人员还指出，用于训练系统的数据包含有问题的内容，这可能导致 Imagen Video 制作出图形暴力或色情露骨的片段。谷歌表示，它不会发布 Imagen 视频模型或源代码，“直到这些担忧得到缓解，”而且，与 Meta 不同，它不会提供任何形式的注册表格来注册兴趣。</span></p>
<p class="translated">尽管如此，随着文本到视频技术的快速发展，开源模式的出现可能用不了多久——这既增强了人类的创造力，也提出了一个棘手的挑战，其中涉及到<a href="https://web.archive.org/web/20230311084019/https://techcrunch.com/2022/08/24/deepfakes-for-all-uncensored-ai-art-model-prompts-ethics-questions/"> deepfakes </a>、<a href="https://web.archive.org/web/20230311084019/https://techcrunch.com/2022/07/22/commercial-image-generating-ai-raises-all-sorts-of-thorny-legal-issues/">版权</a>和错误信息。</p>


		

			
	
		

			<amp-pixel src="https://web.archive.org/web/20230311084019im_/https://ampmetrics.techcrunch.com/pixel.gif" placeholder="" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>
		<amp-analytics data-credentials="include" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed">
		
	</amp-analytics>
	<amp-pixel src="https://web.archive.org/web/20230311084019im_/https://pixel.wp.com/g.gif?v=ext&amp;blog=136296444&amp;post=2419476&amp;tz=-8&amp;srv=techcrunch.com&amp;host=techcrunch.com&amp;rand=RANDOM&amp;ref=DOCUMENT_REFERRER" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_googleanalytics" type="googleanalytics" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_comscore" type="comscore" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_parsely" type="parsely" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>	</div>

</div>    
</body>
</html>