<html>
<head>
<title>OpenAI is testing a version of GPT-4 that can 'remember' long conversations | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenAI 正在测试 GPT 4 的一个版本，它可以“记住”长时间的对话</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/14/openai-is-testing-a-version-of-gpt-4-that-can-remember-long-conversations/">https://web.archive.org/web/https://techcrunch.com/2023/03/14/openai-is-testing-a-version-of-gpt-4-that-can-remember-long-conversations/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">OpenAI 正在测试一个可以“记住”长对话的 GPT 4 版本</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">OpenAI 已经建立了一个版本的<a href="https://web.archive.org/web/20230408081409/https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/"> GPT-4 </a>，它的最新文本生成模型，由于大大扩展的上下文窗口，它可以“记住”大约 50 页的内容。</p>
<p class="translated">这听起来可能不太重要。但是它的信息量是普通的 GPT 4 号“记忆”的五倍，是 GPT 3 号的八倍。</p>
<p class="translated">“该模型能够灵活地使用长文档，”OpenAI 联合创始人兼总裁格雷格·布罗克曼在今天下午的现场演示中说。“我们想看看(这能实现)什么样的应用。”</p>
<p class="translated">当它涉及文本生成人工智能时，上下文窗口指的是模型在生成附加文本之前考虑的文本。虽然像 GPT-4 这样的模型通过对数十亿个文本示例进行训练来“学习”写作，但它们一次只能考虑一小部分文本——这主要取决于它们的上下文窗口的大小。</p>
<p class="translated">具有小上下文窗口的模型倾向于“忘记”最近的对话内容，导致他们偏离主题。大约几千个单词之后，他们也会忘记最初的指令，而是根据上下文窗口中的最后信息而不是最初的请求来推断他们的行为。</p>
<p class="translated">苹果公司的前软件工程师艾伦·派克生动地,<a href="https://web.archive.org/web/20230408081409/https://allenpike.com/2023/175b-parameter-goldfish-gpt" target="_blank" rel="noopener">这样解释</a>:</p>
<p class="translated">“[模型]会忘记你试图教给它的任何东西。它会忘记你住在加拿大。它会忘记你有孩子。它会忘记你讨厌在周三预订东西，请停止建议周三的东西，该死的。如果你们两个都很久没提起过你的名字，它也会忘记的。和一个(GPT 式的)角色聊一会儿，你会开始觉得你和他很亲近，会去一个很酷的地方。有时会有点困惑，但这也发生在人们身上。但最终，它没有中期记忆的事实变得清晰起来，这种幻觉也随之破灭。”</p><p class="piano-inline-promo"/>
<p class="translated">我们还没能拿到带扩展上下文窗口的 GPT-4 版本，gpt-4-32k。(OpenAI 表示，它正在“根据容量以不同的速度”处理高上下文和低上下文 GPT-4 模型的请求)但不难想象，与 it 的对话可能会比上一代产品更有吸引力。</p>
<p class="translated">凭借更大的“内存”，GPT-4 应该能够相对连贯地交谈几个小时——甚至几天——而不是几分钟。或许更重要的是，它不太可能出轨。正如派克所指出的，像 Bing Chat 这样的聊天机器人可能会被刺激得表现不佳的原因之一是，它们最初的指令——成为一个有帮助的聊天机器人，礼貌地回应等等——很快就被额外的提示和回应挤出了它们的上下文窗口。</p>
<p class="translated">它可以比这更微妙一点。但是上下文窗口在模型的基础上起着重要的作用。毫无疑问。假以时日，我们将会看到它会产生什么样的实际影响。</p>
			</div>

			</div>    
</body>
</html>