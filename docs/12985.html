<html>
<head>
<title>Twelve Labs lands $12M for AI that understands the context of videos | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">12 个实验室获得 1200 万美元，用于人工智能理解视频的背景| TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/12/05/twelve-labs-lands-12m-for-ai-that-understands-the-context-of-videos/">https://web.archive.org/web/https://techcrunch.com/2022/12/05/twelve-labs-lands-12m-for-ai-that-understands-the-context-of-videos/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">对于训练有素的数据科学家 Jae Lee 来说，视频——随着抖音、Vimeo 和 YouTube 等平台的兴起，它已经成为我们生活中的一个巨大部分——很难搜索，这是因为上下文理解带来的技术障碍。搜索视频的标题、描述和标签总是很容易，只需要一个基本的算法。但是在视频中搜索<em>特定的时刻和场景远远超出了技术的能力，特别是如果这些时刻和场景没有以一种明显的方式被标记的话。</em></p>
<p class="translated">为了解决这个问题，李开复和科技行业的朋友们一起，建立了一个视频搜索和理解的云服务。它变成了<a href="https://web.archive.org/web/20230228171927/https://twelvelabs.io/" target="_blank" rel="noopener">十二实验室</a>，并继续筹集了 1700 万美元的风险投资——其中 1200 万美元来自于今天结束的种子推广期。李在一封电子邮件中告诉 TechCrunch，Radical Ventures 领导了这次扩展，参与方包括 Index Ventures、WndrCo、Spring Ventures、Weights&amp;bias 首席执行官 Lukas Biewald 和其他人。</p>
<p class="translated">“十二实验室的愿景是通过为他们提供最强大的视频理解基础设施，帮助开发人员构建能够像我们一样看、听和理解世界的程序，”Lee 说。</p>
<p/><div id="attachment_2285094" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2285094" decoding="async" class="wp-image-2285094 size-full" src="../Images/7e5ee520007b6d60bdc30c6cbd981c5c.png" alt="" srcset="https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png 1275w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png?resize=150,86 150w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png?resize=300,172 300w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png?resize=768,442 768w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png?resize=680,391 680w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png?resize=1200,690 1200w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png?resize=50,29 50w" sizes="(max-width: 1275px) 100vw, 1275px" data-original-src="https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Search-API1.png"/><p id="caption-attachment-2285094" class="wp-caption-text translated">十二实验室平台功能的演示。<strong>图片来源:</strong>十二实验室</p></div>
<p class="translated">目前处于封闭测试阶段的 12 个实验室使用人工智能试图从视频中提取“丰富的信息”，如运动和动作、物体和人、声音、屏幕上的文本和语音，以确定它们之间的关系。该平台将这些不同的元素转换为称为“向量”的数学表示，并在帧之间形成“时间连接”，从而实现视频场景搜索等应用。</p>
<p class="translated">“作为实现公司帮助开发人员创建智能视频应用的愿景的一部分，十二实验室团队正在为多模态视频理解建立‘基础模型’，”Lee 说。“开发人员将能够通过一套 API 访问这些模型，不仅可以执行语义搜索，还可以执行其他任务，如长格式视频‘章节化’、摘要生成和视频问答。”</p>
<p class="translated">谷歌通过其<a href="https://web.archive.org/web/20230228171927/https://techcrunch.com/2021/09/29/google-introduces-a-new-way-to-search-that-combines-images-and-text-into-one-query/"> MUM AI 系统</a>采取了类似的视频理解方法，该公司使用该系统通过基于音频、文本和视觉内容挑选视频中的主题(例如，“丙烯绘画材料”)来为谷歌搜索和 YouTube 上的视频推荐提供动力。虽然这项技术可能不相上下，但 12 实验室是第一批将其推向市场的供应商之一；谷歌选择在内部保持沉默，拒绝通过面向公众的 API 提供。</p><p class="piano-inline-promo"/>
<p class="translated">话虽如此，谷歌以及微软和亚马逊都提供了识别视频中的对象、位置和动作并在帧级别提取丰富元数据的服务(即谷歌云视频 AI、Azure 视频索引器和 AWS Rekognition)。还有<a href="https://web.archive.org/web/20230228171927/https://techcrunch.com/2019/05/27/reminiz-automatically-indexes-and-tags-videos-in-real-time/"> Reminiz </a>，一家法国计算机视觉初创公司，声称能够索引任何类型的视频，并为录制和直播内容添加标签。但 Lee 断言，十二实验室已经足够差异化——部分原因是其平台允许客户根据特定类别的视频内容对人工智能进行微调。</p>
<p/><div id="attachment_2285095" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2285095" decoding="async" loading="lazy" class="wp-image-2285095 size-full" src="../Images/191df49d9703e633a0287dc35afcd5ac.png" alt="" srcset="https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png 1272w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=150,86 150w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=300,172 300w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=768,441 768w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=680,391 680w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=1200,690 1200w, https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=50,29 50w" sizes="(max-width: 1272px) 100vw, 1272px" data-original-src="https://web.archive.org/web/20230228171927im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png"/><p id="caption-attachment-2285095" class="wp-caption-text translated">API 模型，用于微调模型，以便更好地处理沙拉相关内容。<strong>图片来源:</strong>十二实验室</p></div>
<p class="translated">“我们发现，为检测特定问题而构建的狭义人工智能产品在受控环境下的理想场景中显示出很高的准确性，但对于杂乱的现实世界数据来说却不那么适用，”Lee 说。“它们更像是一个基于规则的系统，因此在出现差异时缺乏概括的能力。我们也认为这是一种局限，根源在于缺乏对上下文的理解。对背景的理解赋予了人类独特的能力，可以对现实世界中看似不同的情况进行归纳，这也是十二实验室的独特之处。”</p>
<p class="translated">除了搜索，李说，十二实验室的技术可以推动广告插入和内容调节等事情，例如，智能地计算出哪些视频显示刀是暴力的，而不是指导性的。他说，它还可以用于媒体分析和实时反馈，以及从视频中自动生成精彩片段。</p>
<p class="translated">在成立一年多一点后(2021 年 3 月)，十二实验室拥有付费客户——李没有透露具体有多少——并与甲骨文签订了多年合同，使用甲骨文的云基础设施训练人工智能模型。展望未来，这家初创公司计划投资发展技术和扩大团队。(Lee 拒绝透露 12 个实验室目前的员工规模，但 LinkedIn <a href="https://web.archive.org/web/20230228171927/https://www.linkedin.com/company/twelvelabs/people/" target="_blank" rel="noopener">数据</a>显示大约有 18 人。)</p>
<p class="translated">“对于大多数公司来说，尽管大型模型可以带来巨大的价值，但让他们自己训练、操作和维护这些模型确实没有意义。通过利用十二实验室平台，任何组织都可以通过几个直观的 API 调用来利用强大的视频理解能力，”Lee 说。“人工智能创新的未来方向是直接走向多模态视频理解，而 12 个实验室有望在 2023 年进一步推动这一界限。”</p>
			</div>

			</div>    
</body>
</html>