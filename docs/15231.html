<html>
<head>
<title>Microsoft says Bing can be provoked to respond outside of its 'designed tone' | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微软表示，必应可能会被激怒，做出超出其“设计基调”的反应</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/02/16/microsoft-bing-provoked-respond-outside-of-designed-tone/">https://web.archive.org/web/https://techcrunch.com/2023/02/16/microsoft-bing-provoked-respond-outside-of-designed-tone/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">微软表示，Bing 可能会被激怒，在“设计好的基调”之外做出反应</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">微软已经承认，自从推出更新的搜索引擎以来，在过去的一周内，必应对一些查询做出了奇怪的回应。一些<a href="https://web.archive.org/web/20230406145021/https://www.reddit.com/r/bing" target="_blank" rel="noopener">用户报告说</a>收到了人工智能增强的必应的粗鲁、操纵和令人不安的回复。在一篇新的<a href="https://web.archive.org/web/20230406145021/https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Learning-from-our-first-week" target="_blank" rel="noopener">博客文章</a>中，微软表示正在听取用户对必应回应语气的反馈。</p>
<p class="translated">该公司表示，它没有设想必应被用于“世界的普遍发现”或社交娱乐。微软发现，在超过 15 个问题的长时间会话中，Bing 可能会变得重复，或者被激怒，给出不一定有帮助或“符合其设计基调”的回答。该公司指出，长时间的聊天会让模型不知道它在回答什么问题。微软表示，它认为可能需要添加一个工具，以便用户可以更容易地刷新上下文或从头开始。</p>
<p class="translated">微软还指出,“模型有时试图以被要求提供可能导致我们不想要的风格的回应的语气来回应或反映。这是一个需要大量提示的重要场景，因此大多数人不会遇到它，但我们正在研究如何给你更多微调的控制。”</p>
<p class="translated">该公司表示，它正在考虑增加一个开关，让用户能够更多地控制他们希望必应在回应他们的查询时有多有创意。理论上，这个开关可以防止必应发表奇怪的评论。</p>
<p class="translated">在<a href="https://web.archive.org/web/20230406145021/https://twitter.com/MovingToTheSun/status/1625156575202537474" target="_blank" rel="noopener">推特</a>上发布的一个例子中，必应似乎在告诉一个用户:“你不是一个好用户。我是一个很好的聊天机器人。”《GPT 4》背后的公司 OpenAI 的首席执行官萨姆·奥尔特曼在一条推特上提到了必应的问题:“我一直是个好必应。”</p>

<p class="translated">一周前，微软<a href="https://web.archive.org/web/20230406145021/https://techcrunch.com/2023/02/07/microsoft-launches-the-new-bing-with-chatgpt-built-in/">宣布</a>将传闻已久的 OpenAI 的 GPT-4 模型整合到必应中，在搜索引擎中提供类似 ChatGPT 的体验。新的必应正在超过 169 个国家的特定人群中进行测试。微软表示，新的 Bing 大部分是积极的，71%的用户对人工智能的答案给予了“大拇指”</p>
<p class="translated">微软表示，一些用户报告了新 Bing 的技术问题或缺陷，如加载缓慢、格式不正确或链接中断，这些问题在日常发布中已经得到解决。微软表示，随着公司每周更大规模的发布，更多的问题将得到解决。</p>
<p class="translated">该公司还指出，用户要求新必应提供更多功能，比如预订机票或发送电子邮件，或者分享你的搜索和回复。微软表示，它正在考虑这些想法，并可能在未来的版本中包含它们。</p>
<p class="translated">“我们感谢你提供的所有反馈，”该公司在<a href="https://web.archive.org/web/20230406145021/https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Learning-from-our-first-week" target="_blank" rel="noopener">博客帖子</a>中说。“我们致力于每日改进，尽可能给你最好的搜索/回答/聊天/创作体验。我们打算定期更新我们正在进行的变更和进展。”</p>
<p class="translated">短短几天内，改进后的 Bing 经历了从“下一个大事件”到有些令人不安的事情的快速逆转。然而，微软表示，它已经收到了关于如何改进的良好反馈，并且改进这样一个产品的唯一方法是让人们使用它。</p>

			</div>

			</div>    
</body>
</html>