<html>
<head>
<title>Perceptron AI Roundup: Bias, computer vision and wave action</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">感知人工智能综述:偏见、计算机视觉和波动作用</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/05/08/perceptron-ai-bias-can-arise-from-annotation-instructions/">https://web.archive.org/web/https://techcrunch.com/2022/05/08/perceptron-ai-bias-can-arise-from-annotation-instructions/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">机器学习和人工智能领域的研究现在几乎是每个行业和公司的一项关键技术，对于任何人来说都太庞大了，无法全部阅读。这个专栏，感知器(以前的<a href="https://web.archive.org/web/20230318115303/https://techcrunch.com/tag/deep-science/">深度科学</a>)，旨在收集一些最相关的最新发现和论文——特别是在但不限于人工智能领域——并解释它们为什么重要。</p>
<p id="speakable-summary" class="translated">本周在《人工智能》杂志上，一项新的研究揭示了偏差(人工智能系统中的一个常见问题)是如何从给被招募来注释数据的人发出指令开始的，人工智能系统从这些数据中学习进行预测。合著者发现，注释者在指令中提取模式，这使他们能够贡献注释，然后这些注释在数据中变得过多，使 AI 系统偏向这些注释。</p>
<p class="translated">今天，许多人工智能系统“学习”从标注者标注的例子中理解图像、视频、文本和音频。标签使得系统能够推断示例之间的关系(例如，标题“厨房水槽”和厨房水槽的照片之间的链接)到系统以前没有见过的数据(例如，没有包括在用于“教导”模型的数据中的厨房水槽的照片)。</p>
<p class="translated">这非常有效。但是注释并不是一种完美的方法——注释者给表格带来了偏见，这种偏见会渗透到经过训练的系统中。例如，研究表明，<a href="https://web.archive.org/web/20230318115303/https://www.unite.ai/the-invisible-often-unhappy-workforce-thats-deciding-the-future-of-ai/">的普通注释者</a>更有可能将非裔美国人白话英语(AAVE，一些美国黑人使用的非正式语法)中的短语标记为有毒，这导致经过标签训练的人工智能毒性检测器将 AAVE 视为毒性过大。</p>
<p class="translated">事实证明，注释者的倾向性可能不是训练标签中存在偏见的唯一原因。在亚利桑那州立大学和艾伦人工智能研究所的一项预印本<a href="https://web.archive.org/web/20230318115303/https://arxiv.org/abs/2205.00415?context=cs.AI">研究</a>中，研究人员调查了偏见的来源是否可能存在于数据集创建者编写的指导注释者的指令中。此类说明通常包括任务的简短描述(例如，“标记这些照片中的所有鸟类”)以及几个示例。</p>
<p class="mceTemp"/>
<p/><div id="attachment_2314227" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2314227" decoding="async" class="vertical wp-image-2314227 size-full" src="../Images/3293beb5f8f5009c0153df559aed84f2.png" alt="Parmar et al." srcset="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/Screenshot-2.png 696w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/Screenshot-2.png?resize=68,150 68w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/Screenshot-2.png?resize=137,300 137w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/Screenshot-2.png?resize=310,680 310w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/Screenshot-2.png?resize=547,1200 547w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/Screenshot-2.png?resize=23,50 23w" sizes="(max-width: 696px) 100vw, 696px" data-original-src="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/Screenshot-2.png"/><p id="caption-attachment-2314227" class="wp-caption-text translated"><strong>图片来源:</strong> Parmar 等人。</p></div>
<p class="translated">研究人员查看了 14 个不同的“基准”数据集，这些数据集用于衡量自然语言处理系统或人工智能系统的性能，这些系统可以分类，总结，翻译以及其他分析或操纵文本。在研究提供给处理数据集的注释者的任务指令时，他们发现了这些指令影响注释者遵循特定模式的证据，这些模式随后传播到数据集。例如，Quoref(一个旨在测试人工智能系统理解两个或更多表达式何时指代同一个人(或事物)的能力的数据集)中超过一半的注释以短语“名称是什么”开头，该短语出现在该数据集三分之一的指令中。</p><p class="piano-inline-promo"/>
<p class="translated">这种现象被研究人员称为“指令偏差”，特别令人不安，因为它表明，根据有偏差的指令/注释数据训练的系统可能不如最初想象的那样好。事实上，合著者发现，指令偏差高估了系统的性能，并且这些系统通常无法超越指令模式进行归纳。</p>
<p class="translated">令人欣慰的是，像 OpenAI 的 GPT-3 这样的大型系统通常对指令偏差不太敏感。但这项研究提醒人们，人工智能系统像人一样，容易受到来自不总是显而易见的来源的偏见的影响。棘手的挑战是发现这些源头并减轻下游影响。</p>
<p class="translated">在一篇不那么发人深省的论文中，来自瑞士的科学家<a href="https://web.archive.org/web/20230318115303/https://arxiv.org/pdf/2205.02496.pdf">得出结论</a>面部识别系统不容易被人工智能编辑的真实面孔所欺骗。他们称之为“变形攻击”，涉及使用人工智能修改身份证、护照或其他形式的身份证件上的照片，以绕过安全系统。合著者使用 AI(英伟达的 StyleGAN 2)创建了“变形”，并对四个最先进的面部识别系统进行了测试。他们声称，尽管它们看起来很真实，但这些变形并没有造成重大威胁。</p>
<p class="translated">在计算机视觉领域的其他地方，Meta 的研究人员开发了一种人工智能“助手”，它可以记住房间的特征，包括物体的位置和背景，以回答问题。在一篇预印本论文中，这项工作很可能是 Meta 的<a href="https://web.archive.org/web/20230318115303/https://www.theverge.com/23022611/meta-facebook-nazare-ar-glasses-roadmap-2024">项目纳扎尔</a>倡议的一部分，旨在开发利用人工智能分析周围环境的增强现实眼镜。</p>
<p/><div id="attachment_2314226" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2314226" decoding="async" loading="lazy" class="size-full wp-image-2314226" src="../Images/664ca38707c5cc6b8d8e1640d2a5c100.png" alt="Meta egocentric AI" srcset="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png 2000w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png?resize=150,84 150w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png?resize=300,169 300w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png?resize=768,432 768w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png?resize=680,383 680w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png?resize=1536,864 1536w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png?resize=1200,675 1200w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/teaser.png"/><p id="caption-attachment-2314226" class="wp-caption-text translated"><strong>图片来源:</strong> Meta</p></div>
<p class="translated">研究人员的系统旨在用于任何配备摄像头的穿戴式设备，分析镜头以构建“语义丰富而有效的场景记忆”，这些记忆“编码了关于物体的时空信息。”该系统会记住物体在哪里，何时出现在视频片段中，此外还会将用户可能会问的关于物体的问题的答案存储在它的内存中。例如，当被问到“你最后一次看到我的钥匙是在哪里？系统可以指示那天早上钥匙在客厅的边桌上。</p>
<p class="translated">meta<a href="https://web.archive.org/web/20230318115303/https://techcrunch.com/2018/10/24/facebook-ar-headset/">据报道</a>计划在 2024 年发布全功能 AR 眼镜，去年 10 月发布了 Ego4D，这是一个长期的“以自我为中心的感知”人工智能研究项目，透露了其“以自我为中心”的人工智能计划。该公司当时表示，目标是教会人工智能系统理解社会线索，AR 设备佩戴者的行为可能如何影响他们的周围环境，以及手如何与物体互动。</p>
<p class="translated">从语言和增强现实到物理现象:人工智能模型在麻省理工学院的波研究中非常有用——它们是如何破裂的以及何时破裂的。虽然这看起来有点神秘，但事实是波浪模型对于在水中和附近建造结构以及在气候模型中模拟海洋与大气的相互作用都是需要的。</p>
<p/><div id="attachment_2314222" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2314222" decoding="async" loading="lazy" class="size-full wp-image-2314222" src="../Images/98a3f1b0ca75358dabb55b118c22be7e.png" alt="" srcset="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/MIT-BreakingWaves-02-press.jpg 900w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/MIT-BreakingWaves-02-press.jpg?resize=150,100 150w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/MIT-BreakingWaves-02-press.jpg?resize=300,200 300w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/MIT-BreakingWaves-02-press.jpg?resize=768,512 768w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/MIT-BreakingWaves-02-press.jpg?resize=680,453 680w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/MIT-BreakingWaves-02-press.jpg?resize=50,33 50w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/MIT-BreakingWaves-02-press.jpg"/><p id="caption-attachment-2314222" class="wp-caption-text translated"><strong>图片来源:</strong>麻省理工学院</p></div>
<p class="translated">通常情况下，波浪是由一组方程粗略模拟的，但研究人员<a href="https://web.archive.org/web/20230318115303/https://news.mit.edu/2022/wave-model-ai-0429">在一个装满传感器的 40 英尺水槽中，对数百个波浪实例训练了一个机器学习模型</a>。通过观察波浪并根据经验证据进行预测，然后将其与理论模型进行比较，人工智能有助于显示模型的不足之处。</p>
<p class="translated">一家初创公司诞生于 EPFL 大学的研究，Thibault Asselborn 关于笔迹分析的博士论文已经变成了一款成熟的教育应用程序。利用他设计的算法，这款名为“学校反弹”的应用程序可以识别习惯和纠正措施，只需 30 秒，一个孩子就可以用手写笔在 iPad 上写字。这些以游戏的形式呈现给孩子，通过强化良好的习惯帮助他们写得更清楚。</p>
<p class="translated">“我们的科学模型和严谨性很重要，这也是我们区别于其他现有应用的地方，”阿瑟伯恩在一次新闻发布会上说。“我们收到了一些老师的来信，他们看到自己的学生进步神速。有些学生甚至在课前就来练习。”</p>
<p/><div id="attachment_2314223" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2314223" decoding="async" loading="lazy" class="size-full wp-image-2314223" src="../Images/9fd85927e8b476dbdfabafa934cf7f8c.png" alt="" srcset="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/tympanometer.jpeg 799w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/tympanometer.jpeg?resize=150,113 150w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/tympanometer.jpeg?resize=300,225 300w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/tympanometer.jpeg?resize=768,577 768w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/tympanometer.jpeg?resize=680,511 680w, https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/tympanometer.jpeg?resize=50,38 50w" sizes="(max-width: 799px) 100vw, 799px" data-original-src="https://web.archive.org/web/20230318115303im_/https://techcrunch.com/wp-content/uploads/2022/05/tympanometer.jpeg"/><p id="caption-attachment-2314223" class="wp-caption-text translated"><strong>图片来源:</strong>杜克大学</p></div>
<p class="translated">小学的另一个新发现与在常规筛查中识别听力问题有关。一些读者可能记得，这些筛查通常使用一种称为鼓室计的设备，必须由受过训练的听力学家操作。如果没有，比如在一个孤立的学区，有听力问题的孩子可能永远无法及时得到他们需要的帮助。</p>
<p class="translated">杜克大学的 Samantha Robler 和 Susan Emmett 决定建造一个基本上自己操作的鼓室计，将数据发送到智能手机应用程序，由人工智能模型进行解释。任何令人担忧的事情都会被标记出来，孩子可以接受进一步的检查。它不能代替专家，但是它比什么都没有好得多，并且可以帮助在没有适当资源的地方更早地发现听力问题。</p>
			</div>

			</div>    
</body>
</html>