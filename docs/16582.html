<html>
<head>
<title>1,100+ notable signatories just signed an open letter asking 'all AI labs to immediately pause for at least 6 months' | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">1，100 多名知名签名者刚刚签署了一封公开信，要求“所有人工智能实验室立即暂停至少 6 个月”| TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/">https://web.archive.org/web/https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">包括人道技术中心的埃隆·马斯克、史蒂夫·沃兹尼亚克和特里斯坦·哈里斯在内的 1100 多名签名者签署了一封公开信，该公开信于周二晚上发布在网上，呼吁“所有人工智能实验室立即暂停至少 6 个月的人工智能系统训练，这些系统比 GPT-4 更强大。”</p>
<p class="translated">信中写道:</p>
<blockquote><p class="translated">当代人工智能系统现在在一般任务上变得与人类竞争，[3]我们必须问自己:我们应该让机器用宣传和谎言淹没我们的信息渠道吗？我们应该自动化所有的工作吗，包括令人满意的工作？我们是否应该开发出非人类的思维，最终可能在数量上超过、智胜、淘汰并取代我们？我们应该冒着失去对我们文明控制的风险吗？这种决定不能委托给未经选举的科技领袖。只有当我们确信强大的人工智能系统的效果是积极的，并且其风险是可控的，我们才应该开发这些系统。</p></blockquote>
<p class="translated">这封信认为，有一个“规划和管理水平”是“没有发生的”，相反，在最近几个月，未命名的“人工智能实验室”已经“陷入了一场失控的竞赛，以开发和部署越来越强大的数字思维，没有人——甚至是它们的创造者——可以理解、预测或可靠地控制。”</p>
<p class="translated">这封<a href="https://web.archive.org/web/20230409032002/https://finance.yahoo.com/news/musk-experts-urge-pause-training-042927625.html" target="_blank" rel="noopener">信的签名者</a>，其中一些是人工智能专家，表示他们要求的暂停应该是“公开和可验证的，并包括所有关键角色。”信中说，如果上述暂停“不能很快实施，政府应该介入并制定暂停令”。</p>
<p class="translated">当然，这封信很有趣，因为有签名的人——包括 Meta 和谷歌的一些工程师，Stability AI 创始人兼首席执行官艾玛德·莫斯塔克，以及非技术人员，包括一名自称的电工和美学家——也有没有签名的人。例如，大型语言模型 GPT-4 背后的组织 OpenAI 没有人在这封信上签名。Anthropic 的人也没有，他们的团队从 OpenAI 中分离出来，建立了一个“<a href="https://web.archive.org/web/20230409032002/https://www.anthropic.com/research">更安全的</a>”人工智能聊天机器人。</p>

<p class="translated">周三，OpenAI 首席执行官 Sam Altman <a href="https://web.archive.org/web/20230409032002/https://www.wsj.com/articles/elon-musk-other-ai-bigwigs-call-for-pause-in-technologys-development-56327f?mod=djemalertNEWS">接受《华尔街日报》采访时表示，OpenAI 还没有开始训练 GPT-5。奥尔特曼还指出，该公司长期以来一直优先考虑发展中的安全问题，并在发射前花了六个多月的时间对 GPT-4 进行安全测试。“在某种意义上，这是在向唱诗班布道，”他告诉《华尔街日报》。“我认为，我们一直在最大声、最强烈、最长时间地谈论这些问题。”</a></p>
<p class="translated">事实上，奥特曼<a href="https://web.archive.org/web/20230409032002/https://www.youtube.com/watch?v=ebjkD1Om4uw">在一月份与这位编辑坐下来</a>，他认为“现在开始这些(产品发布)是有意义的，因为风险仍然相对较低，而不是仅仅发布整个行业在几年后将会拥有的东西，而没有时间让社会更新。”</p>
<p class="translated">奥特曼最近与计算机科学家和受欢迎的播客莱克斯·弗里德曼坐下来，<a href="https://web.archive.org/web/20230409032002/https://www.youtube.com/watch?v=L_Guz73e6fw" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link" data-analytics-post-depth="40" data-uri="ced56c3688156c092f34673c2a463d7c">谈到了他与马斯克的关系，马斯克是 OpenAI 的联合创始人，但在 2018 年以利益冲突为由离开了该组织。(来自 Semafor 的一份更新的报告称，马斯克在他提出运营 OpenAI 的提议被其他联合创始人</a><a href="https://web.archive.org/web/20230409032002/https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai">拒绝</a>后离开，其中包括 2019 年初担任首席执行官的奥特曼。)</p>
<p class="translated">马斯克可能是这封公开信中最不令人惊讶的签名者，因为他多年来一直在谈论人工智能安全，最近更是专门针对 OpenAI，暗示该公司只是说说而已。弗里德曼问奥特曼关于马斯克最近和例行的推文<a href="https://web.archive.org/web/20230409032002/https://twitter.com/elonmusk/status/1626516035863212034?lang=en">抨击该组织</a>。奥特曼说:“埃隆现在显然在推特上通过一些不同的途径攻击我们，我感同身受，因为我相信他真的很担心 AGI 的安全，这是可以理解的。我肯定还有其他一些动机，但这绝对是其中之一。”</p>
<p class="translated">尽管如此，奥尔特曼补充道，他发现马斯克的一些行为是有害的。“毫无疑问，埃隆是我成长过程中的英雄。你知道，尽管他在推特上是个混蛋，但我很高兴他存在于这个世界上。但我希望他能多看看我们为把这些事情做好所做的努力。”</p>
<p class="translated">我们还在消化这封信(其他人已经<a href="https://web.archive.org/web/20230409032002/https://twitter.com/jeffjarvis/status/1640834319647141888" target="_blank" rel="noopener">把它撕成碎片</a>)。</p>
<p class="translated">同时，你可以<a href="https://web.archive.org/web/20230409032002/https://futureoflife.org/open-letter/pause-giant-ai-experiments/" target="_blank" rel="noopener">在这里</a>阅读全文。</p>
			</div>

			</div>    
</body>
</html>