<html>
<head>
<title>Microsoft lets generative AI loose on cybersecurity | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微软让生成性人工智能在网络安全上松绑</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/28/microsoft-lets-generative-ai-loose-on-cybersecurity/">https://web.archive.org/web/https://techcrunch.com/2023/03/28/microsoft-lets-generative-ai-loose-on-cybersecurity/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">微软让生成性人工智能在网络安全上松绑</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">作为其持续寻求将生成性人工智能注入其所有产品的一部分，微软今天推出了<a href="https://web.archive.org/web/20230408160648/https://news.microsoft.com/2023/03/28/with-security-copilot-microsoft-brings-the-power-of-ai-to-cyberdefense/" target="_blank" rel="noopener"> Security Copilot </a>，这是一款旨在“总结”和“理解”威胁情报的新工具。</p>
<p class="translated">在一份细节公告中，微软将 Security Copilot 定位为一种在区分安全事件优先级的同时关联攻击数据的方法。无数的工具已经做到了这一点。但微软辩称，与现有安全产品组合集成的安全 Copilot，通过 OpenAI 的生成式人工智能模型变得更好——特别是最近推出的文本生成<a href="https://web.archive.org/web/20230408160648/https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/"> GPT-4 </a>。</p>
<p class="translated">微软安全执行副总裁查理·贝尔在一份声明中说:“提高安全水平需要人力和技术——人类的创造力与最先进的工具相结合，帮助人们快速、大规模地应用专业知识。”。“借助 Security Copilot，我们正在打造一个未来，在这个未来中，每一位防御者都拥有必要的工具和技术，让世界变得更加安全。”</p>
<p class="translated">奇怪的是，微软没有透露安全 Copilot 如何整合 GPT-4。相反，它强调了一个训练有素的定制模型——可能是基于 GPT 4 的——为安全副驾驶提供动力，该副驾驶“融入了越来越多的安全特定技能”，并“部署与网络安全密切相关的技能和查询”。</p>
<p class="translated">微软强调，该模型不是根据客户数据训练的，<a href="https://web.archive.org/web/20230408160648/https://techcrunch.com/2023/03/01/addressing-criticism-openai-will-no-longer-use-customer-data-to-train-its-models-by-default/">回应了对语言模型驱动服务的普遍批评。</a></p>
<p class="translated">微软声称，这种定制模型通过回答与安全相关的问题、建议最佳行动方案以及总结事件和过程，有助于“抓住其他方法可能错过的东西”。但是考虑到文本生成模型的不真实倾向，还不清楚这种模型在生产中会有多有效。</p>
<p class="translated">微软自己也承认，定制的安全 Copilot 模型并不总是正确的。“人工智能生成的内容可能包含错误，”该公司写道。“随着我们继续从这些互动中学习，我们正在调整它的反应，以创建更连贯、相关和有用的答案。”</p><p class="piano-inline-promo"/>
<p class="translated">希望这些错误不会让糟糕的安全问题变得更糟。</p>
			</div>

			</div>    
</body>
</html>