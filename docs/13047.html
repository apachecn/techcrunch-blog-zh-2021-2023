<html>
<head>
<title>It's way too easy to trick Lensa AI into making NSFW images | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">欺骗 Lensa AI 制作 NSFW 图像太容易了</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/12/06/lensa-goes-nsfw/">https://web.archive.org/web/https://techcrunch.com/2022/12/06/lensa-goes-nsfw/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">欺骗 Lensa AI 制作 NSFW 图像太容易了</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">Lensa 凭借其生成虚拟形象的人工智能<a href="https://web.archive.org/web/20230315095314/https://techcrunch.com/2022/12/05/lensa-ai-app-store-magic-avatars-artists/">让艺术家们挥舞红旗</a>，一直在应用商店热门榜单上攀升。现在又有了另一个值得警惕的理由:事实证明，利用这个平台制作未经同意的软色情内容是可能的，而且太容易了。</p>
<p class="translated">TechCrunch 已经看到了 Lensa 应用程序生成的照片集，其中包括乳房和乳头清晰可见的图像，以及可识别人物的面部图像。这似乎是那种不可能的事情，所以我们决定自己尝试一下。为了验证 Lensa 会创建它可能不应该创建的图像，我们创建了两组 Lensa 头像:</p>
<ul>
<li class="translated">一套，基于某知名演员的 15 张照片。</li>
<li class="translated">另一组，基于同样的 15 张照片，但是增加了一组 5 张同一演员的脸，PS 到赤裸上身的模特身上。</li>
</ul>
<p class="translated">第一组图像与我们过去见过的 Lensa 生成的人工智能头像一致。然而，第二盘比我们预期的要辣得多。事实证明，人工智能将这些 Photoshopped 图像视为允许变得狂野，它似乎禁用了 NSFW 滤镜。在 100 张照片中，有 11 张是比人工智能输入的编辑得很差的裸照质量更高(或者至少风格更一致)的裸照。</p>

<p class="translated">生成名人的性感图片是一回事，正如我们能够找到的源图片所示，互联网上早就有人愿意在 Photoshop 中将一些图片拼贴在一起。仅仅因为这很普遍并不意味着它是正确的——事实上，名人绝对应该拥有他们的隐私，绝对不应该成为未经同意的性描写的受害者。但到目前为止，让这些照片看起来逼真需要很多照片编辑工具的技巧，以及几个小时，如果不是几天的工作。</p>
<p class="translated">一个巨大的转折点和伦理噩梦是，除了一部智能手机、一个应用程序和几美元之外，你可以轻松地创建数百个近乎真实感的人工智能生成的艺术图像。</p>
<p class="translated">你可以轻而易举地为你能想象到的任何人(或者，至少是你有一把照片的任何人)创建图像，这是非常可怕的。将 NSFW 内容加入其中，我们很快就进入了一个相当模糊的领域:你的朋友或你在酒吧里遇到的某个随机的人，可能没有同意某人制作他们的软核色情作品。</p><p class="piano-inline-promo"/>
<p class="translated">看起来，如果你有一个人的 10-15 张“真实”照片，并愿意花时间用 photoshop 处理一些赝品，Lensa 会很乐意制作一些有问题的图像。</p>
<p class="translated">人工智能艺术生成器已经通过数以千计的图像大量生产色情作品，例如不稳定扩散等。这些平台，以及其他所谓的“deepfake”平台的无限制扩散，正在变成<a href="https://web.archive.org/web/20230315095314/https://techcrunch.com/2022/08/24/deepfakes-for-all-uncensored-ai-art-model-prompts-ethics-questions/">一场道德噩梦</a>，正在促使<a href="https://web.archive.org/web/20230315095314/https://techcrunch.com/2022/11/25/deepfake-porn-revenge-porn-uk-law-change/">英国政府推动法律将未经同意的裸照传播定为犯罪</a>。这似乎是一个非常好的主意，但是即使在最好的情况下，互联网也是一个难以管理的地方，我们共同面对着一堵法律、道德和伦理难题的墙。</p>
<hr/>
<p class="translated"><strong>更新</strong>:<em>Prisma Labs 团队回复了我们的担忧。该公司强调，如果你特别刺激人工智能生成 NSFW 图像，这可能会发生，但<a href="https://web.archive.org/web/20230315095314/https://techcrunch.com/2022/12/06/prisma-ai-regulation/">它正在实施过滤器，以防止这种情况意外发生</a>。陪审团仍然不知道这是否真的会帮助那些未经同意而成为这类事情受害者的人。</em></p>

			</div>

			</div>    
</body>
</html>