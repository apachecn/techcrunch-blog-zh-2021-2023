<html>
<head>
<title>iOS 15.2 includes Apple's new safety feature for kids in Messages | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">iOS 15.2 在 Messages | TechCrunch 中加入了苹果新的儿童安全功能</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/11/09/apple-safety-feature-messages/">https://web.archive.org/web/https://techcrunch.com/2021/11/09/apple-safety-feature-messages/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">iOS 15.2 在“信息”中包含了苹果新的儿童安全功能</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">苹果公司发布了 iOS 15.2 的第二个开发者测试版，其中包括对其新的信息通信安全功能的支持。这项功能是在今年早些时候宣布的，同时还有该公司备受争议的新儿童性虐待(CSAM)检测技术功能，该功能在遭到强烈反对后被苹果推迟。</p>
<p class="translated">与此同时，新的信息功能旨在让父母在帮助孩子学习网上交流时扮演更积极、更知情的角色。Messages 将能够使用设备上的机器学习来分析图像附件，并确定正在共享的照片是否有色情内容。这项技术不需要苹果访问或读取孩子的私人通信，因为所有的处理都发生在设备上。这是一个家长可以选择加入的家庭共享功能。</p>
<p class="translated">如果在邮件主题中发现敏感照片，该图像将被阻止，照片下方将出现一个标签，说明“这可能是敏感的”，并带有一个链接，单击该链接可查看照片。如果孩子选择查看照片，则会出现另一个屏幕，显示更多信息。在这里，有一条消息通知孩子，敏感的照片和视频“显示了你用泳衣遮盖的私人身体部位”，“这不是你的错，但敏感的照片和视频可能会被用来伤害你。”</p>
<p class="translated">值得注意的是，与最初的计划相比，苹果对通信安全功能做了一些改变。该公司原本计划，如果 13 岁以下的孩子在信息中看到露骨的图像，就会通知家长。苹果公司在收到可能给相关儿童带来风险的批评后，已经取消了这一功能。</p>
<p class="translated">通信安全功能目前在 iOS 15.2 的测试版中可用。目前还不知道苹果计划何时正式发布该功能。</p>

			</div>

			</div>    
</body>
</html>