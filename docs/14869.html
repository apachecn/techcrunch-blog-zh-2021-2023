<html>
<head>
<title>The current legal cases against generative AI are just the beginning | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当前针对生殖人工智能的法律案件仅仅是个开始</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/01/27/the-current-legal-cases-against-generative-ai-are-just-the-beginning/">https://web.archive.org/web/https://techcrunch.com/2023/01/27/the-current-legal-cases-against-generative-ai-are-just-the-beginning/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">随着生殖人工智能进入主流，每一天都会带来新的诉讼。</p>
<p class="translated">微软、GitHub 和 OpenAI 目前正在<a href="https://web.archive.org/web/20230409033059/https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data" target="_blank" rel="noopener">的集体诉讼</a>中被<a href="https://web.archive.org/web/20230409033059/https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data" target="_blank" rel="noopener">起诉</a>，指控他们违反版权法，允许<a href="https://web.archive.org/web/20230409033059/https://techcrunch.com/tag/github-copilot/"> Copilot </a>，一个在数十亿行公共代码上训练的代码生成人工智能系统，在不提供信用的情况下返回授权代码片段。</p>
<p class="translated">流行的人工智能艺术工具背后的两家公司，<a href="https://web.archive.org/web/20230409033059/https://techcrunch.com/tag/midjourney/"> Midjourney </a>和 Stability AI，正处于一起<a href="https://web.archive.org/web/20230409033059/https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart" target="_blank" rel="noopener">法律案件</a>的焦点，该案件指控它们通过在网络抓取的图像上训练它们的工具，侵犯了数百万艺术家的权利。</p>
<p class="translated">就在上周，股票图像供应商 Getty Images 将 Stability AI 告上法庭，理由是<a href="https://web.archive.org/web/20230409033059/https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit" target="_blank" rel="noopener">据报道</a>未经许可使用其网站上的数百万张图像来训练<a href="https://web.archive.org/web/20230409033059/https://techcrunch.com/tag/stable-diffusion/"> Stable Diffusion </a>，这是一种艺术生成人工智能。</p>
<p class="translated">主要的争议在于，生成式人工智能倾向于从用于训练它的数据中复制图像、文本等内容，包括受版权保护的内容。在最近的一个例子中，CNET 用来写解释性文章的人工智能工具被发现抄袭了人类写的文章——这些文章可能是在它的训练数据集中搜索到的。与此同时，12 月发表的一项学术研究发现，像<a href="https://web.archive.org/web/20230409033059/https://techcrunch.com/tag/dall-e/"> DALL-E 2 </a>和<a href="https://web.archive.org/web/20230409033059/https://techcrunch.com/tag/stable-diffusion/">稳定扩散</a>这样的图像生成人工智能模型能够并且确实<a href="https://web.archive.org/web/20230409033059/https://arxiv.org/pdf/2212.03860.pdf" target="_blank" rel="noopener">从它们的训练数据中复制图像的某些方面</a>。</p>
<p class="translated">生殖人工智能领域保持健康——根据 PitchBook 的<a href="https://web.archive.org/web/20230409033059/https://www.emergingtechbrew.com/stories/2022/12/21/three-inflection-points-for-emerging-tech-in-2022" target="_blank" rel="noopener">数据，截至 2022 年 11 月，它筹集了 13 亿美元的风险资金，比去年增长了 15%。但是法律问题开始影响商业。</a></p>
<p class="translated">由于担心法律反弹，一些图像托管平台禁止了人工智能生成的内容。一些法律专家警告说，如果公司无意中将生成性人工智能工具生成的版权内容融入到他们销售的任何产品中，这些工具可能会让公司面临风险。</p><p class="piano-inline-promo"/>
<p class="translated">“不幸的是，我预计几乎所有的生成性人工智能产品都会面临大量诉讼，”开源软件许可方面的法律专家、OSS Capital 的普通合伙人希瑟·米克(Heather Meeker)通过电子邮件告诉 TechCrunch。"著作权法需要澄清."</p>
<p class="translated">波兰艺术家格雷格·鲁特考斯基(Greg Rutkowski)等内容创作者以创作奇幻风景而闻名，他们已经成为抗议生殖人工智能初创公司对待艺术家的运动的代言人。Rutkowski 抱怨说，输入像“拿着剑和发光的魔法火球的巫师与凶猛的龙 Greg Rutkowski 战斗”这样的文本会创建一个看起来与他的原创作品非常相似的图像-威胁到他的收入。</p>
<p class="translated">假设生殖人工智能不会有任何进展，接下来会发生什么？哪些法律案件有价值，哪些法庭斗争即将来临？</p>
<p class="translated">Eliana Torres 是 Nixon Peabody 的一名知识产权律师，她表示，针对 Stability AI、Midjourney 和 DeviantArt 的集体诉讼的指控在法庭上证明是有挑战性的。特别是，她认为很难确定哪些图像用于训练人工智能系统，因为系统生成的艺术不一定与任何训练图像完全一样。</p>
<p class="translated">最先进的图像生成系统，如稳定扩散就是所谓的“扩散”模型。扩散模型在通过大规模训练数据集工作时，学习根据文本提示创建图像(例如，“一只小鸟栖息在窗台上的草图”)。这些模型被训练成“重新创建”图像，而不是从头开始绘制图像，从纯粹的噪声开始，随着时间的推移细化图像，使其逐渐接近文本提示。</p>

<p class="translated">按照托雷斯的观点，完美的娱乐活动不会经常发生。至于特定艺术家风格的图像，风格已经被证明几乎不可能用版权来保护。</p>
<p class="translated"><span>“要让人们普遍接受‘in style of’的定义是‘一件其他人会接受的作品，是那位艺术家创作的作品，他的<em>风格</em>被调用了’，这一点在诉状中有所提及(即针对 Stability AI 等人)，”Torres 在一次电子邮件采访中告诉 TechCrunch。</span></p>
<p class="translated">托雷斯还认为，诉讼不应该针对这些人工智能系统的创造者，而是应该针对负责编译用于训练它们的图像的一方:大型人工智能开放网络(LAION)，一个非营利组织。Midjourney、DeviantArt 和 Stability AI 使用来自 LAION 数据集的训练数据，这些数据集跨越了网络上数十亿张图像。</p>
<p class="translated">“如果 LAION 创建了数据集，那么涉嫌侵权就发生在那个时候，而不是数据集用于训练模型的时候，”Torres 说。“这就像一个人可以走进画廊看画，但不允许拍照一样。”</p>
<p class="translated">像 Stability AI 和 ChatGPT 背后的 OpenAI 这样的公司长期以来一直声称，如果他们的系统是根据许可内容进行训练的，那么“合理使用”可以保护他们。美国法律中的这一原则允许有限使用受版权保护的材料，而无需首先获得权利持有人的许可。</p>
<p class="translated">支持者指出了像作家协会诉谷歌这样的案例，在这些案例中，总部位于纽约的美国第二巡回上诉法院裁定，谷歌在没有许可证的情况下手动扫描数百万本有版权的书籍以创建其图书搜索项目是合理使用。构成合理使用的内容不断受到挑战和修订，但在生成性人工智能领域，这是一个特别未经测试的理论。</p>
<p class="translated">彭博法律最近的一篇<a href="https://web.archive.org/web/20230409033059/https://news.bloomberglaw.com/ip-law/first-ai-art-generator-lawsuits-threaten-future-of-emerging-tech" target="_blank" rel="noopener">文章</a>断言，合理使用辩护的成功将取决于人工智能生成的作品是否被认为<em>具有变革性</em>——换句话说，他们是否以与原作明显不同的方式使用受版权保护的作品。以前的判例法，特别是最高法院 2021 年谷歌诉甲骨文的判决表明，利用收集的数据创作新作品可能具有变革性。在那起案件中，谷歌使用部分 Java SE 代码创建其 Android 操作系统被认为是合理使用。</p>
<p class="translated">有趣的是，其他国家已经发出了对公开内容使用更加宽松的信号——无论是否有版权。例如，英国正计划修改现有法律，允许“出于任何目的”进行文本和数据挖掘，将权力的天平从权利人那里移开，并严重偏向企业和其他商业实体。然而，美国人没有兴趣接受这样的转变，托雷斯不认为这种情况会很快改变——如果有的话。</p>
<p class="translated">Getty 的情况稍微微妙一些。Getty—<span>指出，Torres 还没有提交正式的投诉——必须显示损害，并将其声称的任何侵权行为与具体的图像联系起来。但 Getty 的声明提到，它对经济损失没有兴趣，只是在寻找“新的法律现状”</span></p>
<p class="translated">专注于人工智能的律师事务所 BNH.ai 的创始人之一安德鲁·伯特(Andrew Burt)不同意托雷斯的观点，他认为专注于知识产权问题的人工智能诉讼将“相对简单”在他看来，如果有版权的数据被用于训练人工智能系统——无论是因为知识产权还是隐私限制——这些系统应该也将会受到罚款或其他处罚。</p>
<p class="translated">伯特指出，美国联邦贸易委员会(FTC)已经在追求这条道路，它称之为“<a href="https://web.archive.org/web/20230409033059/https://digiday.com/media/why-the-ftc-is-forcing-tech-firms-to-kill-their-algorithms-along-with-ill-gotten-data/" target="_blank" rel="noopener">算法吐出</a>”，它迫使科技公司杀死有问题的算法以及他们用来训练它们的任何非法数据。在最近的一个例子中，美国联邦贸易委员会利用算法泄露这一补救措施，迫使 Everalbum 删除该公司开发的面部识别算法。Ever album 是一款名为 Ever 的移动应用，现已停产，该算法使用了该应用用户上传的内容。(Everalbum 没有明确表示用户的数据被用于这一目的。)</p>
<p class="translated">“我预计生成式人工智能系统在这方面与传统人工智能系统没有什么不同，”伯特说。</p>
<p class="translated">那么，在缺乏先例和指导的情况下，公司该怎么办呢？托雷斯和伯特一致认为没有明显的答案。</p>
<p class="translated">对她来说，Torres 建议密切关注每个商业生成人工智能系统的使用条款。她指出，Midjourney 对付费和非付费用户有不同的权利，而 OpenAI 的 DALL-E 将生成的艺术作品的权利分配给用户，同时也警告他们“类似的内容”，并鼓励尽职调查以避免侵权。</p>
<p class="translated">“企业应该了解使用条款，并做好尽职调查，例如对旨在用于商业用途的作品进行反向图像搜索，”她补充道。</p>
<p class="translated">Burt 建议公司采用风险管理框架，如美国国家标准与技术研究所发布的人工智能风险管理框架，该框架为如何解决和减轻人工智能系统设计和使用中的风险提供了指导。他还建议公司不断测试和监控他们的系统，以防潜在的法律责任。</p>
<p class="translated">“虽然生成式人工智能系统使人工智能风险管理变得更加困难——公平地说，监控一个对风险进行二元预测的人工智能系统要简单得多——但我们可以采取具体行动，”伯特说。</p>
<p class="translated">一些公司在活动家和内容创作者的压力下，已经朝着正确的方向迈出了步伐。Stability AI 计划允许艺术家选择退出用于训练下一代稳定扩散模型的数据集。通过 HaveIBeenTrained.com 网站，权利持有者将能够在几周后培训开始前请求退出。竞争对手 OpenAI 没有提供这种退出机制，但该公司已经与 Shutterstock 等组织合作，授权他们的部分图库。</p>
<p class="translated">对于 Copilot，GitHub 引入了一个过滤器，可以根据公共 GitHub 代码检查代码建议及其周围约 150 个字符的代码，如果匹配或“近似匹配”，则隐藏建议。这是一个<a href="https://web.archive.org/web/20230409033059/https://techcrunch.com/2022/12/08/github-launches-copilot-for-business-plan-as-legal-questions-remain-unresolved/">不完善的措施</a>——启用过滤器会导致 Copilot 忽略关键的归属和许可文本——但 GitHub 表示，它计划在 2023 年引入额外的功能，旨在帮助开发者就是否使用 Copilot 的建议做出明智的决定。</p>
<p class="translated">从一万英尺的角度来看，伯特认为，在不了解如何解决其危险的情况下，生成性人工智能被越来越多地部署。他赞扬了为解决显而易见的问题所做的努力，比如版权作品被用来培训内容制作者。但他警告说，系统的不透明将对企业造成压力，以防止系统造成严重破坏——并在系统被投入使用前制定计划来解决系统风险。</p>
<p class="translated">“生成性人工智能模型是人工智能最令人兴奋和新颖的用途之一——具有转变‘知识经济’的明显潜力，”他说。“就像人工智能在许多其他领域一样，这项技术在很大程度上已经存在并随时可以使用。尚未成熟的是管理所有风险的方法。如果没有对这些系统的危害进行深思熟虑的、成熟的评估和管理，我们就有可能在了解如何阻止技术造成损害之前部署该技术。"</p>
<p class="translated">Meeker 更悲观，认为不是所有的企业——不管它们采取何种缓解措施——都有能力承担与生殖人工智能相关的法律成本。她说，这表明版权法急需澄清或修改。</p>
<p class="translated">“如果人工智能开发人员不知道他们可以使用什么数据来训练模型，这项技术可能会倒退几年，”米克说。“从某种意义上说，他们无能为力，因为如果企业不能合法地在免费提供的材料上训练模型，他们就没有足够的数据来训练模型。只有各种长期解决方案，如选择加入或选择退出模型，或向所有作者支付版税的系统……针对人工智能企业摄取受版权保护的材料来训练模型的诉讼可能会对行业造成严重损害，[并]可能导致限制创新的整合。”</p>
			</div>

			</div>    
</body>
</html>