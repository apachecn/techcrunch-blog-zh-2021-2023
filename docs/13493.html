<html>
<head>
<title>Try 'Riffusion,' an AI model that composes music by visualizing it | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">试试“Riffusion”，这是一个通过可视化创作音乐的人工智能模型</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/12/15/try-riffusion-an-ai-model-that-composes-music-by-visualizing-it/">https://web.archive.org/web/https://techcrunch.com/2022/12/15/try-riffusion-an-ai-model-that-composes-music-by-visualizing-it/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">人工智能生成的音乐已经是一个足够创新的概念，但 Riffusion 通过一种聪明、怪异的方法将它带到了另一个水平，它使用音频的 T2 图像而不是音频来制作怪异而引人注目的音乐。</p>
<p class="translated">听起来很奇怪，很奇怪。但如果成功了，就成功了。而且确实有效！算是吧。</p>
<p class="translated">扩散是一种用于生成图像的机器学习技术，在过去一年中为人工智能世界提供了动力。DALL-E 2 和 Stable Diffusion 是两个最引人注目的模型，它们通过逐渐用人工智能认为提示应该看起来的样子来取代视觉噪音。</p>
<p class="translated">这种方法在许多情况下被证明是强大的，并且非常容易进行微调，在这种情况下，您可以给大多数训练过的模型大量特定类型的内容，以便使它专门产生该内容的更多示例。例如，你可以在水彩画或汽车照片上对它进行微调，这将证明它在再现这些事物方面更有能力。</p>
<p class="translated">Seth Forsgren 和 Hayk Martiros 为他们的业余爱好项目 Riffusion 所做的是微调光谱图上的稳定扩散。</p>
<p class="translated">“Hayk 和我一起在一个小乐队中演奏，我们开始这个项目只是因为我们热爱音乐，并且不知道稳定扩散是否有可能创建一个足够保真度的频谱图图像来转换成音频，”Forsgren 告诉 TechCrunch。“在前进的每一步，我们都越来越被可能性所打动，一个想法引出下一个想法。”</p>
<p class="translated">你会问，光谱图是什么？它们是音频的视觉表现，显示不同频率的振幅随时间的变化。您可能见过波形，它显示音量随时间的变化，使音频看起来像一系列的山峰和山谷；想象一下，如果不仅仅是总音量，而是显示每个频率的音量，从低端到高端。</p>
<p class="translated">这是我根据一首歌(秘密机器的<a href="https://web.archive.org/web/20230408173940/https://www.youtube.com/watch?v=H0X8lJ31KV8">“马可尼的收音机】，如果你想知道的话)制作的一部分:</a></p>
<p/><div id="attachment_2459404" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2459404" decoding="async" class="size-full wp-image-2459404" src="../Images/b370aa3ce3aa8e8f92e81cab5f6dfb0c.png" alt="" srcset="https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/Marconi2.jpg 805w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/Marconi2.jpg?resize=150,76 150w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/Marconi2.jpg?resize=300,153 300w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/Marconi2.jpg?resize=768,391 768w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/Marconi2.jpg?resize=680,346 680w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/Marconi2.jpg?resize=50,25 50w" sizes="(max-width: 805px) 100vw, 805px" data-original-src="https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/Marconi2.jpg"/><p id="caption-attachment-2459404" class="wp-caption-text translated"><strong>图片来源:</strong>戴文·科迪威</p></div>
<p class="translated">您可以看到随着乐曲的进行，它在所有频率上都变得越来越大，如果您知道要寻找什么，您甚至可以找出单个音符和乐器。无论如何，这个过程本质上并不完美或无损，但它是声音的准确、系统的表现。你可以通过反过来做同样的过程把它转换回声音。</p>
<p class="translated">Forsgren 和 Martiros 制作了一系列音乐的频谱图，并用相关术语标记了结果图像，比如“布鲁斯吉他”、“爵士钢琴”、“非洲吉他”之类的东西。这个集合让它很好地了解了某些声音“看起来”是什么样子，以及它如何重新创建或组合它们。</p>
<p class="translated">如果您在细化图像时对其进行采样，这就是扩散过程的样子:</p>
<p/><div id="attachment_2459448" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2459448" decoding="async" loading="lazy" class="size-full wp-image-2459448" src="../Images/a9e686cc95b366431ba82d4aec650067.png" alt="" data-original-src="https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax.gif"/><p id="caption-attachment-2459448" class="wp-caption-text translated"><strong>图片来源:</strong>塞思·福斯格伦/海克·马提罗斯</p></div>
<p class="translated">事实上，该模型证明能够产生频谱图，当转换为声音时，非常适合“时髦的钢琴”、“爵士萨克斯管”等提示。这里有一个例子:</p>
<p/><div id="attachment_2459450" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2459450" decoding="async" loading="lazy" class="size-full wp-image-2459450" src="../Images/7095e46893a7b67bb84b2b9e3fee1e72.png" alt="" srcset="https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp 512w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp?resize=150,150 150w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp?resize=300,300 300w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp?resize=32,32 32w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp?resize=50,50 50w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp?resize=64,64 64w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp?resize=96,96 96w, https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp?resize=128,128 128w" sizes="(max-width: 512px) 100vw, 512px" data-original-src="https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.webp"/><p id="caption-attachment-2459450" class="wp-caption-text translated"><strong>图片来源:</strong>塞思·福斯格伦/海克·马提罗斯</p></div>
<p class="translated"><audio class="wp-audio-shortcode" id="audio-2459276-1" preload="none" controls="controls">T5<a href="https://web.archive.org/web/20230408173940/https://techcrunch.com/wp-content/uploads/2022/12/funky_sax_to_piano.mp3">https://TechCrunch . com/WP-content/uploads/2022/12/funky _ sax _ to _ piano . MP3</a>T8】</audio></p>
<p class="translated">但是当然，正方形光谱图(512×512 像素，标准稳定扩散分辨率)仅代表一个短剪辑；一首三分钟的歌会是一个宽得多的长方形。没有人想一次听五秒钟的音乐，但他们创造的系统的局限性意味着他们不能创建一个 512 像素高、10000 像素宽的声谱图。</p>
<p class="translated">在尝试了一些事情之后，他们利用了大型模型的基本结构，比如稳定扩散，它有很大的“潜在空间”这有点像定义更明确的节点之间的无人区。就像如果你有一个代表猫的模型区域，另一个代表狗，它们之间的空间是潜在的空间，如果你只是告诉人工智能去画，就会是某种狗，或者猫狗，即使没有这样的东西。</p>
<p class="translated">顺便提一下，<a href="https://web.archive.org/web/20230408173940/https://techcrunch.com/2022/09/13/loab-ai-generated-horror/">潜在空间的东西变得比那个</a>古怪得多:</p>

<p class="translated">不过，Riffusion 项目没有令人毛骨悚然的噩梦世界。相反，他们发现，如果你有两个提示，比如“教堂钟声”和“电子节拍”，你可以一次一点地从一个跳到另一个，它会令人惊讶地逐渐自然地从一个跳到另一个，甚至在节拍上:</p>
<p class="translated"><audio class="wp-audio-shortcode" id="audio-2459276-2" preload="none" controls="controls"><source type="audio/mpeg" src="https://web.archive.org/web/20230408173940im_/https://techcrunch.com/wp-content/uploads/2022/12/church_bells_to_electronic_beats.mp3?_=2"/><a href="https://web.archive.org/web/20230408173940/https://techcrunch.com/wp-content/uploads/2022/12/church_bells_to_electronic_beats.mp3">https://TechCrunch . com/WP-content/uploads/2022/12/church _ bells _ to _ electronic _ beats . MP3</a>T15】</audio></p>
<p class="translated">这是一种奇怪、有趣的声音，尽管显然不是特别复杂或高保真；请记住，他们甚至不确定扩散模型是否能做到这一点，所以这个模型将铃声转变为节拍或将打字机敲击声转变为钢琴和低音的能力是非常了不起的。</p>
<p class="translated">制作更长的片段是可能的，但仍是理论上的:</p>
<p class="translated">“我们还没有真正尝试创作一首经典的 3 分钟歌曲，重复合唱和诗句，”福斯格伦说。“我认为这可以通过一些巧妙的技巧来实现，例如为歌曲结构建立一个较高层次的模型，然后为各个片段使用较低层次的模型。或者，你可以用更大分辨率的完整歌曲图像来深度训练我们的模型。”</p>
<p class="translated">它从这里去哪里？其他团队正试图以各种方式创造人工智能生成的音乐，从使用<a href="https://web.archive.org/web/20230408173940/https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html" target="_blank" rel="noopener">语音合成模型</a>到经过特殊训练的音频模型，如<a href="https://web.archive.org/web/20230408173940/https://techcrunch.com/2022/10/07/ai-music-generator-dance-diffusion/">舞蹈扩散</a>。</p>

<p class="translated">Riffusion 更像是一个“哇，看看这个”的演示，而不是任何一种重塑音乐的宏伟计划，Forsgren 说他和 Martiros 只是很高兴看到人们参与他们的工作，享受乐趣并不断重复:</p>
<p class="translated">“我们可以从这里走向许多方向，我们很高兴能够在这个过程中不断学习。今天早上看到其他人也已经在我们的代码上构建了他们自己的想法，这很有趣。稳定扩散社区的一个令人惊讶的地方是，人们在最初作者无法预测的方向上建立事物的速度有多快。”</p>
<p class="translated">你可以在 Riffusion.com<a href="https://web.archive.org/web/20230408173940/https://www.riffusion.com/" target="_blank" rel="noopener">的现场演示中测试它，但你可能需要等待一段时间来渲染你的剪辑——这比创作者预期的要多一点关注。代码都可以通过 about 页面</a>获得<a href="https://web.archive.org/web/20230408173940/https://www.riffusion.com/about" target="_blank" rel="noopener">，所以如果你有芯片的话，也可以随意运行你自己的代码。</a></p>
			</div>

			</div>    
</body>
</html>