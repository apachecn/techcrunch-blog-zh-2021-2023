<html>
<head>
<title>This co-worker does not exist: FBI warns of deepfakes interviewing for tech jobs • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这位同事并不存在:FBI 警告 deepfakes 面试技术工作</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/06/28/this-coworker-does-not-exist-fbi-warns-of-deepfakes-interviewing-for-tech-jobs/">https://web.archive.org/web/https://techcrunch.com/2022/06/28/this-coworker-does-not-exist-fbi-warns-of-deepfakes-interviewing-for-tech-jobs/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">很多人担心与人工智能竞争工作的前景，但这可能不是他们所期望的。美国联邦调查局警告称，在美国，利用“深度伪造”和窃取的个人信息申请工作的案件有所上升，包括伪造视频面试。不过，现在还不要重新开始<a href="https://web.archive.org/web/20230213014954/https://youtu.be/Umc9ezAyJv0">沃伊特-坎普夫测试</a>。</p>
<p class="translated">向远程工作的转变对许多人来说是一个好消息，但就像方法和期望的任何其他变化一样，这也是骗子的新游乐场。安全标准正在更新，招聘人员也在适应，当然劳动力市场已经足够疯狂，招聘公司和求职者都试图比以往更快地前进。</p>
<p class="translated">在这些持续的变化中，<a href="https://web.archive.org/web/20230213014954/https://www.bleepingcomputer.com/news/security/fbi-stolen-pii-and-deepfakes-used-to-apply-for-remote-tech-jobs/">今天的联邦调查局公共服务公告</a>警告说，deepfakes 再次被用于邪恶的目的——在这种情况下，模仿身份被盗的人来申请工作:</p>
<blockquote><p class="translated">投诉报告了在潜在申请人的在线面试中使用语音欺骗或潜在的语音欺骗。在这些采访中，镜头中被采访者的动作和嘴唇运动与说话者的声音并不完全一致。有时，咳嗽、打喷嚏或其他听觉动作与视觉呈现的不一致。</p></blockquote>
<p class="translated">你可以想象从开始到结束的过程:一个美国公民的执照、姓名、地址和其他重要信息在一些黑客或数据库泄露中被盗。deepfake 可以由任何人创建，只要他有一两张某人的好照片，并用来录制目标说话的假视频，甚至现场直播(结果好坏参半，正如我们所见)。结合看似合法的申请数据，这很可能足以让一个匆忙的招聘经理签下一个新的承包商。</p>
<p class="translated">为什么？有很多原因。也许黑客不能在美国工作，但希望以美元支付报酬。也许他们想访问只有该公司员工才能看到的数据。也许这只是一次测试，以开发更大规模的工具，并获得更大的可销售数据缓存。正如 FBI 所写:“……一些报告的位置包括访问客户 PII、财务数据、公司 IT 数据库和/或专有信息。”</p>
<p class="translated">它甚至可能是一个民族国家的情报或资助行动；人们已经观察到朝鲜使用伪造的证件来获得美国的工作，<a href="https://web.archive.org/web/20230213014954/https://techcrunch.com/2022/04/19/north-korea-blockchain-crypto/">特别是在加密货币领域</a>，在这个领域，大量的盗窃行为几乎不会引起任何反响。</p>

<p class="translated">这种事情已经不是第一次被报道了。假员工和假同事的轶事已经流传多年，当然，用假身份工作是书中最古老的伎俩之一。这里的转折是使用人工智能支持的图像来通过面试过程。</p>
<p class="translated">幸运的是，质量不是特别有说服力…目前来说。虽然 deepfakes 在某些方面已经变得非常好，但它们与真实的东西相去甚远，人类非常擅长识别这种东西。拥有 10 秒钟不间断的视频而不引起观众眯起眼睛已经够难了——假设采访者在注意，用当前的工具进行半小时的现场对话似乎是不可能的。</p>
<p class="translated">令人失望的是，联邦调查局没有包括任何明显的避免这种骗局的最佳做法，但它指出，背景调查已经确定了被盗的 PII，人们报告了他们的身份，地址，电子邮件等。在他们不知情的情况下被利用。</p>
<p class="translated">事实是任何人对此都无能为力。身份被盗的人只能保持警惕，注意可疑的事情，如奇怪的电子邮件和电话。小企业不太可能成为目标，因为除了工资，它们没有太多价值。企业可能有相当繁琐的招聘流程，包括传统的背景调查。</p>
<p class="translated">如果有什么不同的话，那可能是初创公司和 SaaS 公司面临的风险最大:可能有大量数据或对数据的访问，但与它们所服务或试图取代的企业相比，安全基础设施相对较少。这也适用于雇佣他们来提高你的安全性——创业公司经常被黑客攻击！这似乎是一种成人仪式。</p>
<p class="translated">要求你的受访者拿起今天的报纸可能有点过分(申请远程 It 工作的人不太可能得到一份报纸)，但如果你在潜在的高风险部门招聘，如安全、医疗技术等，可能就要多一点小心了。使用强加密、现代访问控制并听取安全专家的意见。别说联邦调查局没警告你。</p>

			</div>

			</div>    
</body>
</html>