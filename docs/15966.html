<html>
<head>
<title>With Evals, OpenAI hopes to crowdsource AI model testing | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenAI 希望通过 Evals 众包人工智能模型测试</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/14/with-evals-openai-hopes-to-crowdsource-ai-model-testing/">https://web.archive.org/web/https://techcrunch.com/2023/03/14/with-evals-openai-hopes-to-crowdsource-ai-model-testing/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">OpenAI 希望通过 Evals 来众包人工智能模型测试</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">除了 GPT 4 号，OpenAI 还开源了一个软件框架来评估其人工智能模型的性能。名为<a href="https://web.archive.org/web/20230408182348/https://github.com/openai/evals" target="_blank" rel="noopener"> Evals </a>的 OpenAI 表示，该工具将允许任何人报告其模型中的缺点，以帮助指导改进。</p>
<p class="translated">OpenAI 在<a href="https://web.archive.org/web/20230408182348/https://openai.com/research/gpt-4" target="_blank" rel="noopener">的博客文章</a>中解释道，这是一种众包模型测试方法。</p>
<p class="translated">“我们使用评估来指导我们模型的开发(识别缺点和防止回归)，我们的用户可以应用它来跟踪模型版本的性能和发展产品集成，”OpenAI 写道。“我们希望 Evals 成为分享和众包基准的工具，代表最大范围的故障模式和困难任务。”</p>
<p class="translated">OpenAI 创建了 Evals 来开发和运行用于评估 GPT-4 等模型的基准，同时检查它们的性能。通过 Evals，开发人员可以使用数据集来生成提示，测量 OpenAI 模型提供的完成质量，并比较不同数据集和模型的性能。</p>
<p class="translated">Evals 兼容几种流行的 AI 基准测试，也支持编写新的类来实现定制的评估逻辑。作为一个例子，OpenAI 创建了一个逻辑谜题评估，其中包含 10 个 GPT-4 失败的提示。</p>
<p class="translated">很不幸，这都是无偿的工作。但为了激励 Evals 的使用，OpenAI 计划向那些贡献“高质量”基准的人授予 GPT-4 访问权。</p>
<p class="translated">该公司写道:“我们相信，评估将成为使用和构建我们模型的过程中不可或缺的一部分，我们欢迎直接的贡献、问题和反馈。”</p><p class="piano-inline-promo"/>
<p class="translated">有了 Evals，open AI——最近<a href="https://web.archive.org/web/20230408182348/https://techcrunch.com/2023/03/01/addressing-criticism-openai-will-no-longer-use-customer-data-to-train-its-models-by-default/">表示</a>它将在默认情况下停止使用客户数据来训练它的模型——正在跟随其他人的脚步，这些人已经转向众包来获得鲁棒的人工智能模型。</p>
<p class="translated">2017 年，马里兰大学的计算语言学和信息处理实验室推出了一个名为 Break It，Build It 的平台，让研究人员向用户提交模型，用户的任务是想出击败它们的例子。Meta 还维护着一个名为 Dynabench 的平台，该平台拥有用户“傻瓜”模型，旨在分析情绪、回答问题、检测仇恨言论等。</p>
			</div>

			</div>    
</body>
</html>