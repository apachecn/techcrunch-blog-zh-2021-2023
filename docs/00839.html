<html>
<head>
<title>TikTok updates Safety Center resources following research on harmful challenges | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">抖音根据对有害挑战的研究更新安全中心资源</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/11/17/tiktok-updates-safety-center-resources-following-internal-research-on-harmful-challenges/">https://web.archive.org/web/https://techcrunch.com/2021/11/17/tiktok-updates-safety-center-resources-following-internal-research-on-harmful-challenges/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">抖音因在其应用程序上举办危险的病毒“挑战”而声名狼藉，在最糟糕的情况下，这些挑战已经导致了严重的伤害或死亡——就像停电挑战一样，这促使意大利监管机构<a href="https://web.archive.org/web/20230404005247/https://techcrunch.com/2021/01/25/tiktok-has-until-friday-to-respond-to-italys-order-to-block-users-it-cant-age-verify-after-girls-death/">今年对社交网络</a>采取行动，<a href="https://web.archive.org/web/20230404005247/https://techcrunch.com/2021/05/12/tiktok-removes-500k-accounts-in-italy-after-dpa-order-to-block-underage-users/">删除未成年用户</a>。最近，该应用因鼓励学生<a href="https://web.archive.org/web/20230404005247/https://www.usatoday.com/story/news/nation/2021/10/08/slap-teacher-tiktok-challenge-condemned-tiktok-and-schools/6048654001/" target="_blank" rel="noopener">打老师</a>和<a href="https://web.archive.org/web/20230404005247/https://techcrunch.com/2021/09/15/tiktok-devious-licks/">破坏学校财产</a>的挑战而成为头条新闻。随着进一步监管的潜在威胁的出现，抖音今天分享了其对病毒挑战和恶作剧的研究结果，以及如何采取行动。</p>
<p class="translated">迄今为止，抖音经常试图淡化其在病毒挑战中的参与。</p>
<p class="translated">例如，10 月，<a href="https://web.archive.org/web/20230404005247/https://twitter.com/TikTokComms/status/1445813823198220295?s=20" target="_blank" rel="noopener">抖音否认</a>“打老师”是抖音的一种趋势。在一名儿童因尝试停电挑战而死亡后，抖音发布了一份声明，称该公司没有发现任何证据表明其平台上存在任何涉及窒息的挑战。在最近的一次参议院听证会上，该公司再次重申了这一主张。但是参议员 Blackburn (R-TN)告诉抖音的代表，她的工作人员已经发现了“传递视频”，以及其他令人不安的内容。</p>
<p class="translated">今天，抖音发布了其委托进行的有害挑战和骗局研究的结果。</p>
<p class="translated">该公司表示，几个月前它启动了一个关于这一主题的全球项目，其中包括对来自阿根廷、澳大利亚、巴西、德国、意大利、印度尼西亚、墨西哥、英国、美国和越南的 1 万多名青少年、家长和教师的调查。它还委托一个独立的保护机构 Praesidio guarantings 编写一份报告，详细说明调查结果及其建议。另外，一个由 12 名主要青少年安全专家组成的小组被要求审查该报告并提供他们自己的意见。最后，抖音与专门研究青少年健康发展的临床儿童精神病学家理查德·格拉翰博士和专门研究青少年风险预防的行为科学家格雷琴·布里翁-梅瑟尔斯博士合作，提供进一步的指导。</p>
<p class="translated">该报告发现的数据值得研究，因为它说明了社交媒体如何成为有害内容的滋生地，如这些病毒式挑战，因为年轻人如何大量使用社交平台。年轻人有更大的风险偏好，这是由于他们在心理发展方面所处的位置。</p>
<p class="translated">正如格雷厄姆博士解释的那样，青春期是一个特殊的时期，为孩子过渡到成人生活做准备。他说，这是一个“大脑大规模发展”的时代。</p><p class="piano-inline-promo"/>
<p class="translated">他解释说:“现在人们非常关注理解为什么青少年会做他们所做的事情——因为这些判断中心正在被再次修正，为未来更复杂的决策和思考做准备。”</p>
<p class="translated">格雷厄姆博士说，年轻人的大脑在抽象思维、识别更复杂的心理和情绪状态以及更复杂的人际关系考虑方面正在发展。随着这一切的进行，他们想了解周围世界的愿望增加了——有时，这可能包括参与更危险的活动、测试自己或赢得同行认可的愿望。有时候这些“危险”的活动相对无害，比如看恐怖电影或者坐过山车。但在其他时候，青少年和其他年轻人可能会选择从事他们认为会在某种程度上真正拓展他们的东西，这吸引他们去迎接更危险的挑战。</p>
<p class="translated">“有时他们会…贪多嚼不烂，至少在短期内会有某种程度的创伤，但[青少年]的愿望是成长，”他指出。</p>
<p class="translated">此外，一般来说，病毒式挑战可以吸引青少年对朋友和同龄人认可的渴望，因为它们会产生喜欢和观点。但是青少年评估挑战是否安全的方法有缺陷——他们倾向于看更多的视频或向朋友寻求建议。与此同时，家长和老师往往不愿谈论挑战和恶作剧，因为害怕引起更多的兴趣。</p>
<p class="translated">研究发现，大多数青少年没有参与最危险的挑战。只有 21%的全球青少年参加了挑战，只有 2%参加了那些被认为有风险的活动。更少的 0.3%参加过他们认为“非常危险”的挑战。大多数人认为参与挑战要么是中立的(54%)，要么是积极的(34%)，而不是消极的(11%)。64%的人说参与对他们的友谊和关系有积极的影响。</p>
<p class="translated">这项研究还检验了恶作剧挑战——像蓝鲸和 T2 摩摩传播一种信念，即有一个坏演员指导孩子们从事有害的活动，最终导致自残或自杀。61%的青少年表示，当他们遇到恶作剧时，他们会搜索更多关于恶作剧的信息，试图验证它们是否真实，但很多困惑往往围绕着恶作剧。青少年怀疑转发恶作剧的人是出于喜欢和观点(62%的人相信这一点)或者因为他们认为恶作剧是真实的(60%的人相信这一点)。46%接触恶作剧的青少年寻求支持或建议，这表明青少年将从帮助他们理解恶作剧材料的资源中受益。</p>
<p class="translated">虽然研究表明，社交媒体平台在解决用户安全相关问题方面还有很多工作要做，但抖音在这方面的回应相当少。</p>
<p class="translated">该公司今天宣布，它将在其安全中心<a href="https://web.archive.org/web/20230404005247/https://www.tiktok.com/safety/en-us/online-challenges/" target="_blank" rel="noopener">增加一个专门处理挑战和恶作剧的新部分</a>，并根据研究人员的建议，修改当人们搜索与自杀或自残有关的恶作剧时出现的警告标签中的一些语言。</p>
<p class="translated">考虑到这些变化的相对较小的性质——本质上是一个帮助文档和一些修改的文本——有趣的是，在今天的宣布之前，抖音在周一向媒体直播了一个小时的研究演示，并通过电子邮件向记者发送了完整的 38 页研究报告。通过这样做，抖音似乎想与脸书区别开来，在，致命的内部研究一直保持沉默，直到告密者 Frances Haugen 拿出数千份文件，表明脸书知道它的问题，却没有采取行动。</p>
<p class="translated">抖音希望被视为有意义地参与了研究过程，但最终，它所做的改变并没有解决问题。归根结底，有害内容是一个适度的挑战，也是一个源于社交媒体本身性质的问题。消除有害内容需要一个从头开始设计的系统，而不是用令人震惊或令人愤慨的内容来换取喜欢和观点。大多数社交媒体并不是这样建立的。</p>
<p class="translated">此外，抖音表示，它将寻找与标签相关的违规内容的突然增加，包括潜在的危险行为。</p>
<p class="translated">例如，如果像#FoodChallenge 这样的标签(通常用于分享食物食谱和烹饪灵感)开始看到更多内容违反抖音政策的峰值，那么审核团队就会收到警报，寻找这种峰值的原因，以便他们可以采取行动。</p>
<p class="translated">或者，换句话说，抖音表示，它现在将更好地调节内容——用户认为该公司无论如何都在这么做。</p>
<p class="translated">完整的研究报告如下。</p>
<p class="translated"><a title="View Praesidio Report - Exploring Effective Prevention Education Responses to Dangerous Online Challenges on Scribd" href="https://web.archive.org/web/20230404005247/https://www.scribd.com/document/540171524/Praesidio-Report-Exploring-Effective-Prevention-Education-Responses-to-Dangerous-Online-Challenges#from_embed" target="_blank" rel="noopener"> Praesidio 报告——探索应对危险在线挑战的有效预防教育对策</a>,作者:Scribd 上的<a title="View TechCrunch's profile on Scribd" href="https://web.archive.org/web/20230404005247/https://www.scribd.com/publisher/17551504/TechCrunch#from_embed"> TechCrunch </a></p>
<p/>
			</div>

			</div>    
</body>
</html>