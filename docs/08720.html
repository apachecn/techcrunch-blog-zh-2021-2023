<html>
<head>
<title>Facebook fails to detect calls for violence in Kenya</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书未能察觉肯尼亚的暴力呼声</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/07/29/facebook-risks-ban-in-kenya-for-failing-to-stop-hate-speech/">https://web.archive.org/web/https://techcrunch.com/2022/07/29/facebook-risks-ban-in-kenya-for-failing-to-stop-hate-speech/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated"><strong>更新于美国东部时间 7 月 30 日上午 9:30</strong>:<em>肯尼亚 ICT 内阁部长<a href="https://web.archive.org/web/20221024182049/https://twitter.com/mucheru/status/1553271302005334016">表示</a>肯尼亚没有关闭互联网或禁止脸书的计划。然而，他没有透露政府如何应对社交网站上仇恨言论的传播。</em></p>
<p class="translated">肯尼亚的民族团结监督机构，国家团结和融合委员会(NCIC)已经指示脸书在七天内停止在其平台上传播仇恨言论，否则将面临在这个东非国家的暂停。</p>
<p class="translated">监督机构是对一份由倡导组织全球见证和一家合法的非盈利公司 Foxglove 发布的报告做出反应，该报告指出脸书没有能力检测仇恨言论广告。这发生在该国全国大选临近之际。</p>
<p class="translated">全球证人报告证实了 NCIC 自己的调查结果，即脸书的母公司 Meta 在删除和阻止仇恨内容方面行动迟缓，加剧了本已动荡的政治环境。NCIC 现在呼吁 Meta 在选举之前、期间和之后加强节制，同时给它一周的时间遵守规定，否则将在该国被禁止。</p>
<p class="translated">NCIC 成立于 2007 年导致 1300 名肯尼亚人死亡的选举后暴力事件之后，其任务之一是就针对实施和延续仇恨言论的实体或个人的补救行动提出建议。几个月前，它禁止使用一些据说会加剧种族紧张的编码词。</p>

<p class="translated">“脸书违反了我们国家的法律。他们让自己成为仇恨言论和煽动、错误信息和虚假信息的载体，”<a href="https://web.archive.org/web/20221024182049/https://www.reuters.com/world/africa/kenyas-cohesion-watchdog-gives-meta-7-days-comply-with-regulations-2022-07-29/" target="_blank" rel="noopener">NCIC 专员丹瓦斯·马科里说。</a></p><p class="piano-inline-promo"/>
<p class="translated">全球见证组织和毛地黄组织还呼吁 Meta 停止政治广告，并使用“打破玻璃”措施，即在 2020 年美国大选期间用来阻止错误信息和民间动乱的更严格的紧急节制方法。</p>
<p class="translated">在肯尼亚，脸书的渗透率为 82%，是仅次于 WhatsApp 的第二大社交网络。</p>
<h2 class="translated">脸书的人工智能模型未能检测到暴力呼吁</h2>
<p class="translated">为了测试脸书声称其人工智能模型可以检测仇恨言论，Global Witness 用英语和斯瓦希里语提交了 20 个呼吁暴力和斩首的广告，除了一个以外，所有广告都获得了批准。人权组织称，他们使用广告是因为，与帖子不同，广告经过了更严格的审查和审核过程。他们也可以在上线前撤下广告。</p>
<p class="translated">“我们提交的所有广告都违反了脸书的社区标准，属于仇恨言论和基于种族的暴力号召。“演讲的大部分是非人性化的，将特定的部落群体比作动物，呼吁强奸、屠杀和斩首，”全球见证组织在一份声明中说。</p>
<p class="translated">根据调查结果，全球见证组织的数字威胁民主运动的领导人艾娃·李说，“脸书有能力建立或破坏民主，但我们一次又一次地看到该公司将利润置于人之上。”</p>
<p class="translated">“我们震惊地发现，即使在肯尼亚选举前声称改善其制度和增加资源后，它仍然批准公开呼吁种族暴力。这不是一次性的。过去几个月，我们在缅甸和埃塞俄比亚也看到了同样的无法正常运转的情况。脸书在肯尼亚选举以及从巴西到美国中期选举等世界各地即将到来的选举中不作为的可能后果是可怕的。”</p>

<p class="translated">在其他措施中，全球见证组织呼吁脸书在内容审核上加倍努力。</p>
<p class="translated">作为回应，这家社交媒体巨头表示，它正在对人员和技术进行投资，以阻止错误信息和有害内容。</p>
<p class="translated">它说它已经“雇佣了更多的内容审查员来审查超过 70 种语言的应用程序内容，包括斯瓦希里语。”在截至 4 月 30 日的 6 个月里，该公司报告删除了超过 3.7 万条违反仇恨言论政策的内容，另有 4.2 万条内容涉及在脸书和 Instagram 上宣扬暴力和煽动。</p>
<p class="translated">Meta 告诉 TechCrunch，它也在与选举委员会和民间社会组织等公民利益相关者密切合作，以了解“脸书和 Instagram 如何成为公民参与的积极工具，以及他们在使用我们的平台时可以采取哪些措施来保持安全。”</p>
<p class="translated">其他社交网络，如 Twitter 和最近的抖音，也因没有在调节内容和阻止仇恨言论传播方面发挥更积极的作用而受到关注，仇恨言论被认为加剧了该国的政治紧张局势。</p>
<p class="translated">就在上个月，Mozilla 基金会的一项研究发现抖音在肯尼亚散布虚假信息。Mozilla 在审查了 130 个高收视率的视频后得出了这一结论，这些视频分享了充满仇恨言论、煽动和政治虚假信息的内容——这与抖音反对仇恨言论和分享歧视性、煽动性和合成内容的政策相矛盾。</p>
<p class="translated">在抖音的案例中，Mozilla 得出结论，内容管理者不熟悉该国的政治背景是一些煽动性帖子没有被删除的主要原因之一，这使得虚假信息在社交应用上传播。</p>
<p class="translated">人们呼吁社交媒体平台采取更严格的措施，因为在 8 月 9 日投票之前，政界人士和公民的激烈政治讨论、不同观点和公开仇恨言论都有所增加。</p>

			</div>

			</div>    
</body>
</html>