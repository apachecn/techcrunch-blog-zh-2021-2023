<html>
<head>
<title>Ethicists fire back at 'AI Pause' letter they say 'ignores the actual harms' | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">伦理学家对“人工智能暂停”信进行了反击，称其“忽略了实际危害”</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/31/ethicists-fire-back-at-ai-pause-letter-they-say-ignores-the-actual-harms/">https://web.archive.org/web/https://techcrunch.com/2023/03/31/ethicists-fire-back-at-ai-pause-letter-they-say-ignores-the-actual-harms/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">一群著名的人工智能伦理学家对本周的一封有争议的信写了一封反驳信，要求人工智能开发“暂停”六个月，批评它专注于假设的未来威胁，而真正的伤害是由于今天对技术的滥用。</p>
<p class="translated">成千上万的人，包括史蒂夫·沃兹尼亚克和埃隆·马斯克这些熟悉的名字，<a href="https://web.archive.org/web/20230409033106/https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/">在本周早些时候签署了未来生命研究所的公开信，</a>提议应该暂停开发像 GPT-4 这样的人工智能模型，以避免“我们的文明失控”，以及其他威胁。</p>
<p class="translated">蒂姆尼特·格布鲁、艾米丽·m·本德、安吉丽娜·麦克米兰-梅杰和玛格丽特·米歇尔都是人工智能和伦理学领域的重要人物，他们因在一篇批评人工智能能力的<a href="https://web.archive.org/web/20230409033106/https://dl.acm.org/doi/abs/10.1145/3442188.3445922" target="_blank" rel="noopener">论文</a>中被赶出谷歌而闻名(除了他们的工作之外)。他们目前在 T4 DAIR 研究所合作，这是一个新的研究机构，旨在研究、揭露和预防与人工智能相关的危害。</p>
<p class="translated">但是他们并没有出现在签名者的名单上，现在<a href="https://web.archive.org/web/20230409033106/https://www.dair-institute.org/blog/letter-statement-March2023" target="_blank" rel="noopener">发表了一篇谴责</a>指出这封信没有解决由技术引起的现存问题。</p>
<p class="translated">“这些假设的风险是一种叫做长期主义的危险意识形态的焦点，这种意识形态忽视了今天部署人工智能系统带来的实际危害，”他们写道，引用了工人剥削、数据窃取、支撑现有权力结构的合成媒体以及这些权力结构进一步集中在少数人手里。</p>
<p class="translated">当我们同时有像 Clearview AI <a href="https://web.archive.org/web/20230409033106/https://www.nytimes.com/2023/03/31/technology/facial-recognition-false-arrests.html" target="_blank" rel="noopener">这样的公司被警方用来陷害一个无辜的人的报道时，担心终结者或黑客帝国式的机器人末日的选择是在转移注意力。当你通过网上的橡皮图章授权工厂在每个前门上都安装了环形摄像头时，就不需要 T-1000 了。</a></p>

<p class="translated">虽然 DAIR 的工作人员同意这封信的一些目的，如识别合成媒体，但他们强调，现在必须采取行动，解决今天的问题，我们有可用的补救措施:</p>
<blockquote><p class="translated">我们需要的是加强透明度的监管。不仅当我们遇到合成媒体时应该总是清楚的，而且还应该要求构建这些系统的组织记录和公开训练数据和模型架构。创建可安全使用的工具的责任应该由构建和部署生殖系统的公司承担，这意味着这些系统的构建者应该对其产品产生的输出负责。</p>
<p class="TextBlock__paragraph body translated">当前这场走向更大规模“人工智能实验”的竞赛并不是一条注定的道路，在这条道路上，我们唯一的选择是跑多快，而是一系列由利润动机驱动的决定。公司的行为和选择必须由保护人们权利和利益的法规来决定。</p>
<p class="TextBlock__paragraph body translated">确实是时候行动了:但我们关注的焦点不应该是想象中的“强大的数字思维”。相反，我们应该关注那些声称建造它们的公司的非常真实和非常现实的剥削做法，这些公司正在迅速集中权力，加剧社会不平等。</p>
</blockquote>
<p class="translated">顺便说一句，这封信呼应了我从 Uncharted Power 创始人杰西卡·马修斯(Jessica Matthews)那里听到的一个观点:“你不应该害怕人工智能。你应该害怕建造它的人。”(她的解决方案是:成为建造它的人。)</p>
<p class="translated">虽然几乎不可能有任何大公司会同意根据公开信暂停研究工作，但从它收到的参与度来看，很明显，人工智能的风险——真实的和假设的——是社会许多部门非常关注的问题。但是如果他们不做，也许有人会替他们做。</p>
			</div>

			</div>    
</body>
</html>