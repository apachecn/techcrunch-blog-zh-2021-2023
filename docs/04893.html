<html>
<head>
<title>Twelve Labs makes searching inside videos simple and powerful, propelled by $5M seed round | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">12 个实验室让视频内部搜索变得简单而强大，由 500 万美元的种子资金推动| TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/03/16/twelve-labs-makes-searching-inside-videos-simple-and-powerful-propelled-by-5m-seed-round/">https://web.archive.org/web/https://techcrunch.com/2022/03/16/twelve-labs-makes-searching-inside-videos-simple-and-powerful-propelled-by-5m-seed-round/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">随着视频在我们日常交互和创建的媒体中越来越多，对这些内容进行跟踪和索引的需求也越来越大。我在什么会议或研讨会上问了这个问题？哪个讲座有关于税收政策的部分？<a href="https://web.archive.org/web/20230309103830/https://twelvelabs.io/" target="_blank" rel="noopener"> Twelve Labs </a>有一个用于总结和搜索视频的机器学习解决方案，可以让消费者和创作者更快更容易地工作。</p>
<p class="translated">这家初创公司提供的功能是能够输入一个复杂而模糊的查询，如“考特尼唱国歌的办公室聚会”，并立即获得不仅是视频，还有视频中发生的时刻。“视频的 Ctrl-F”是他们的说法。(那是我们 MAC 上的朋友用的 command-F。)</p>
<p class="translated">你可能会想“但是等等，我现在就可以搜索视频！”是的，在 YouTube 或大学档案馆，你经常可以找到你想要的视频。但是接下来会发生什么呢？你在视频中寻找你要找的部分，或者在文字记录中滚动，试图想出他们表达某件事的确切方式。</p>
<p class="translated">这是因为当你搜索视频时，你实际上是在搜索标签、描述和其他可以轻松添加的基本元素。有一些算法魔术来浮现你想要的视频，但系统并不真正理解视频本身。</p>
<p class="translated">“这个行业过度简化了这个问题，认为标签可以解决搜索，”十二实验室创始人兼首席执行官 Jae Lee 说。许多解决方案现在确实依赖于，例如，识别视频的一些帧包含猫，所以它添加标签#cats。“但是视频不仅仅是一系列图像，它还是复杂的数据。我们知道我们需要建立一个新的神经网络，它可以接受视觉和听觉，并围绕它形成上下文；这叫做多模态理解。”</p>
<p class="translated">这是目前人工智能中的一个热门短语，因为当人工智能系统狭隘地专注于一种“感觉”，如音频或静止图像时，它对世界的理解程度似乎达到了极限。例如，脸书最近发现，它需要一个同时关注<a href="https://web.archive.org/web/20230309103830/https://techcrunch.com/2020/05/12/facebook-upgrades-its-ai-to-better-tackle-covid-19-misinformation-and-hate-speech/">帖子中的图像和文本的人工智能</a>，以检测错误信息和仇恨言论。</p>
<p class="translated">对于视频，如果你只看单个的画面，并试图将它们与有时间戳的文字记录联系起来，你的理解将会受到限制。当人们观看视频时，他们会自然地将视频和音频信息融合到人物角色、动作、意图、因果、交互和其他更复杂的概念中。</p>
<p class="translated">12 个实验室声称已经用他们的视频理解系统沿着这些路线建立了一些东西。Lee 解释说，人工智能被训练成从多模态的角度来处理视频，从一开始就将音频和视频联系起来，并创建他们所说的对它的更丰富的理解。</p>
<p/><div id="attachment_2285040" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230309103830/https://techcrunch.com/wp-content/uploads/2022/03/twelvelabs1.gif"><img aria-describedby="caption-attachment-2285040" decoding="async" class="size-full wp-image-2285040" src="../Images/35419434e2f8538262c301f4bf7b0b00.png" alt="" data-original-src="https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/twelvelabs1.gif"/></a><p id="caption-attachment-2285040" class="wp-caption-text translated">展示视频数据库查询示例的动画。<strong>图片来源:</strong>十二个实验室</p></div>
<p class="translated">“我们包括更复杂的信息，如框架中项目之间的关系，连接过去和现在，这使得复杂的查询成为可能，”他说。“举个例子，如果有一个 YouTuber，他们搜索‘野兽先生挑战乔伊·切斯特纳特吃汉堡’，它会理解挑战某人和谈论挑战的概念。”</p>
<p class="translated">当然，野兽先生——一个专业人士——可能已经把那个特定的数据放在标题或标签里了，但是如果它只是一个常规 vlog 或一系列挑战的一部分呢？如果那天野兽先生很累，没有正确填写所有元数据怎么办？如果有一打或一千个汉堡挑战，而视频搜索无法区分乔伊·切斯纳特和乔西·艾克伦，该怎么办？只要你对内容的理解是肤浅的，就有很多方法会让你失败。如果你是一家希望让 10，000 个视频可供搜索的公司，你会想要比现有的更好的东西，而且劳动强度更低。</p>
<p class="translated"><a href="https://web.archive.org/web/20230309103830/https://docs.twelvelabs.io/">十二实验室将其工具内置于一个简单的 API </a>中，可以调用它来索引一个视频(或一千个)并生成丰富的摘要，并将其连接到一个选定的图表。因此，如果你记录下全体会议或技能分享研讨会或每周头脑风暴会议，这些会议不仅可以根据时间或与会者进行搜索，还可以根据谁在什么时候发言、谈论什么，以及包括绘制图表或放映幻灯片等其他行为进行搜索。</p>
<p class="translated">“我们已经看到拥有大量组织数据的公司对找出首席执行官何时谈论或提出某个概念感兴趣，”Lee 说。“我们一直在非常认真地与人们合作，收集数据点和有趣的使用案例，我们看到了很多这样的案例。”</p><p class="piano-inline-promo"/>
<p/><div id="attachment_2285536" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230309103830/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png"><img aria-describedby="caption-attachment-2285536" decoding="async" loading="lazy" class="size-full wp-image-2285536" src="../Images/b7cff69580459442622c56b6b11e7010.png" alt="Simulation of a Twelve Labs search within videos." srcset="https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png 1324w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png?resize=150,120 150w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png?resize=300,240 300w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png?resize=768,614 768w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png?resize=680,543 680w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png?resize=1200,959 1200w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png?resize=50,40 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/Search_Simple_Sports.png"/></a><p id="caption-attachment-2285536" class="wp-caption-text translated"><strong>图片来源:</strong>十二实验室</p></div>
<p class="translated">为搜索而处理视频的一个副作用，以及理解视频中发生的事情，是生成摘要和字幕的能力。这是另一个可以改进的领域。当然，自动生成的字幕在质量上千差万别，搜索它们的能力、将它们与视频中的人物和场景联系起来的能力以及其他更复杂的能力也是如此。摘要是一个到处都在兴起的领域，这不仅仅是因为没有人有足够的时间观看所有内容，还因为高水平的摘要对于从可访问性到存档目的的所有事情都是有价值的。</p>
<p class="translated">重要的是，可以对 API 进行微调，以更好地处理它所处理的语料库。例如，如果有很多行话或一些不熟悉的情况，它可以被训练得像在更常见的情况下一样工作，如会议室和标准的商业对话(无论那是什么)。这还是在你开始涉足大学讲座、安全录像、烹饪等事情之前</p>
<p/><div id="attachment_2285095" class="wp-caption aligncenter"><a href="https://web.archive.org/web/20230309103830/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png"><img aria-describedby="caption-attachment-2285095" decoding="async" loading="lazy" class="size-full wp-image-2285095" src="../Images/c968222cbfdceac14bce08a5b404f77c.png" alt="" srcset="https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png 1272w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=150,86 150w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=300,172 300w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=768,441 768w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=680,391 680w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=1200,690 1200w, https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png?resize=50,29 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230309103830im_/https://techcrunch.com/wp-content/uploads/2022/03/TwelveLabs_Finetune-API1.png"/></a><p id="caption-attachment-2285095" class="wp-caption-text translated">API 模型，用于微调模型，以便更好地处理沙拉相关内容。<strong>图片来源:</strong>十二个实验室</p></div>
<p class="translated">就这一点而言，该公司非常支持机器学习的“大网络”风格。制造一个能够理解如此复杂的数据并产生如此多种结果的人工智能模型意味着它是一个需要训练和部署的大型计算密集型模型。但这正是解决这个问题所需要的，李说。</p>
<p class="translated">“我们非常相信大型神经网络，但我们不只是增加参数大小，”他说。“它仍然有数十亿个参数，但我们已经做了大量的技术功夫来提高它的效率。我们做的事情就像不要看每一帧——光算法识别重要的帧，诸如此类。在语言理解和多模态空间方面，还有很多科学有待研究。但一个大型网络的目的是了解输入其中的数据的统计表示，这是我们深信不疑的概念。”</p>
<p class="translated">虽然十二实验室希望帮助索引那里的大部分视频，但作为用户的你可能不会意识到这一点；除了一个开发者游乐场，没有任何十二实验室网络平台可以让你搜索东西。该 API 旨在集成到现有的技术堆栈中，以便无论你通常在哪里搜索视频，你都仍然会这样做，但结果会更好。(他们已经在基准测试中证明了这一点，在基准测试中，API 抽其他模型。)</p>
<p class="translated">尽管可以肯定的是，谷歌、网飞和亚马逊等公司正在研究这种视频理解模式，但李开复似乎并不介意。“如果历史可以作为参考，在像 YouTube 和抖音这样的大公司，搜索是非常特定于他们的平台的，也是他们业务的核心，”他说。“我们并不担心他们会窃取自己的核心技术并提供给潜在客户。我们的大部分 beta 合作伙伴都尝试过这些大公司的所谓解决方案，然后来找我们。"</p>
<p class="translated">该公司已经筹集了 500 万美元的种子资金，将其从测试版推向市场；Index Ventures 领投，Radical Ventures、Expa 和 Techstars Seattle 参与，加上天使投资人，包括斯坦福大学的人工智能领导者费-李非、Scale 人工智能首席执行官王敬实、Patreon 首席执行官杰克·康特和 AI2 的柳文欢·埃齐奥尼。</p>
<p class="translated">从这里开始的计划是构建对测试版合作伙伴最有用的特性，然后在不久的将来作为开放服务推出。</p>
			</div>

			</div>    
</body>
</html>