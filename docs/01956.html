<html>
<head>
<title>MVP versus EVP: Is it time to introduce ethics into the agile startup model? • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MVP 与 EVP:是时候将伦理引入敏捷创业模型了吗？TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/01/05/mvp-versus-evp-is-it-time-to-introduce-ethics-into-the-agile-startup-model/">https://web.archive.org/web/https://techcrunch.com/2022/01/05/mvp-versus-evp-is-it-time-to-introduce-ethics-into-the-agile-startup-model/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">创业公司的火箭轨迹是众所周知的:获得一个想法，建立一个团队，然后拼凑一个最小可行产品(MVP)，你可以在用户面前得到它。</p>
<p class="translated">然而，随着人工智能(AI)和机器学习(ML)在科技产品中变得无处不在，以及市场越来越意识到人工智能在决策过程中增加或取代人类的道德影响，今天的创业公司需要重新考虑 MVP 模式<a href="https://web.archive.org/web/20221007053253/https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html" target="_blank" rel="noopener">。</a></p>
<p class="translated">MVP 允许您从目标市场收集关键反馈，然后告知推出产品所需的最低开发要求，从而创建一个强大的反馈回路，推动当今以客户为导向的业务。这种精益、敏捷的模式在过去二十年中非常成功——推出了数千家成功的创业公司，其中一些已经成长为十亿美元的公司。</p>
<p class="translated">然而，构建适用于大多数人的高性能产品和解决方案已经不够了。从对有色人种有偏见的面部识别技术到歧视女性的信贷算法，过去几年里，由于在数百万美元投入开发和营销后出现的道德困境，多个人工智能或人工智能产品被扼杀。在一个你只有一次机会将想法推向市场的世界里，这种风险可能是致命的，即使是对那些成熟的公司。</p>
<p class="translated">创业公司不必放弃精益商业模式，转而采用更能规避风险的方式。有一个中间地带，可以在不牺牲精益模式灵活性的情况下，将道德引入初创企业的心态，它始于初创企业的最初目标——在潜在客户面前获得早期阶段的概念证明。</p>
<p class="translated">然而，公司应该开发和推出基于负责任的人工智能(RAI)的道德可行产品(EVP)，而不是开发 MVP，这种方法在 AI/ML 系统的开发、部署和使用过程中考虑伦理、道德、法律、文化、可持续发展和社会经济因素。</p>
<p class="translated">虽然这对于初创公司来说是一个很好的实践，但对于构建 AI/ML 产品的大型技术公司来说，这也是一个很好的标准实践。</p><p class="piano-inline-promo"/>
<p class="translated">这里有三个步骤，初创公司——尤其是那些在产品中整合了重要人工智能/人工智能技术的公司——可以用来开发 EVP。</p>
<h2 class="translated">找一个道德官员来领导这项指控</h2>
<p class="translated">初创公司有首席战略官、首席投资官，甚至还有首席财务官。首席道德官同样重要，甚至更重要。这个人可以与不同的利益相关者合作，以确保初创公司开发的产品符合公司、市场和公众设定的道德标准。</p>
<p class="translated">他们应该充当创始人、高管、投资者和董事会与开发团队之间的联络人——确保每个人都以深思熟虑、规避风险的方式提出正确的道德问题。</p>
<p class="translated">基于历史数据训练机器。如果当前的业务流程中存在系统性偏见(例如不平等的种族或性别贷款做法)，人工智能将会发现这一点，并认为这应该继续表现。如果你的产品后来被发现不符合市场的道德标准，你不能简单地删除数据，寻找新的数据。</p>
<p class="translated">这些算法已经被训练过了。你无法抹去这种影响，就像一个 40 岁的男人无法消除父母或哥哥姐姐对他成长的影响一样。不管是好是坏，你都被结果所困。首席道德官需要在人工智能产品中根深蒂固之前，在整个组织中嗅出这种固有的偏见。</p>
<h2 class="translated">将道德融入整个发展过程</h2>
<p class="translated">负责任的 AI 不仅仅是一个时间点。它是一个端到端的治理框架，专注于组织的人工智能之旅的风险和控制。这意味着道德应融入整个开发过程——从战略和规划开始，直至开发、部署和运营。</p>
<p class="translated">在范围界定过程中，开发团队应该与首席道德官合作，了解一般的道德人工智能原则，这些原则代表了在许多文化和地理应用中有效的行为原则。这些原则规定、建议或启发人工智能解决方案在特定使用领域面临道德决策或困境时应该如何表现。</p>
<p class="translated">最重要的是，应进行风险和危害评估，确定对任何人的身体、情感或财务健康的任何风险。评估还应该考虑可持续性，并评估人工智能解决方案可能对环境造成的危害。</p>
<p class="translated">在开发阶段，团队应该不断询问他们对人工智能的使用如何与公司的价值观保持一致，模型是否公平地对待不同的人，以及他们是否尊重人们的隐私权。他们还应该考虑他们的人工智能技术是否安全、可靠和强大，以及运营模式在确保问责制和质量方面的有效性如何。</p>
<p class="translated">任何机器学习模型的关键组件是用于训练模型的数据。初创公司不仅应该关注 MVP 和模型最初是如何被证明的，还应该关注模型的最终背景和地理范围。这将允许团队选择正确的代表性数据集，以避免任何未来的数据偏差问题。</p>
<h2 class="translated">不要忘记持续的人工智能治理和法规遵从性</h2>
<p class="translated">鉴于对社会的影响，欧盟、美国或其他一些立法机构通过管理人工智能/人工智能使用的消费者保护法只是时间问题。一旦法律通过，这些保护措施很可能会扩展到世界其他地区和市场。</p>
<p class="translated">这种情况以前也发生过:欧盟《通用数据保护条例》( GDPR)的通过导致了世界各地的其他消费者保护浪潮，要求公司证明同意收集个人信息。现在，政界和商界的人们都在呼吁围绕人工智能制定道德准则。同样，欧盟在发布 2021 年人工智能法律框架提案后处于领先地位。</p>
<p class="translated">部署由人工智能/人工智能支持的产品或服务的初创公司应该准备好展示持续的治理和监管合规性——在监管规定强加于他们之前，现在就小心地建立这些流程。在构建产品之前，快速浏览提议的法规、指导文件和其他相关指南是 EVP 的必要步骤。</p>
<p class="translated">此外，在发布前重新审视监管/政策环境也是明智之举。在你的董事会或顾问委员会中有一个与当前全球正在发生的积极讨论息息相关的人，也会有助于理解可能会发生什么。规定要来了，有准备就好。</p>
<p class="translated">毫无疑问，人工智能将会给人类带来巨大的好处。自动化手动任务、简化业务流程和改善客户体验的能力太强大了，不容忽视。但是创业公司需要意识到 AI/ML 将对他们的客户、市场和整个社会产生的影响。</p>
<p class="translated">创业公司通常只有一次成功的机会，如果一个高性能的产品因为一些伦理问题直到上市后才被发现而被扼杀，这将是一个耻辱。创业公司需要从一开始就将道德规范融入开发流程，开发基于 RAI 的 EVP，并继续确保发布后的人工智能治理。</p>
<p class="translated">人工智能是商业的未来，但我们不能忽视对同情心的需求和创新中的人性因素。</p>
			</div>

			</div>    
</body>
</html>