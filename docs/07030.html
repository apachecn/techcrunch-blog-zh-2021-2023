<html>
<head>
<title>In iOS 16, apps can trigger real-world actions hands-free • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 iOS 16 中，应用程序可以无需手动触发现实世界的动作 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/06/07/in-ios-16-apps-can-trigger-real-world-actions-hands-free/">https://web.archive.org/web/https://techcrunch.com/2022/06/07/in-ios-16-apps-can-trigger-real-world-actions-hands-free/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">iOS 16 中的新功能将使应用程序无需手动即可触发现实世界的动作。这意味着用户可以做一些事情，比如走进房间就开始播放音乐，或者骑上电动自行车锻炼身体。苹果公司今天在该公司全球开发者大会(WWDC)期间举办的一次会议上告诉开发者，即使 iOS 用户当时没有积极使用该应用程序，这些免提操作也可能被触发。</p>
<p class="translated">这一更新利用了苹果的 Nearby Interaction framework，如果开发者和配件制造商选择采用这一技术，可能会导致一些有趣的用例，即 iPhone 成为与现实世界中的物体进行交互的一种方式。</p>
<p class="translated">在会议期间，苹果解释了当今的应用程序如何在后台运行时连接到蓝牙 le 配件并与之交换数据。然而，在 iOS 16 中，应用程序将能够通过蓝牙 le 附件在后台启动附近的交互会话，该附件也支持超宽带。</p>
<p class="translated">与此相关，苹果更新了配件制造商的规范，以支持这些新的后台会话。</p>
<p class="translated">这为应用程序和现实世界之间的界限模糊的未来铺平了道路，但第三方应用程序和设备制造商是否选择使用这些功能仍有待观察。</p>
<p class="translated">这项新功能是苹果附近互动框架更广泛更新的一部分，这是开发者会议的焦点。</p>
<p class="translated">这一框架是在 WWDC 2020 与 iOS 14 一起推出的，允许第三方应用程序开发人员在 iPhone 11 和更高版本的设备、Apple Watch 和其他第三方配件上接入 U1 或超宽带(UWB)芯片。这就是今天<a href="https://web.archive.org/web/20221007212130/https://www.imore.com/apple-tells-accessory-makers-how-make-things-work-iphones-u1-chip">为</a>苹果 AirTag 提供的精确查找功能提供的动力，它允许 iPhone 用户<a href="https://web.archive.org/web/20221007212130/https://support.apple.com/guide/iphone/locate-an-item-ipha779f0c10/ios">打开“查找我的”应用程序</a>，使用屏幕上的方向箭头和其他指导来指导他们的 AirTag 的精确位置，让你知道你离 AirTag 有多远，或者 AirTag 是否可能位于不同的楼层。</p><p class="piano-inline-promo"/>
<p class="translated">在 iOS 16 中，第三方开发人员将能够开发出做同样事情的应用程序，这要归功于一个新的功能，该功能允许他们将苹果的增强现实开发工具包 ARKit 与附近的交互框架相集成。</p>
<p class="translated">这将允许开发人员利用 ARKit 计算出的设备轨迹，因此他们的设备也可以根据应用程序的功能，智能地引导用户找到放错地方的物品或用户可能想要与之交互的另一个对象。通过利用 ARKit，开发人员将获得比单独使用附近交互更一致的距离和方向信息。</p>
<p class="translated">然而，该功能不必仅用于由第三方制造的类似 AirTag 的配件。苹果演示了另一个用例，例如，博物馆可以使用超宽带配件来引导游客参观其展品。</p>
<p class="translated">此外，该功能可用于将方向箭头或其他 AR 对象覆盖在相机的真实世界视图上，因为它有助于引导用户找到超宽带对象或配件。继续演示，苹果简要展示了红色 AR 气泡如何出现在相机视图顶部的应用程序屏幕上，以指明前进的方向。</p>
<p class="translated">从长远来看，这一功能为苹果传言中的混合现实智能眼镜奠定了基础，据推测，AR 驱动的应用程序将是体验的核心。</p>
<p class="translated">更新的功能正在向 iOS 16 软件更新的 beta 测试人员推出，将于今年晚些时候向公众发布。</p>
<p class="translated"><a href="https://web.archive.org/web/20221007212130/https://techcrunch.com/tag/wwdc-2022/"><img src="../Images/15ef6ff74a3944a667828dc0baf34a45.png" alt="Read more about WWDC 2022 on TechCrunch" data-original-src="https://web.archive.org/web/20221007212130im_/https://techcrunch.com/wp-content/uploads/2022/06/wwdc-2022-banner.jpg"/>T2】</a></p>
			</div>

			</div>    
</body>
</html>