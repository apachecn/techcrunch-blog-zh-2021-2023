<html>
<head>
<title>UK to avoid fixed rules for AI - in favor of 'context-specific guidance' | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">英国避免人工智能的固定规则——支持“特定语境指导”</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/29/uk-ai-white-paper/">https://web.archive.org/web/https://techcrunch.com/2023/03/29/uk-ai-white-paper/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">英国不会很快为人工智能制定硬性规定。</p>
<p class="translated">今天，科学、创新和技术部(DSIT)发布了一份<a href="https://web.archive.org/web/20230406070653/https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1146542/a_pro-innovation_approach_to_AI_regulation.pdf" target="_blank" rel="noopener">白皮书</a>，阐述了政府对监管人工智能的宽松方式的偏好。它开始了一个公共咨询过程——寻求对<span>6 月 21 日之前的计划的反馈——但似乎已经开始为人工智能可以快速通过的“灵活原则”铺平道路。</span></p>
<p class="translated"><span>对日益强大的人工智能技术的风险的担忧在很大程度上被视为次要考虑因素，远远落后于谈论高科技增长巨大潜力的政治议程——因此，如果问题出现，政府建议英国现有的(过度扩张的)监管机构将不得不在个案基础上处理它们，只配备现有的权力(和资源)。所以，呃，lol！</span></p>
<p class="translated">这份 91 页的白皮书题为“人工智能监管的亲创新方法”，谈到了采取“常识性的，以结果为导向的方法”来监管自动化——通过应用政府框架中的“适度和亲创新的监管框架”。</p>
<p class="translated">在伴随白皮书发布的一份新闻稿中，政府确认将不会有专门的人工智能监管机构，只有一套现有监管机构可以遵循的“原则”,这显然是着眼于产生报纸标题，以构建部长们寻求“涡轮增压增长”的叙述；因此，没有新的立法，而是一个“适应性”(但没有法律约束力)监管的主张。</p>
<p class="translated">DSIT 表示，立法“可能”被引入——在未来某个不确定的时期，当议会时间允许时——“以确保监管者一致考虑这些原则”。所以，是的，那是一个罐子被踢到马路上的声音。但预计在未来 12 个月内，将会看到一些现有的英国监管机构提出指导意见——以及一些工具和“风险评估模板”，人工智能制造商可能会被鼓励去尝试(如果他们愿意的话)。</p>
<p class="translated">还将有无情的沙盒(由 2M 从公共钱包资助)——或者至少是“沙盒试验，以帮助企业在进入市场之前测试人工智能规则”，DSIT 说。但很明显，实际使用它不会有硬性的法律要求。</p><p class="piano-inline-promo"/>
<p class="translated">政府表示，其人工智能的方法将专注于“监管使用，而不是技术”——因此，不会有任何规则或风险等级分配给整个行业或技术。这与欧盟基于风险的框架的发展方向形成了鲜明对比，该框架包括对某些人工智能用户的一些预先禁止，为指定为高风险的用例定义制度，并为低风险的使用进行自我监管。</p>
<p class="translated">“相反，我们将根据人工智能在特定应用中可能产生的结果进行监管，”政府规定，例如，在这里选择例子时有点大胆，认为将人工智能在关键基础设施中的所有应用归类为高风险“将是不相称或有效的”，因为人工智能在关键基础设施中可能会有一些“相对低风险”的用途。</p>
<p class="translated">由于部长们选择了白皮书所说的“特定环境”，他们决定不为人工智能设立专门的监管机构——因此，责任落在了拥有各个部门专业知识的现有机构身上。</p>
<p class="translated">“为了最好地实现这种环境特异性，我们将授权现有的英国监管机构应用跨领域的原则，”它写道。“监管机构最适合在其专业领域进行详细的风险分析和执法活动。创建一个新的专门针对人工智能的跨部门监管机构将带来复杂性和混乱，破坏并可能与我们现有的专家监管机构的工作相冲突。”</p>
<p class="translated">根据该计划，现有监管机构将被期待应用一套五项原则——列出“负责任的人工智能设计、开发和使用的关键要素”——政府希望/希望在企业开发人工智能时指导它们。</p>
<p class="translated">“监管机构将领导框架的实施，例如通过发布遵守这些原则的最佳实践指南，”它建议，并补充说，他们将被期待“根据现有的法律法规，在其职权范围内”应用这些原则来解决人工智能带来的风险，“认为这将使这些原则能够“补充现有的监管，增加清晰度，并减少跨监管职权范围经营的企业的摩擦”。</p>
<p class="translated">它表示，预计相关监管机构需要发布关于这些原则的“实用指南”或更新现有指南，以便在持续的法律不确定性的真空中“为企业提供清晰度”。这还表明，监管机构可能需要发布联合指南，重点关注跨越多个监管权限的人工智能用例。因此，英国监管机构将面临更多的工作和更多的联合工作。</p>
<p class="translated">“除了发布指导意见之外，监管机构还可以在其现有职权范围内使用替代措施，引入其他工具或资源来实施这些原则，”它接着说，并补充说，它将“监测这些原则的总体有效性和框架的更广泛影响”——规定:“这将包括与监管机构合作，了解这些原则是如何应用的，以及该框架是否足以支持创新。”</p>
<p class="translated">因此，如果企业认为某些原则过于艰巨，这似乎是在为这些原则的倒退敞开大门。</p>
<h2 class="translated">“灵活原则”</h2>
<p class="translated">“我们认识到，特定的人工智能技术，例如基础模型，可以以许多不同的方式应用，这意味着风险可能会有很大差异。例如，使用聊天机器人制作一篇长文章的摘要，与使用相同的技术提供医疗建议相比，存在非常不同的风险。科学、创新和技术部部长米歇尔·多内兰(Michelle Donelan)在白皮书的执行摘要中写道:“我们理解有必要与创新者合作监测这些发展，同时避免给部署人工智能的人带来不必要的监管负担，”政府在白皮书的执行摘要中阐述了其“支持创新”的立场。</p>
<p class="translated">“为了确保我们的监管框架有效，我们将利用世界级监管机构的专业知识。他们了解所在行业的风险，最适合采取适当的方法来监管人工智能。这将意味着支持创新和与企业密切合作，但也要在必要时介入解决风险。通过用一套原则来支撑框架，我们将推动监管者之间的一致性，同时也为他们提供所需的灵活性。”</p>
<p class="translated">政府打算让现有的监管机构承担更多的任务——起草“量身定制的、特定背景的方法”，人工智能模型制造商也只能接受建议(即忽略)——包括<span>健康与安全执行局；平等和人权委员会；以及竞争和市场管理局，根据 DSIT。</span></p>
<p class="translated"><span>公关</span> <span>没有提到信息专员办公室(ICO)，也就是数据保护监管机构，但它在白皮书中提到了几次，看起来将成为另一个被迫产生人工智能指导的机构(有用的是，足够了，<a href="https://web.archive.org/web/20230406070653/https://techcrunch.com/2022/10/26/no-to-voight-kampff-tests/"> ICO 已经提供了一些关于人工智能蛇油的想法</a>)。</span></p>
<p class="translated">这里有一个小插曲:CMA 仍在等待政府授权给一个<a href="https://web.archive.org/web/20230406070653/https://techcrunch.com/2021/04/07/uks-digital-markets-unit-starts-work-on-pro-competition-reforms/">专门的数字市场部门</a> (DMU ),该部门本应控制大型科技公司的市场力量，即通过必要的立法。但是，<a href="https://web.archive.org/web/20230406070653/https://techcrunch.com/2022/05/10/uk-queens-speech-big-tech-privacy-data-protection/">去年</a>，部长们选择把那个罐子踢到长长的草地上——所以 DMU 在软推出近两年后仍未被置于法定地位，期待议会时间被发现赋予它权力……所以很明显，这个政府更喜欢起草新闻稿，而不是智能数字监管。</p>
<p class="translated">结果是，英国在数字竞争的突出领域落后于整个欧盟(欧盟将在几个月后申请数字市场法案)，而德国在 2021 年初用事前数字制度更新了其国家竞争制度，并已经有了一系列支持竞争的执法措施。</p>
<p class="translated">现在——根据设计——英国的部长们也打算让国家在人工智能监管方面落后于其他国家；正如 DSIT 所说，这是一种“避免可能扼杀创新的严厉立法”的选择，有利于企业可以选择是否遵循的大量部门监管指导——字面上与写下这样一句话相同:“目前，组织可能无法充分发挥人工智能的潜力，因为拼凑的法律制度给试图遵守规则的企业带来了混乱以及财务和行政负担。”那么，嗯……法律确定性是好是坏——到底是哪个？！</p>
<p class="translated">简而言之，这看起来非常像英国(后英国退出欧盟时代)的混乱。</p>
<p class="translated">与此同时，在英吉利海峡的另一边，欧盟立法者正在就建立基于风险的人工智能监管框架进行谈判，这是欧盟委员会早在 2021 年就提出的法律草案。现在，随着欧洲议会议员推动修正案，以确保最终文本涵盖通用人工智能，如 OpenAI 的 ChatGPT。欧盟也有一个更新软件和人工智能责任规则的提案摆在桌面上。</p>
<p class="translated">面对欧盟精心构建的基于风险的框架，英国立法者只能鼓吹自愿风险评估模板和玩具沙盒——并将这种生成可信人工智能的“DIY”方法称为“英国退出欧盟奖金”。哎哟。</p>
<p class="translated">政府希望指导人工智能使用的五项原则——或者，具体而言，现有监管机构“应该考虑以最佳方式促进人工智能在他们监控的行业中的安全和创新使用”——是:</p>
<ul>
<li class="translated"><strong>安全、保障和稳健</strong>:“人工智能的应用应该以一种安全、可靠和稳健的方式运行，在这种方式下，风险得到了谨慎的管理”</li>
<li class="translated"><strong>透明度和可解释性</strong>:“开发和部署人工智能的组织应该能够沟通何时以及如何使用人工智能，并以适当的详细程度解释系统的决策过程，以匹配人工智能的使用所带来的风险”</li>
<li class="translated"><strong>公平</strong>:“人工智能的使用应符合英国现有法律，例如《2010 年平等法案》或英国《GDPR》，不得歧视个人或制造不公平的商业结果”</li>
<li class="translated"><strong>问责制和治理</strong>:“需要采取措施确保对人工智能的使用方式进行适当的监督，并对结果进行明确的问责”</li>
<li class="translated"><strong>可争议性和补救</strong>:“人们需要有明确的途径来质疑人工智能产生的有害结果或决定”</li>
</ul>
<p class="translated">所有这些听起来确实像是好词。但是，如果没有一个法律框架来将“原则”转化为硬性规定，并确保在选择不理会任何昂贵的安全东西的实体上一致的应用和执行，这看起来就像吹口哨祈祷并希望最好的一样有用，如果你正在寻找的是值得信赖的人工智能…</p>

<p class="translated">(哦，是的——别忘了，英国政府最近邀请企业“共同设计”一个新的数据保护框架，也正在<a href="https://web.archive.org/web/20230406070653/https://techcrunch.com/2023/03/08/uk-data-reform-bill-no-2/">淡化上述英国 GDPR </a>。这导致了一场修改后的改革，旨在使商业实体更容易处理人们的数据以用于研究等用例，并通过增加一个政治任命的委员会来削弱隐私监管机构的独立性，以确保(我在这里引用多尼伦的话)“我们是世界上最具创新性的经济体，我们巩固自己作为科学和技术超级大国的地位”。)</p>
<p class="translated">英国的明显趋势是，随着政府寻求为人工智能推动的“创新”铺上红地毯，现有的保护措施正在被取消，而没有考虑这对安全或公平等相当重要的东西可能意味着什么——以及可信度，假设你希望人们对你推出的人工智能有一点信任——但部长们基本上是在说:“别担心，躺回去想想英国的 GDP 吧！”</p>
<p class="translated">当然，任何在英国构建人工智能模型并希望超越这些海岸的开发人员都必须考虑适用于英国以外的法规。因此，监管如此宽松的自由最终可能会带来一个严格的要求，即无论如何都要遵守外国框架——或者在地理范围上受到严格限制。(而且，技术创新者确实喜欢规模化。)</p>
<p class="translated">尽管如此，DSIT 的公关引用了谷歌旗下 DeepMind 的首席运营官(英国人工智能委员会成员)莱拉·易卜拉欣(Lila Ibrahim)的原话，deep mind 是一家人工智能巨头，在当前热门的人工智能技术(生成式人工智能)方面落后于 OpenAI 等竞争对手，他称赞政府提出的“情境驱动方法”，并声称这将“帮助监管跟上人工智能的发展，支持创新并减轻未来的风险”。</p>
<p class="translated">“人工智能有潜力推动科学发展，并在许多方面造福人类，从应对气候变化到更好地理解和治疗疾病。这种变革性技术只有在受到信任的情况下才能发挥其全部潜力，这需要本着负责任的开拓精神建立公共和私人伙伴关系，”Ibrahim 还建议道。</p>
<p class="translated">政府显然希望其提供的“除了你选择的规则之外没有规则”将鼓励人工智能初创公司选择英国，而不是自动化监管更严格的其他地方。(或者正如多尼兰所写的那样:“当海外人工智能企业在英国建立业务时，我们支持创新的方法也将成为一种强有力的激励。”)</p>
<p class="translated">这是保守党政府的一场赌博——考虑到监管过轻的人工智能出现可怕错误的高度可扩展潜力。关于“人工智能驱动的关键基础设施失败”的头条新闻不会等待政府的新闻稿；他们会自己写的。但是 Rishi Sunak 的托利党人显然会全力以赴。</p>
<p class="translated">在一份新闻声明中，Donelan 继续提供了这个有趣的结构，以解释政府正在做什么:</p>
<blockquote><p class="translated">人工智能有潜力让英国成为一个更智能、更健康、更快乐的生活和工作场所。人工智能不再是科幻小说中的东西，人工智能的发展速度令人震惊，所以我们需要有规则来确保它的安全发展。</p>
<p class="last-child translated">我们的新方法基于强有力的原则，因此人们可以相信企业会释放未来的技术。</p>
</blockquote>
<p class="translated">这是相当多的句子——结合了需要“确保(人工智能)安全开发的规则”的断言，以及(只是)“强有力的原则，以便人们可以相信企业会释放这种未来技术”的巧妙提议。那就没有规则了。(我的意思是，“信任企业释放技术”和信任企业释放 T2 信任的技术完全不是一回事。事实上，你可以说他们截然不同。所以相位的选择很重要。)</p>
<p class="translated">但是回到规则和原则。我们问 ChatGPT 这两个词有什么区别。这是它告诉我们的:</p>
<blockquote><p class="translated">规则和原则都是管理行为的指导方针，但它们在性质和应用上有所不同。</p>
<p class="translated">规则是具体的指示或指令，规定一个人应该做什么或不应该做什么。它们通常由当局或机构制定，并通过惩罚或奖励等后果来实施。规则往往是僵硬的，不灵活的，不考虑情况的差异或个人的情况。例如，“不要在高速公路上超速行驶”是一条适用于所有司机的规则，与上下文无关。</p>
<p class="translated">另一方面，原则是指导行为和决策的宽泛概念或价值观。它们比规则更灵活，适应性更强，为做出伦理或道德判断提供了一个框架。原则通常不会通过惩罚或奖励来强制执行，而是被内化并自愿遵循。例如，诚实原则是一种在各种情况下指导行为的价值观，如在交流中诚实，尊重他人的财产，履行义务。</p>
<p class="translated">总之，规则是具体而不灵活的指令，而原则是指导行为的广泛而灵活的价值观。规则是通过外部手段实施的，而原则是内在的，是自愿遵循的。</p></blockquote>
<p class="translated">因此，假设这个大型语言模型不是简单地再次产生幻觉，并且它识别的细微差别是正确的，Donelan 不仅认识到人工智能的安全需要固定的规则，同时确认政府已经决定现在不设置任何规则。口头降级是为了纯粹的自愿原则。或者，基本上，它将让企业自己拿主意，做他们必须做的事情，以便在可预见的未来尽可能快地增长(或者至少到下一次选举之后)。还能出什么差错！？</p>
<p class="translated">很明显，政府不惜一切代价的增长议程已经吃了一顿人工智能炒作的大餐。可怜的英国人以在名为“创新”的无舵树皮上释放无脑自动化的名义，准备成为试验品。</p>
<p class="translated">英国公民会想为这次旅行系好安全带。因为如果出了问题，他们将被迫等待政府腾出议会时间来通过一些安全规则。可能要屏住呼吸。</p>

			</div>

			</div>    
</body>
</html>