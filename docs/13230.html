<html>
<head>
<title>OpenAI's attempts to watermark AI text hit limits | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenAI 试图给人工智能文本添加水印达到极限| TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/12/10/openais-attempts-to-watermark-ai-text-hit-limits/">https://web.archive.org/web/https://techcrunch.com/2022/12/10/openais-attempts-to-watermark-ai-text-hit-limits/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">是人类写的，还是<a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/tag/chatgpt/"> ChatGPT </a>写的？这很难讲——也许太难了，它的创造者 OpenAI 认为，这就是为什么它正在研究一种方法来“水印”人工智能生成的内容。</p>
<p class="translated">在德克萨斯大学奥斯汀分校的一场<a href="https://web.archive.org/web/20230408230401/https://scottaaronson.blog/?p=6823" target="_blank" rel="noopener">讲座</a>中，目前担任 OpenAI 客座研究员的计算机科学教授 Scott Aaronson 透露，OpenAI 正在开发一种工具，用于“对文本(人工智能系统)的输出进行统计水印处理”每当一个系统——比如 chat GPT——生成文本时，该工具就会嵌入一个“不易察觉的秘密信号”,表明文本来自何处。</p>
<p class="translated">Aaronson 说，OpenAI 工程师 Hendrik Kirchner 建立了一个工作原型，希望将其构建到未来 OpenAI 开发的系统中。</p>
<p class="translated">“我们希望更难获取[人工智能系统]的输出，并将其当作来自人类的输出来传递，”Aaronson 在他的评论中说。“显然，这可能有助于防止学术剽窃，但也有助于，例如，大规模的宣传——你知道，在每一个博客上发垃圾邮件，发表看似切题的评论，支持俄罗斯入侵乌克兰，而莫斯科甚至没有一栋挤满巨魔的大楼。或者模仿某人的写作风格以证明其有罪。”</p>
<h2 class="translated">利用随机性</h2>
<p class="translated">为什么需要水印？ChatGPT 就是一个很强的例子。OpenAI 开发的聊天机器人<a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/12/05/chatgpt-shrugged/">通过</a> <a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/12/02/daily-crunch-chatgpts-user-experience-and-implementation-should-have-google-scared/"> storm </a>接管了<a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/12/08/sharegpt-lets-you-easily-share-your-chatgpt-conversations/"/><a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/">互联网</a> <a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/12/02/chatgpt-isnt-putting-me-out-of-a-job-yet-but-its-very-good-fun/">，不仅表现出了回答挑战性问题的能力，还表现出了写诗、解决编程难题以及在许多哲学话题上表现出诗意的能力。</a></p>
<p class="translated">虽然 ChatGPT 非常有趣，而且真正有用，但该系统引发了明显的伦理问题。像它之前的许多文本生成系统一样，ChatGPT 可以用来编写高质量的钓鱼电子邮件和有害的恶意软件，或者在学校作业中作弊。作为一个问答工具，它实际上是不一致的——这一缺点导致编程问答网站堆栈溢出，禁止来自 ChatGPT 的答案，直到另行通知。</p>
<p class="translated">为了掌握 OpenAI 水印工具的技术基础，了解 ChatGPT 这样的系统为什么工作得这么好是有帮助的。这些系统将输入和输出文本理解为“记号”字符串，记号可以是单词，也可以是标点符号和单词的一部分。在它们的核心，系统不断地产生称为概率分布的数学函数，以决定下一个要输出的标记(例如单词)，考虑所有先前输出的标记。</p><p class="piano-inline-promo"/>
<p class="translated">在像 ChatGPT 这样的 OpenAI 托管的系统中，在分发版生成之后，OpenAI 的服务器会根据分发版进行令牌采样的工作。这个选择有一些随机性。这就是为什么同样的文本提示会产生不同的响应。</p>
<p class="translated">Aaronson 在讲座中说，OpenAI 的水印工具就像现有文本生成系统的“包装器”,利用运行在服务器级别的加密功能“伪随机”选择下一个令牌。理论上，系统生成的文本在你我看来仍是随机的，但任何拥有加密功能“钥匙”的人都能够发现水印。</p>
<p class="translated">“根据经验，几百个令牌似乎足以获得一个合理的信号，即是的，这个文本来自[一个人工智能系统]。原则上，你甚至可以提取一段很长的文本，分离出哪些部分可能来自[系统]，哪些部分可能不是。”阿伦森说。“[该工具]可以使用秘密密钥进行水印处理，并且可以使用相同的密钥检查水印。”</p>
<h2 class="translated">主要限制</h2>
<p class="translated">给人工智能生成的文本加水印并不是一个新想法。以前的尝试大多基于规则，依赖于同义词替换和特定于语法的单词变化等技术。但是除了德国 CISPA 研究所去年三月发表的理论研究之外，OpenAI 似乎是解决这个问题的第一批基于密码学的方法之一。</p>
<p class="translated">当联系 Aaronson 进行评论时，他拒绝透露更多关于水印原型的信息，只是说他希望在未来几个月内与人合作撰写一篇研究论文。OpenAI 也拒绝了，只是说水印是它正在探索的几种“来源技术”之一，以检测人工智能产生的输出。</p>
<p class="translated">然而，无党派学者和行业专家的看法不一。他们注意到该工具是服务器端的，这意味着它不一定适用于所有的文本生成系统。他们认为对手解决问题是微不足道的。</p>
<p class="translated">“我认为，通过重新措辞、使用同义词等方法来绕过它是相当容易的。麻省理工学院计算机科学教授 Srini Devadas 通过电子邮件告诉 TechCrunch。"这有点像拔河比赛."</p>
<p class="translated">艾伦人工智能研究所的研究科学家 Jack Hessel 指出，难以察觉地对人工智能生成的文本进行指纹识别，因为每个标记都是一个离散的选择。太明显的指纹可能会导致选择奇怪的单词，降低流利度，而太细微的指纹会在寻找指纹时留下怀疑的空间。</p>
<p/><div id="attachment_2456275" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2456275" decoding="async" class="vertical wp-image-2456275 size-full" src="../Images/33afe5bb65050f92f5b3352721d6c22e.png" alt="ChatGPT" srcset="https://web.archive.org/web/20230408230401im_/https://techcrunch.com/wp-content/uploads/2022/12/Screenshot-2022-12-02-at-7.03.19-AM.webp 768w, https://web.archive.org/web/20230408230401im_/https://techcrunch.com/wp-content/uploads/2022/12/Screenshot-2022-12-02-at-7.03.19-AM.webp?resize=102,150 102w, https://web.archive.org/web/20230408230401im_/https://techcrunch.com/wp-content/uploads/2022/12/Screenshot-2022-12-02-at-7.03.19-AM.webp?resize=205,300 205w, https://web.archive.org/web/20230408230401im_/https://techcrunch.com/wp-content/uploads/2022/12/Screenshot-2022-12-02-at-7.03.19-AM.webp?resize=465,680 465w, https://web.archive.org/web/20230408230401im_/https://techcrunch.com/wp-content/uploads/2022/12/Screenshot-2022-12-02-at-7.03.19-AM.webp?resize=34,50 34w" sizes="(max-width: 768px) 100vw, 768px" data-original-src="https://web.archive.org/web/20230408230401im_/https://techcrunch.com/wp-content/uploads/2022/12/Screenshot-2022-12-02-at-7.03.19-AM.webp"/><p id="caption-attachment-2456275" class="wp-caption-text translated">ChatGPT 回答问题。</p></div>
<p class="translated">OpenAI 的竞争对手<a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/07/12/openai-rival-ai21-labs-raises-64m-to-ramp-up-its-ai-powered-language-services/"> AI21 Labs </a>的联合创始人兼联合首席执行官 Yoav Shoham 认为，统计水印不足以帮助识别人工智能生成的文本的来源。他呼吁一种“更全面”的方法，包括差分水印，即文本的不同部分采用不同的水印，以及更准确地引用事实文本来源的人工智能系统。</p>
<p class="translated">专家指出，这种特殊的水印技术还需要对 OpenAI 寄予很大的信任和力量。</p>
<p class="translated">“一个理想的指纹将不会被人类的读者识别，并能够非常自信地检测到，”Hessel 通过电子邮件说。“取决于它是如何设置的，由于‘签名’过程的工作方式，OpenAI 自己可能是唯一能够自信地提供这种检测的一方。”</p>
<p class="translated">在他的演讲中，Aaronson 承认，只有在 OpenAI 这样的公司在扩大最先进的系统方面领先的世界中，该计划才能真正发挥作用——并且他们都同意成为负责任的参与者。即使 OpenAI 与其他文本生成系统提供商共享水印工具，如 Cohere 和 AI21Labs，这也不会阻止其他人选择不使用它。</p>
<p class="translated">“如果[它]成为一场混战，那么许多安全措施确实会变得更加困难，甚至可能无法实施，至少在没有政府监管的情况下是如此，”Aaronson 说。“在这个世界上，任何人都可以构建自己的文本模型，就像(例如 ChatGPT)一样好……你会怎么做？”</p>
<p class="translated">这就是它在文本到图像领域的表现。与 OpenAI 的<a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/11/03/now-anyone-can-build-apps-that-use-dall-e-2-to-generate-images/"> DALL-E 2 </a>图像生成系统只能通过 API 获得不同，<a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/2022/10/17/stability-ai-the-startup-behind-stable-diffusion-raises-101m/"> Stability AI </a>开源了其文本到图像技术(称为<a href="https://web.archive.org/web/20230408230401/https://techcrunch.com/tag/stable-diffusion/">稳定扩散</a>)。虽然 DALL-E 2 在 API 级别有许多过滤器，以防止生成有问题的图像(加上它生成的图像上的水印)，但开源的稳定扩散没有。除了其他毒性，坏演员已经用它制作了深度伪造的色情片。</p>
<p class="translated">对他来说，阿伦森是乐观的。在演讲中，他表示相信，如果 OpenAI 可以证明水印工作并且不影响生成文本的质量，它有可能成为行业标准。</p>
<p class="translated">不是每个人都同意。正如 Devadas 指出的那样，该工具需要一个密钥，这意味着它不能完全开源——这可能会限制它被同意与 OpenAI 合作的组织采用。(如果密钥被公开，任何人都可以推断出水印背后的模式，这就违背了他们的目的。)</p>
<p class="translated">但这可能不是那么遥不可及。Quora 的一名代表说，该公司将有兴趣使用这样一个系统，它可能不会是唯一的一个。</p>
<p class="translated">“你可能会担心，在扩展人工智能时，所有这些关于试图安全和负责任的东西……一旦它严重伤害了谷歌、Meta、阿里巴巴和其他主要参与者的底线，很多东西都会被扔出窗外，”Aaronson 说。“另一方面，在过去的 30 年里，我们看到大型互联网公司可以就某些最低标准达成一致，无论是因为害怕被起诉，还是希望被视为负责任的参与者，还是其他什么原因。”</p>
			</div>

			</div>    
</body>
</html>