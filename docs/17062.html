<html>
<head>
<title>The takeaways from Stanford's 386-page report on the state of AI | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">斯坦福大学 386 页的人工智能现状报告摘录</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/04/04/the-takeaways-from-stanfords-386-page-report-on-the-state-of-ai/">https://web.archive.org/web/https://techcrunch.com/2023/04/04/the-takeaways-from-stanfords-386-page-report-on-the-state-of-ai/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">写一份关于人工智能现状的报告一定感觉很像在流沙上建筑:当你点击发布时，整个行业已经在你脚下发生了变化。但是在斯坦福大学长达 386 页的论文中仍然有一些重要的趋势和要点来总结这个复杂而快速发展的领域。</p>
<p class="translated">人工智能指数来自以人为中心的人工智能研究所，与学术界和私营企业的专家合作，收集有关此事的信息和预测。作为一年一度的努力(从规模来看，你可以打赌他们已经在努力规划下一个)，这可能不是对人工智能的最新看法，但这些定期的广泛调查对于保持人们对行业脉搏的了解非常重要。</p>
<p class="translated">今年的报告包括“对基础模型的新分析，包括它们的地缘政治和培训成本，人工智能系统的环境影响，K-12 人工智能教育和人工智能的公众舆论趋势，”以及对 100 个新国家的政策的审视。</p>
<p class="translated">让我们来总结一下最高层次的要点:</p>
<ul>
<li class="translated">在过去的十年里，人工智能的发展已经从学术界主导转变为工业界主导，而且这种转变没有任何迹象。</li>
<li class="translated">在传统基准上测试模型变得越来越困难，这里可能需要一个新的范例。</li>
<li class="translated">人工智能培训和使用的能源足迹变得相当可观，但我们还没有看到它如何在其他地方增加效率。</li>
<li class="translated">自 2012 年以来，“人工智能事件和争议”的数量增加了 26 倍，这实际上似乎有点低。</li>
<li class="translated">人工智能相关的技能和职位正在增加，但没有你想象的那么快。</li>
<li class="translated">然而，政策制定者们正努力撰写一份明确的人工智能法案，如果曾经有过这样的法案，那也是徒劳的。</li>
<li class="translated">投资暂时停滞，但那是在过去十年天文数字般增长之后。</li>
<li class="translated">超过 70%的中国、沙特和印度受访者认为人工智能利大于弊。美国人？35%.</li>
</ul>
<p class="translated">但是这份报告对许多主题和副主题进行了详细阐述，可读性很强，而且不涉及技术。只有专心致志的人会阅读全部 386 页的分析报告，但实际上，几乎任何有动力的人都可以。</p>
<p class="translated">让我们更详细地看看第 3 章，技术人工智能伦理。</p>
<p class="translated">偏见和毒性很难简化为度量标准，但就我们可以定义和测试这些东西的模型而言，很明显，“未经过滤的”模型更容易导致问题。指令调整，也就是说增加一层额外的准备(如隐藏的提示)或通过第二个中介模型传递模型的输出，在改善这个问题上是有效的，但它远非完美。</p>
<p class="translated">下图很好地说明了项目符号中提到的“AI 事件和争议”的增加:</p>
<p/><div id="attachment_2523948" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2523948" decoding="async" class="size-full wp-image-2523948" src="../Images/8e28a27dcbae397f98a63a37b7afe091.png" alt="" srcset="https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg 2560w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=150,80 150w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=300,159 300w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=768,408 768w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=680,361 680w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=1536,816 1536w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=2048,1088 2048w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=1200,638 1200w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg?resize=50,27 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/ai-incidents-increase.jpg"/><p id="caption-attachment-2523948" class="wp-caption-text translated"><strong>图片来源:</strong>史丹福海</p></div>
<p class="translated">正如你所看到的，趋势是上升的，这些数字出现在 ChatGPT 和其他大型语言模型的主流采用之前，更不用说图像生成器的巨大改进了。可以肯定的是，26 倍的增长只是一个开始。</p>
<p class="translated">以某种方式使模型更加公平或公正可能会对其他指标产生意想不到的后果，如下图所示:</p>
<p/><div id="attachment_2523963" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2523963" decoding="async" loading="lazy" class="size-full wp-image-2523963" src="../Images/368d31cddfaca2593c26b988e5883d16.png" alt="" srcset="https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg 2560w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=150,80 150w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=300,159 300w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=768,408 768w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=680,361 680w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=1536,816 1536w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=2048,1088 2048w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=1200,638 1200w, https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg?resize=50,27 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230408090835im_/https://techcrunch.com/wp-content/uploads/2023/04/bias-fairness-ai.jpg"/><p id="caption-attachment-2523963" class="wp-caption-text translated"><strong>图片来源:</strong>史丹福海</p></div>
<p class="translated">正如报告指出的，“在某些公平基准上表现更好的语言模型往往有更严重的性别偏见。”为什么？这很难说，但这恰恰说明优化并不像大家希望的那么简单。没有简单的方法来改进这些大型模型，部分原因是我们并不真正了解它们是如何工作的。</p>
<p class="translated">事实核查是那些听起来很适合人工智能的领域之一:它已经索引了大部分网络，可以评估声明并返回一个信心，即它们得到真实来源的支持，等等。事实远非如此。人工智能实际上特别不擅长评估真实性，风险并不在于它们是不可靠的检验者，而在于它们本身会成为令人信服的错误信息的强大来源。已经创建了许多研究和数据集来测试和改进人工智能事实核查，但迄今为止，我们或多或少仍处于起步阶段。</p>
<p class="translated">幸运的是，这里的兴趣大增，原因很明显，如果人们觉得他们不能信任人工智能，整个行业都会受到阻碍。在 ACM 会议上，关于公平性、问责制和透明度的提交量大幅增加，在 NeurIPS 会议上，公平性、隐私和可解释性等问题得到了更多的关注和关注。</p>
<p class="translated">这些亮点在桌面上留下了很多细节。然而，海团队在组织内容方面做得很好，在<a href="https://web.archive.org/web/20230408090835/https://aiindex.stanford.edu/report/#individual-chapters" target="_blank" rel="noopener">在这里</a>仔细阅读了高水平的东西之后，你可以<a href="https://web.archive.org/web/20230408090835/https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index_Report_2023.pdf" target="_blank" rel="noopener">下载完整的论文</a>并更深入地了解任何激起你兴趣的主题。</p>
			</div>

			</div>    
</body>
</html>