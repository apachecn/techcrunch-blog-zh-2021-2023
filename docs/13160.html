<html>
<head>
<title>GitHub launches Copilot for Business plan as legal questions remain unresolved | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">由于法律问题仍未解决，GitHub 为商业计划推出 Copilot</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/12/08/github-launches-copilot-for-business-plan-as-legal-questions-remain-unresolved/">https://web.archive.org/web/https://techcrunch.com/2022/12/08/github-launches-copilot-for-business-plan-as-legal-questions-remain-unresolved/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">GitHub Copilot 是 GitHub 的一项服务，它可以智能地建议代码行，在面向个人用户和教育工作者推出几个月后，现在已经在面向企业的计划中推出。</p>
<p class="translated">这项新计划名为 GitHub Copilot for Business，每个用户每月花费 19 美元，拥有单许可证 Copilot 层的所有功能，以及公司许可和政策控制。其中包括一个开关，让 IT 管理员阻止向开发者显示与 GitHub 上的公共代码匹配的建议代码，这可能是对围绕 Copilot 酝酿的知识产权争议的回应。</p>
<p class="translated">Copilot 可作为开发环境的可下载扩展，包括 Microsoft Visual Studio、Neovim 和 JetBrains，它由 OpenAI 开发的一个名为 Codex 的人工智能模型提供支持，该模型对数十亿行公共代码进行训练，以根据现有代码的上下文建议额外的代码行和功能。Copilot 截至 8 月已有超过 400，000 名订户-可以利用其知识库和当前上下文，针对开发人员想要完成的内容的描述(例如，“Say hello world”)提出编程方法或解决方案。</p>
<p/><div id="attachment_2171486" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2171486" decoding="async" class="wp-image-2171486 size-full" src="../Images/fd2fb94257fbb736c088c0a661d677a1.png" alt="" data-original-src="https://web.archive.org/web/20230406201916im_/https://techcrunch.com/wp-content/uploads/2021/06/GitHub-Copilot-2.gif"/><p id="caption-attachment-2171486" class="wp-caption-text translated"><strong>图片来源:</strong> GitHub</p></div>
<p class="translated">法典委员会培训的代码中至少有一部分是受版权保护的，或者是受限制性许可保护的，一些倡导团体对此提出了异议。用户已经能够提示 Copilot 从 Quake 生成代码，从个人代码库中生成代码片段，从《掌握 JavaScript》和《思考 JavaScript》等书籍中生成示例代码；GitHub 自己也承认，大约 1%的情况下，Copilot 建议包含的代码片段长度超过 150 个字符，与训练数据相匹配。</p>
<p class="translated">GitHub 声称，公平使用——美国法律中允许使用受版权保护的材料而无需首先获得权利持有人的许可的原则——在 Copilot 有意或无意地违反受版权保护的代码的情况下保护它。但并不是所有人都同意。倡导自由软件运动的非营利组织自由软件基金会称 Copilot 是“不可接受和不公正的”。微软、GitHub 和 OpenAI 被<a href="https://web.archive.org/web/20230406201916/https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data" target="_blank" rel="noopener">集体起诉</a>,指控他们允许 Copilot 在不提供信用的情况下重复使用部分授权代码，违反了版权法。</p>
<p class="translated">抛开 GitHub 的责任不谈，一些法律专家认为，如果 Copilot 无意中将该工具中受版权保护的建议整合到他们的生产软件中，可能会给公司带来风险。正如 Elaine Atwell <a href="https://web.archive.org/web/20230406201916/https://www.kolide.com/blog/github-copilot-isn-t-worth-the-risk" target="_blank" rel="noopener">在 Kolide 的企业博客上的一篇文章中指出的那样，由于 Copilot 剥离了其许可证的代码，因此很难区分哪些代码是允许部署的，哪些代码可能有不兼容的使用条款。</a></p><p class="piano-inline-promo"/>
<p class="translated">GitHub 试图纠正这一点，它是一个过滤器，于 6 月首次引入 Copilot 平台，根据公共 GitHub 代码检查代码建议及其周围约 150 个字符的代码，如果匹配或“近似匹配”，则隐藏建议。但这是一个不完善的措施。德克萨斯 A&amp;M 大学的计算机科学教授 Tim Davis 发现，启用过滤器会导致 Copilot 泄露大量他的版权代码，包括所有的属性和许可文本。</p>

<p class="translated">GitHub 计划在 2023 年引入更多功能，旨在帮助开发人员就是否使用 Copilot 的建议做出明智的决定，包括通过引用这些存储库来识别与公共代码匹配的字符串的能力。对于面向企业客户的 GitHub Copilot，GitHub 声称不会保留用于培训的代码片段或共享代码，无论数据来自公共存储库、私有存储库、非 GitHub 存储库还是本地文件。</p>
<p class="translated">但尚不清楚这些措施是否足以减轻企业对法律挑战的担忧。</p>
			</div>

			</div>    
</body>
</html>