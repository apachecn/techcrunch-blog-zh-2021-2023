<html>
<head>
<title>Google's new 'multisearch' feature lets you search using text and images at the same time | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌新的“多重搜索”功能让你可以同时使用文本和图片进行搜索</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/04/07/googles-multisearch-search-using-text-images/">https://web.archive.org/web/https://techcrunch.com/2022/04/07/googles-multisearch-search-using-text-images/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">谷歌新的“多重搜索”功能可以让你同时使用文本和图片进行搜索</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">谷歌今天宣布，它将推出一项新的“多重搜索”功能，允许用户通过谷歌镜头(该公司的图像识别技术)同时使用文本和图像进行搜索。谷歌<a href="https://web.archive.org/web/20230307034813/https://techcrunch.com/2021/09/29/google-introduces-a-new-way-to-search-that-combines-images-and-text-into-one-query/">去年九月在其 Search On event 上首次取笑了</a>这一功能，并表示将在测试和评估后的几个月内推出这一功能。从今天开始，新的多重搜索功能在美国以英语测试版的形式推出。</p>
<p class="translated">要开始，你需要在 Android 或 iOS 上打开谷歌应用程序，点击镜头相机图标，然后搜索你的截图或拍照。然后，你可以向上滑动并点击“+添加到您的搜索”按钮来添加文本。谷歌指出，用户应该拥有最新版本的应用程序才能使用新功能。</p>
<p/><div id="attachment_2295649" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2295649" decoding="async" class="vertical  wp-image-2295649" src="../Images/496da432c0379bc203fa517c5ac9593b.png" alt="google multisearch" data-original-src="https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-dress_Hi_res.gif"/><p id="caption-attachment-2295649" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div>
<p class="translated">有了新的多重搜索功能，你可以问一个关于你面前的物体的问题，或者根据颜色、品牌或视觉属性来优化你的搜索结果。谷歌告诉 TechCrunch，这项新功能目前在购物搜索方面有最好的结果，未来会有更多的用例。有了这个最初的测试版，你还可以做购物以外的事情，但它不会对每个搜索都是完美的。</p>
<p class="translated">实际上，这就是新功能的工作方式。假设你找到了一件你喜欢的衣服，但是不喜欢它的颜色。你可以调出一张裙子的照片，然后在搜索查询中添加“绿色”字样，就可以找到你想要的颜色。在另一个例子中，你正在寻找新家具，但想确保它与你现有的家具相得益彰。你可以给你的餐桌拍一张照片，然后在搜索查询中添加文字“coffee table”来找到一张匹配的桌子。或者，假设你有了一棵新植物，但不知道如何正确地照顾它。你可以给这种植物拍张照片，并在搜索中添加“护理说明”来了解更多信息。</p>
<p class="translated">新功能对于谷歌目前遇到困难的查询类型可能特别有用——在这种情况下，你正在寻找的东西有一个视觉组件，很难用语言来描述。通过将图片和文字组合成一个查询，谷歌可能会更好地提供相关的搜索结果。</p>
<p/><div id="attachment_2295652" class="wp-caption alignnone"><img aria-describedby="caption-attachment-2295652" decoding="async" loading="lazy" class="size-full wp-image-2295652" src="../Images/6a2ba80cda1a867469ea684b0bb7933e.png" alt="multisearch" srcset="https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png 5088w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=150,85 150w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=300,169 300w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=768,433 768w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=680,384 680w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=1536,866 1536w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=2048,1155 2048w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=1200,677 1200w, https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png?resize=50,28 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230307034813im_/https://techcrunch.com/wp-content/uploads/2022/04/Multisearch-on-Lens_heels.png"/><p id="caption-attachment-2295652" class="wp-caption-text translated"><strong>图片来源:</strong>谷歌</p></div><p class="piano-inline-promo"/>
<p class="translated">“在谷歌，我们总是在想出新的方法来帮助你发现你正在寻找的信息——无论表达你的需求有多难，”谷歌在一篇关于该声明的博客文章中说。“这就是为什么今天，我们推出了一种全新的搜索方式:同时使用文本和图像。通过 Lens 上的 multisearch，您可以超越搜索框，就您看到的内容提出问题。”</p>
<p class="translated">谷歌表示，新功能的实现得益于其在人工智能领域的最新进展。该公司还在探索如何通过其最新的人工智能搜索模型 MUM 来增强多重搜索。多任务统一模型(MUM)可以同时理解各种格式的信息，包括文本、图像和视频，并得出主题、概念和想法之间的见解和联系。</p>
<p class="translated">今天的声明是在<a href="https://web.archive.org/web/20230307034813/https://techcrunch.com/2022/03/30/google-rolls-out-a-i-improvements-to-aid-with-search-safety-and-personal-crisis-queries/">谷歌宣布</a>它将推出对其人工智能模型的改进，以使谷歌搜索更安全，更擅长处理敏感查询，包括自杀、性侵犯、药物滥用和家庭暴力等主题。它还使用其他人工智能技术来提高其从搜索结果中删除不想要的显式或暗示性内容的能力，当人们没有特别寻找这些内容时。</p>
			</div>

			</div>    
</body>
</html>