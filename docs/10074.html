<html>
<head>
<title>Intel, Arm and Nvidia propose new standard to make AI processing more efficient • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">英特尔、Arm 和英伟达提出新标准以提高人工智能处理效率 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/09/14/intel-amd-and-nvidia-propose-new-standard-to-make-ai-processing-more-efficient/">https://web.archive.org/web/https://techcrunch.com/2022/09/14/intel-amd-and-nvidia-propose-new-standard-to-make-ai-processing-more-efficient/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">英特尔、Arm 和 Nvidia 提出新标准以提高人工智能处理效率</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">为了追求更快更有效的人工智能系统开发，英特尔、Arm 和 Nvidia 今天<a href="https://web.archive.org/web/20221005154407/https://developer.nvidia.com/blog/nvidia-arm-and-intel-publish-fp8-specification-for-standardization-as-an-interchange-format-for-ai/" target="_blank" rel="noopener">发布了</a>一份他们称为人工智能通用交换格式的规范草案。虽然是自愿的，但他们表示，拟议的“8 位浮点(FP8)”标准有可能通过优化硬件内存使用和人工智能训练(即工程人工智能系统)和推理(运行系统)来加速人工智能的发展。</p>
<p class="translated">在开发人工智能系统时，数据科学家面临着关键的工程选择，而不仅仅是收集数据来训练系统。一个是选择一种格式来表示系统的权重——权重是从训练数据中学习到的影响系统预测的因素。例如，权重使得像<a href="https://web.archive.org/web/20221005154407/https://techcrunch.com/tag/gpt-3/"> GPT-3 </a>这样的系统能够从一个句子长的提示中生成整个段落，或者<a href="https://web.archive.org/web/20221005154407/https://techcrunch.com/2022/08/12/a-startup-wants-to-democratize-the-tech-behind-dall-e-2-consequences-be-damned/">达尔-E 2 </a>能够从标题中创建照片般逼真的肖像。</p>
<p class="translated">常见的格式包括半精度浮点(FP16)和单精度浮点(FP32)，前者使用 16 位来表示系统的权重，后者使用 32 位。半精度和更低精度减少了训练和运行人工智能系统所需的内存量，同时加快了计算速度，甚至减少了带宽和功耗。但是他们牺牲了一些准确性来获得这些收益；毕竟，16 位比 32 位更难处理。</p>
<p class="translated">然而，业内许多公司——包括英特尔、Arm 和 Nvidia——都将 FP8 (8 位)视为最佳选择。在一篇博客文章中，Nvidia 产品营销总监沙尔山·纳拉辛汗指出，前面提到的 FP8 格式在包括计算机视觉和图像生成系统在内的各种用例中，显示出与 16 位精度“相当的准确性”，同时提供了“显著”的加速。</p>
<p class="translated">英伟达、Arm 和英特尔表示，他们正在以一种开放的格式让他们的 FP8 格式免许可。一份白皮书对此进行了更详细的描述；Narasimhan 说，这些规范将提交给 IEEE，这是一个维护多个技术领域标准的专业组织，供以后考虑。</p>
<p class="translated">Narasimhan 表示:“我们相信，拥有一种通用的交换格式将会推动硬件和软件平台的快速发展和互操作性，从而推动计算的发展。”。</p>
<p class="translated">三人组不一定是出于他们内心的善良而推动平等。Nvidia 的 GH100 Hopper 架构原生实现了 FP8，英特尔的 Gaudi2 AI 训练芯片组也是如此。</p><p class="piano-inline-promo"/>
<p class="translated">但是，通用的 FP8 格式也将有利于像 SambaNova、AMD、Groq、IBM、Graphcore 和 Cerebras 这样的竞争对手——所有这些公司都在系统开发中试验或采用了某种形式的 FP8。在今年 7 月的一篇<a href="https://web.archive.org/web/20221005154407/https://www.graphcore.ai/posts/graphcore-and-amd-propose-8-bit-fp-ai-standard-with-qualcomm-support" target="_blank" rel="noopener">博客</a>中，Graphcore 联合创始人兼首席技术官 Simon Knowles 写道，“8 位浮点的出现为人工智能计算提供了巨大的性能和效率优势”，并断言这也是行业解决“单一、开放标准”的“机会”，而不是引入竞争格式的混合。</p>
			</div>

			</div>    
</body>
</html>