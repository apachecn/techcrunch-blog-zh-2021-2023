<html>
<head>
<title>Regulating the future: A look at the EU's plan to reboot product liability rules for AI | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">监管未来:看看欧盟重启人工智能产品责任规则的计划</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/11/04/eu-ai-liability-directive-product-liability-directive/amp/">https://web.archive.org/web/https://techcrunch.com/2022/11/04/eu-ai-liability-directive-product-liability-directive/amp/</a></blockquote><div><div class="content">

			
	
		
		

		
<p class="amp-featured-image translated"><amp-img src="https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?w=1024" class="breakout attachment-post-thumbnail size-post-thumbnail wp-post-image amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="Digital transformation concept. Binary code. AI (Artificial Intelligence)." srcset="https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg 2253w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=150,89 150w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=300,177 300w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=768,453 768w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=680,401 680w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=1536,907 1536w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=2048,1209 2048w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=1200,708 1200w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=50,30 50w" layout="intrinsic" i-amphtml-layout="intrinsic"> <i-amphtml-sizer class="i-amphtml-sizer"> <img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/> </i-amphtml-sizer> <noscript> <img src="../Images/3846f29a1a0207a44676a050a2fcb07d.png" class="breakout attachment-post-thumbnail size-post-thumbnail wp-post-image" alt="Digital transformation concept. Binary code. AI (Artificial Intelligence)." decoding="async" loading="lazy" srcset="https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg 2253w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=150,89 150w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=300,177 300w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=768,453 768w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=680,401 680w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=1536,907 1536w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=2048,1209 2048w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=1200,708 1200w, https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?resize=50,30 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230307025157im_/https://techcrunch.com/wp-content/uploads/2021/05/GettyImages-1271697775.jpg?w=1024"/> </noscript> </amp-img></p><p class="translated"><strong>图片来源:</strong> metamorworks / Getty Images</p><p class="translated">最近提交的欧盟<a href="https://web.archive.org/web/20230307025157/https://techcrunch.com/2022/09/28/eu-ai-liability-directive/">计划为数字时代更新长期存在的产品责任规则</a>——包括解决人工智能(AI)和自动化使用的增加——立即遭到欧洲消费者组织<a href="https://web.archive.org/web/20230307025157/https://www.beuc.eu/" target="_blank" rel="noopener"> BEUC </a>的一些抨击，该组织认为这一更新是一种降级，认为欧盟消费者在人工智能服务造成的伤害方面的保护不如其他类型的产品。</p>
<p class="translated">对于人工智能驱动的各种伤害和风险，可能会推动对强大责任保护的需求，仅在上个月<a href="https://web.archive.org/web/20230307025157/https://techcrunch.com/2022/10/26/no-to-voight-kampff-tests/">英国的数据保护监管机构就对声称执行“情绪分析”的伪科学人工智能系统发出了全面警告——敦促这种技术不应用于纯粹娱乐之外的任何事情。而在公共部门方面，早在 2020 年</a><a href="https://web.archive.org/web/20230307025157/https://techcrunch.com/2020/02/06/blackbox-welfare-fraud-detection-system-breaches-human-rights-dutch-court-rules/"/>，一家荷兰法院发现一项针对社会保障申请人的算法福利风险评估违反了人权法。此外，在最近几年，联合国也对公共服务自动化带来的人权风险发出了警告。此外，美国法院使用黑盒人工智能系统做出量刑决定——不透明地烘烤偏见和歧视——多年来一直是一种反人类的技术犯罪<a href="https://web.archive.org/web/20230307025157/https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/" target="_blank" rel="noopener">。</a></p>
<p class="translated">代表 32 个国家 46 个独立消费者组织的伞式消费者组织 BEUC 多年来一直呼吁更新欧盟责任法，以考虑人工智能日益增长的应用，并确保消费者保护法不会被超越。但它对欧盟提议的政策包的看法——包括对现有产品责任指令(PLD)的调整，以便它涵盖软件和人工智能系统(以及其他变化)；新的人工智能责任指令(AILD)旨在解决自动化带来的更广泛的潜在危害，但它没有实现它所倡导的更全面的改革方案。</p>
<p class="translated">“新规则在一些领域取得了进展，但在其他领域还不够，对于人工智能驱动的服务来说太弱了，”它在 9 月<a href="https://web.archive.org/web/20230307025157/https://techcrunch.com/2022/09/28/eu-ai-liability-directive/">日</a>对委员会提议的首次回应中警告说。“与传统的产品责任规则相反，如果消费者受到人工智能服务运营商的伤害，他们需要证明错误在于运营商。考虑到人工智能系统是多么不透明和复杂，这些条件将使消费者事实上不可能使用他们获得损害赔偿的权利。”</p>
<p class="translated">“责任规则必须跟上这样一个事实，即我们越来越多地被数字和人工智能驱动的产品和服务所包围，如家庭助手或基于个性化定价的保险单。然而，当涉及到人工智能服务时，消费者将得不到很好的保护，因为他们必须证明运营商有过错或疏忽，才能要求损害赔偿，”副总干事 Ursula Pachl 在一份回应委员会提案的附带声明中补充道。</p>
<p class="translated">“要求消费者这样做确实令人失望。<span lang="EN-US">在一个高度复杂和晦涩难懂的“黑箱”人工智能系统的世界里，消费者几乎不可能使用新规则。因此，如果割草机在花园里撕碎了消费者的鞋子，他们将得到更好的保护，而不是通过信用评分系统受到不公平的歧视。”</span></p>
<p class="translated">鉴于人工智能的持续快速传播——通过“个性化定价”等功能，甚至是最近人工智能生成的图像的爆炸——可能会有一天某种形式的自动化成为产品和服务的规则而不是例外——如果 BEUC 的担忧是有根据的，那么就有风险<em>对欧盟约 4.47 亿公民的产品责任保护大规模降级。</em></p>
<p class="translated">在讨论其对这些提议的反对意见时，BEUC 的高级法律官员 Frederico Oliveira Da Silva 提出了另一个问题，涉及 AILD 如何明确引用委员会早先提出的一个基于风险的框架来监管人工智能应用的提议，即<a href="https://web.archive.org/web/20230307025157/https://techcrunch.com/2021/04/21/europe-lays-out-plan-for-risk-based-ai-rules-to-boost-trust-and-uptake/"> AI Act </a>，暗示消费者需要证明违反了该规定，才能根据 AILD 提起诉讼。</p>

<p class="translated">尽管有这种联系，这两项立法草案并不是由委员会同时提交的——它们的提交之间有大约 1.5 年的时间<a href="https://web.archive.org/web/20230307025157/https://techcrunch.com/2021/04/21/europe-lays-out-plan-for-risk-based-ai-rules-to-boost-trust-and-uptake/">——BEUC 担心，这造成了不连贯的立法轨道，可能会导致不一致并增加复杂性。</a></p>
<p class="translated">例如，它指出，《人工智能法》是针对监管机构的，而不是消费者的——鉴于《人工智能法》中包含的欧盟规则确定人工智能制造商应该如何记录他们的系统以符合监管要求，这可能会因此限制人工智能责任指令中拟议的新信息披露权的效用——换言之，消费者可能很难理解他们根据 AILD 的披露权可以获得的技术文件，因为这些信息是为了提交给监管机构而不是普通用户。</p>
<p class="translated">在提交赔偿责任方案时，欧盟司法专员也直接提到了“高风险”人工智能系统——使用了《人工智能法》中包含的一种特定分类，这似乎暗示只有一部分人工智能系统将承担责任。然而，当被问及 AILD 下的责任是否将仅限于人工智能法案中的“高风险”人工智能系统(代表人工智能潜在应用的一小部分)时，迪迪埃·雷德斯说，这不是委员会的意图。很困惑吗？</p>
<p class="translated">BEUC 认为，一个脱节的政策组合有可能——至少——在本应整合在一起、发挥整体功能的规则之间引入不一致。它还可能破坏赔偿责任的适用和获得，因为它为消费者能够行使其权利创造了一个更加复杂的途径。虽然不同的立法时间表明，监管人工智能的一个相关联的一揽子计划将在另一个之前获得通过，但这可能会为消费者同时获得人工智能导致的伤害的赔偿开辟一个缺口。</p>
<p class="translated">就目前情况而言,《大赦国际法》和一揽子赔偿责任仍在通过欧盟的共同立法程序，因此在成为欧盟法律之前，许多内容仍有可能发生变化。</p>
<h2 class="translated">AI 服务盲区？</h2>
<p class="translated">BEUC 总结了其对委员会更新长期存在的欧盟责任规则的出发点的担忧，警告说该提案为消费者创造了一个“人工智能服务盲点”，并且未能“走得足够远”以确保在所有情况下提供强大的保护——因为某些类型的人工智能伤害将为消费者实现补救带来更高的障碍，因为它们不属于更广泛的 PLD。(特别是与基本权利相关的“非物质”伤害，如歧视或数据丢失，将纳入《AILD》。)</p>
<p class="translated">就其本身而言，委员会强烈反对这种对人工智能系统包中“盲点”的批评。尽管欧盟的共同立法者，理事会和议会，是否会寻求对一揽子计划进行修改——甚至进一步调整人工智能法案以改善一致性——仍有待观察。</p>
<p class="translated">在提交修改欧盟产品责任规则提案的新闻发布会上，欧盟委员会重点关注其声称将支持消费者成功规避“黑盒”人工智能可解释性问题的前景化措施——特别是引入新的披露要求(使消费者能够获得数据以证明责任)；以及可反驳的因果关系推定(降低立案门槛)。它的基调是，总体而言，该方案解决了“与人工智能相关的具体举证困难，并确保合理的主张不受阻碍”。</p>
<p class="translated">虽然欧盟执行机构没有详细说明为什么它没有提出与 PLD 相同的严格责任制度来全面解决人工智能责任——而是选择了一个消费者仍然必须证明合规失败的系统——但很明显，欧盟责任法并不是欧盟 27 个成员国重新讨论/达成共识的最容易的文件(PLD 本身可以追溯到 1985 年)。因此，委员会可能认为这是使产品责任规则现代化的破坏性最小的方式，而不会打开国家法律的更棘手的潘多拉盒子，这将需要扩大 PLD 中允许的伤害类型。</p>
<p class="translated">“人工智能责任指令没有提出基于过失的责任体系，而是有针对性地协调了现有国家基于过失的责任制度的某些条款，以确保人工智能系统造成的损害的受害者受到的保护不会少于任何其他损害的受害者，”当我们对 BEUC 的批评提出批评时，一位委员会发言人告诉我们。“在稍后阶段，委员会将评估这些措施对受害者保护和吸收人工智能的影响。”</p>
<p class="translated">“新的产品责任指令为所有产品建立了严格的责任制度，这意味着没有必要为了获得赔偿而证明某人有过错，”它继续说道。“委员会没有提出降低对受到人工智能系统伤害的人的保护水平:新的产品责任指令将涵盖所有产品，包括所有类型的软件、应用程序和人工智能系统。鉴于[拟议更新的]产品责任指令并不涵盖服务提供的缺陷，就像当前的产品责任指令一样，当产品对自然人造成重大损害时，它仍将适用于所有产品，无论它们是否在提供服务的过程中使用。</p>
<p class="translated">“因此，委员会全面地看待这两个责任支柱，并旨在确保对人工智能受害者的保护水平与因任何其他原因造成的损害相同。”</p>
<p class="translated">委员会还强调,<span lang="EN-US">人工智能<span class="il">责任</span>指令涵盖了更广泛的损害赔偿——由人工智能支持的产品和服务“如信用评分、保险排名、招聘服务等。，在人工智能解决方案的基础上开展此类活动”。</span></p>
<p class="translated">“关于产品责任指令，它一直有一个明确的目的:制定补偿规则，以解决产品生产中的风险，”它补充说，为保持 PLD 对有形伤害的关注进行辩护。</p>
<p class="translated">当被问及欧洲消费者如何理解他们在 AILD 使用披露权可能获得的关于人工智能系统的高技术数据时，欧盟委员会建议，<span lang="EN-US">从潜在被告那里获得人工智能系统信息的受害者——在请求法院命令“披露或保存相关证据”后——应该寻求相关专家的帮助。</span></p>
<p class="translated">“如果披露的文件过于复杂，消费者无法理解，消费者将能够像在任何其他法庭案件中一样，在法庭案件中受益于专家的帮助。根据民事诉讼费用分配的国家规则，如果责任索赔是合理的，被告将承担专家的费用，”它告诉我们。</p>
<p class="translated">“根据产品责任指令，受害者可以要求制造商提供任何产品的相关信息，这些产品已经造成了产品责任指令所涵盖的损害。这些信息，例如交通事故前的数据记录，可以证明对受害者的法律团队非常有用，以确定车辆是否有缺陷，”委员会发言人补充说。</p>
<p class="translated">关于建立单独的立法轨道的决定，其中一个包含 AILD + PLD 更新包，另一个是早期的 AI 法案提案轨道，欧盟委员会表示，它正在根据欧洲议会的一项决议采取行动，该决议要求它将前两个部分一起准备，“以便以一致的方式调整 AI 的责任规则”，并补充说:“在与成员国和利益相关者的讨论中也提出了同样的请求。因此，委员会决定提出一个责任立法包，将两个提案放在一起，而不是将通过人工智能责任指令提案与启动人工智能法案提案联系起来。”</p>
<p data-amp-original-style="font-weight: 400;" class="amp-wp-fe3f5cc translated">“关于《人工智能法》的谈判取得了更大进展，这一事实只会带来好处，因为《人工智能责任指令》提到了《人工智能法》的条款，”该委员会进一步指出。</p>
<p data-amp-original-style="font-weight: 400;" class="amp-wp-fe3f5cc translated">它还强调《大赦国际法》属于 PLD 制度——再次否认任何“漏洞或不一致”的风险。</p>
<p data-amp-original-style="font-weight: 400;" class="amp-wp-fe3f5cc translated">“PLD 于 1985 年通过，甚至早于大多数欧盟安全立法的通过。无论如何，PLD 没有提及《大赦国际法》的具体条款，因为整个立法都属于其管辖范围，它不受制于也不依赖于《大赦国际法》本身的谈判，因此不存在漏洞或与 PLD 不一致的风险。事实上，根据 PLD，消费者不需要证明违反了 AI 法案就可以获得人工智能系统造成的损害赔偿，只需要证明损害是由系统缺陷造成的，”它说。</p>
<p class="translated">最终，欧盟委员会更新欧盟产品责任规则以应对快速扩展的自动化的方法是有根本缺陷还是完美平衡的真相可能介于两种立场之间。但是欧盟在试图监管这些东西方面走在了曲线的前面——所以在中间的某个地方着陆可能是目前最合理的策略。</p>
<h2 class="translated">规范未来</h2>
<p class="translated">毫无疑问，欧盟立法者正在接受监管快速发展的未来的挑战。因此，仅仅通过提出人工智能的规则，欧盟就明显远远领先于其他司法管辖区——这当然带来了自己的陷阱，但也可以说，允许立法者有一些回旋的空间来解决(和重复)应用中的问题。毕竟，法律如何实施也是欧洲法院的事情。</p>
<p class="translated">公平地说，该委员会似乎正试图在过于严厉和抑制新的人工智能驱动服务的发展之间达成平衡——同时张贴足够醒目的<em>警告标志，以使技术专家关注消费者风险，并试图防止问责“黑洞”让伤害失控。</em></p>
<p class="translated">《人工智能法案》本身显然旨在作为一个核心预防框架，通过迫使系统开发人员预先考虑信任和安全问题，并威胁对不遵守行为进行处罚，来减少尖端技术的某些应用带来的风险和伤害。但责任制度建议进一步强化这一框架，为那些不遵守规则的人增加损害赔偿诉讼的风险。这样做的方式甚至可能鼓励过度遵守《人工智能法》——鉴于“低风险”应用程序通常不会面临该框架下的任何具体监管(但可能面临更广泛的人工智能责任条款下的责任)。</p>
<p class="translated">因此，人工智能系统的制造商和应用者可能会感到被迫采用欧盟关于人工智能的监管“最佳实践”，以抵御被消费者起诉的风险，这些消费者拥有从他们的系统中提取数据的新权力和可反驳的因果关系推定，这使他们有责任证明事实并非如此。</p>
<p class="translated">同样即将到来的是明年:执行欧盟新的集体赔偿指令，规定在整个欧盟范围内提起集体消费者诉讼。该指令已经制定了几年，但欧盟成员国需要在 12 月底之前通过并公布必要的法律和规定，并计划在 2023 年年中开始执行。</p>
<p class="translated">这意味着整个欧盟的消费者诉讼数量将会上升，这也肯定会使人们集中精力关注监管合规性。</p>
<p class="translated">在讨论欧盟最新的责任方案时，国际律师事务所 TaylorWessing 的产品责任和产品安全负责人 Katie Chandler 强调，AILD 中包含的信息披露义务对消费者来说是一个“非常重要”的发展，同时指出，该方案作为一个整体将需要消费者做一些跑腿工作，以“了解他们要走哪条路，他们要找谁”；例如，他们是起诉 PLD 的人工智能系统有缺陷，还是起诉 AILD 的人工智能系统侵犯了基本权利。(嗯，有一件事看起来是肯定的:律师将会做更多的工作来帮助消费者处理从危险技术中获得损害赔偿的不断扩大的赔偿选择。)</p>
<p class="translated">钱德勒告诉 TechCrunch:“这一新的披露义务非常重要，非常新，本质上来说，如果制造商或软件开发商无法证明他们遵守了安全法规——我认为，这可能意味着人工智能法案下的要求——那么在这些情况下，因果关系是推定的，我认为这是朝着试图帮助消费者更容易提起索赔迈出的真正一步。”</p>
<p class="translated">“然后在 AILD，我认为它的范围更广——因为它与人工智能系统的操作员有关[例如，自动送货车/无人机等的操作员]——用户/操作员很可能没有应用合理的技能和注意，没有仔细遵循说明，或者没有正确操作，然后你就可以在 AILD 下继续下去。”</p>
<p class="translated">“到目前为止，我的观点是，我认为一揽子措施作为一个整体确实为不同类型的损害提供了不同的追索权。PLD 下的严格责任损害更直接——因为无过失制度——但确实涵盖了软件和人工智能系统，并涵盖了[某些类型的损害]，但如果你有这种其他类型的损害[如侵犯基本权利]，他们的目的是说这些将由 AILD 涵盖，然后绕过证明损害是由系统引起的担忧，这些可反驳的假设开始发挥作用，“她补充说。</p>
<p class="translated">“老实说，我确实认为这对消费者来说是一个非常重要的进步，因为一旦实施，科技公司现在将需要在发生特定类型的损害和损失时对消费者进行赔偿。他们将不能争辩说他们不适合现在的体制——我认为这是一个重大的变化。</p>
<p class="translated">“任何在欧洲运营的明智的科技公司都会仔细研究这些问题，并为它们制定计划，必须认真对待人工智能法案。”</p>
<p class="translated">欧盟提出的两条支持消费者对不同类型的人工智能损害进行赔偿的途径在实践中是否有效，显然将取决于应用。因此，对疗效的全面分析可能需要该机制运行数年，以评估它是如何工作的，以及是否存在人工智能盲点。</p>
<p class="translated">但泰勒韦辛汉堡办公室的合伙人菲利普·贝伦特博士也对改革如何将责任扩大到缺陷软件和人工智能做出了乐观的评估。</p>
<p class="translated"><span data-amp-original-style="font-size: 1rem; letter-spacing: -0.1px;" class="amp-wp-c9d2de0">“根据现行的产品责任法，软件不被视为产品。这意味着，如果消费者遭受了软件造成的损害，他或她不能根据产品责任法获得赔偿。然而，如果软件被用在例如汽车上，并且汽车对消费者造成了损害，这就属于产品责任法的范围，如果使用人工智能软件，情况也是如此。这意味着消费者可能更难对人工智能产品提出索赔，但这是因为根据产品责任指令，软件有一般例外，”他告诉 TechCrunch。</span></p>
<p data-amp-original-style="font-weight: 400;" class="amp-wp-fe3f5cc translated">“在未来的规则下，产品责任规则也将涵盖软件，在这种情况下，人工智能根本不会受到区别对待。重要的是，人工智能指令不建立索赔，而只是通过引入因果关系假设来帮助消费者，在人工智能系统的故障和造成的损害之间建立因果联系，以及关于特定高风险人工智能系统的披露义务。因此，BEUC 批评欧盟委员会提出的制度将意味着欧洲消费者对使用人工智能产品和非人工智能产品的保护水平较低，这似乎是对产品责任制度的误解。”</p>
<p class="translated">钱德勒还预测说:“以他们提议的方式采用这两种方法——取决于这些反驳推定和披露要求是否足以让责任人承担责任——可能会以合理的方式给出不同类型损害的路径。”。“但我认为这一切都在申请中。这一切都取决于法院如何解释这一点，法院如何适用披露义务等事项，以及这些可反驳的推定实际上如何有所帮助。”</p>
<p class="translated">“在我看来，这在法律上是合理的，真的，因为有不同类型的损害……而且,( AILD)会遇到其他类型的情况——比如，当涉及到数据丢失时，你将如何处理侵犯我的基本权利的情况，”她补充道。“我很难理解 PLD 是如何做到这一点的，因为这不是 PLD 的设计初衷。但 AILD 给出了这条路线，并包括类似的推定——反驳推定——所以它确实走了一段路。”</p>
<p class="translated">她还表示支持欧盟立法者寻求平衡的必要性。“当然，硬币的另一面是创新，以及在消费者保护和创新之间取得平衡的必要性——以及以更正式的方式将[人工智能]纳入严格责任制度会如何，这会对创业公司产生什么影响？或者这将如何影响人工智能系统的迭代——我认为，这可能也是[委员会]面临的挑战，”她说，并补充说:“尽管大多数人会同意需要谨慎的平衡，但我会这样做。”</p>
<p class="translated">虽然英国不再是欧盟成员，但她表示，当地立法者将热衷于在加强消费者保护和鼓励英国任何责任改革的技术发展之间促进类似的平衡，她暗示:“如果[英国]做出任何明显不同的事情，我会感到惊讶，并说对人工智能发展和潜在被告背后的相关各方来说更困难，因为我会认为他们希望获得同样的平衡。”</p>
<p class="translated">与此同时，欧盟继续在全球范围内领导监管科技的工作——目前正在积极推进重启人工智能时代的产品责任规则，钱德勒指出，例如，它为回应委员会的提议提供了相对较短的反馈期(她认为这意味着像 BEUC 这样的批评在短期内可能不会产生太多的思考)。她还强调了欧盟需要多长时间才能获得一份关于更新债务的提案草案——这一因素可能会为现在已经摆在桌面上的一揽子计划提供额外的动力。</p>
<p class="translated">“我不确定 BEUC 会在这里得到他们想要的东西。我认为他们可能需要等待，看看这是如何应用的，”她建议道，并补充说:“我认为委员会的策略将是把这些包放在适当的位置——显然你已经在背景中获得了集体赔偿指令，这也是相关的，因为你可以很好地看到与失败的人工智能系统和产品责任有关的集体行动——并通常看到这如何满足消费者获得他们需要的赔偿的需要。到那时，不管多少年后，他们都会重新审视它，再次审视它。”</p>
<p class="translated">展望未来，随着人工智能服务越来越深入到一切事物中，欧盟可能会决定需要通过扩大严格的责任制度来纳入人工智能系统，从而进行更深入的改革。但这将留给未来的迭代过程，以允许我们人类和前沿之间更多的相互作用。钱德勒预测道:“那将是几年后的事了。”。“我认为这将需要一些在实践中如何应用的经验，以找出差距，找出可能存在一些弱点的地方。”</p>




		

			
	
		

			<amp-pixel src="https://web.archive.org/web/20230307025157im_/https://ampmetrics.techcrunch.com/pixel.gif" placeholder="" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>
		<amp-analytics data-credentials="include" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed">
		
	</amp-analytics>
	<amp-pixel src="https://web.archive.org/web/20230307025157im_/https://pixel.wp.com/g.gif?v=ext&amp;blog=136296444&amp;post=2426054&amp;tz=-8&amp;srv=techcrunch.com&amp;host=techcrunch.com&amp;rand=RANDOM&amp;ref=DOCUMENT_REFERRER" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_googleanalytics" type="googleanalytics" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_comscore" type="comscore" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_parsely" type="parsely" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>	</div>

</div>    
</body>
</html>