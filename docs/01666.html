<html>
<head>
<title>TikTok to diversify its 'For You' feed, let users pick the topics they want to avoid | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">抖音将“为了你”的内容多样化，让用户选择他们不想谈论的话题</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2021/12/16/tiktok-to-diversify-its-for-you-feed-let-users-pick-the-topics-they-want-to-avoid/">https://web.archive.org/web/https://techcrunch.com/2021/12/16/tiktok-to-diversify-its-for-you-feed-let-users-pick-the-topics-they-want-to-avoid/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">抖音<a href="https://web.archive.org/web/20230316161010/https://newsroom.tiktok.com/en-us/an-update-on-our-work-to-safeguard-and-diversify-recommendations" target="_blank" rel="noopener">今天早上宣布</a>它将采用一种新的方法来实现它的“为了你”( For You)feed——这个简短视频应用的主要 feed，由它的算法推荐驱动。该公司<a href="https://web.archive.org/web/20230316161010/https://techcrunch.com/2020/06/18/tiktok-explains-how-the-recommendation-system-behind-its-for-you-feed-works/">已经详细介绍了</a>的算法如何根据用户在应用程序中的参与模式来推荐视频，但承认过多的特定内容类别可能会“有问题”该公司现在表示，它正在努力实施新技术，以中断其应用程序上的“重复模式”，并且还在开发一种工具，允许用户在这件事上有发言权，让他们选择他们想要避免的话题。</p>
<p class="translated">该公司在声明中解释说，“太多的东西，无论是动物、健身技巧还是个人健康之旅，都不符合我们旨在创造的多样化发现体验。”然而，抖音并没有使其算法多样化，因为人们抱怨看到太多可爱的小狗视频——它这样做是因为监管机构正在打击技术，并质疑未经检查的推荐算法的有害影响，特别是在青少年心理健康方面。</p>
<p class="translated"><a href="https://web.archive.org/web/20230316161010/https://techcrunch.com/2021/09/30/facebook-grilled-in-senate-hearing-over-teen-mental-health/">脸书</a>和<a href="https://web.archive.org/web/20230316161010/https://techcrunch.com/2021/12/08/instagrams-adam-mosseri-senate-hearing-teen-safety/"> Instagram </a>的高管，以及来自<a href="https://web.archive.org/web/20230316161010/https://techcrunch.com/2021/10/26/tiktok-snap-youtube-hearing-congress/">其他社交平台</a>的高管，已经被传唤到国会，并被质疑他们的应用程序如何将用户导向危险的内容——例如，包括支持厌食症和饮食失调的内容。</p>
<p class="translated">抖音在声明中提到了如果过度观看可能有害的视频类型，包括“极端节食或健身”、“悲伤”和“分手”主题的视频。虽然对这种性质的视频感兴趣的用户可能会觉得它们很有趣，但算法还不够智能，无法知道重复地指导用户更多相同的视频实际上可能会对用户造成伤害。当然，这个问题不仅限于抖音。总的来说，越来越明显的是，那些旨在通过自动化手段增加用户参与度的系统会以牺牲用户的心理健康为代价。虽然国会目前最感兴趣的是这些系统如何影响年轻人，但一些研究表明，未经检查的推荐算法也可能在 T2 使可能被吸引到极端观点的用户变得激进方面发挥作用。</p>
<p class="translated">抖音表示，它还将测试新的方法，以避免在用户观看和参与这些潜在有害类型的视频时推荐一系列类似的内容。但它只是提供了它将限制的视频类型的例子，而不是一个完整的列表。</p>
<p class="translated">此外，该公司表示，它正在开发一种技术，可以帮助它识别用户的“为你”页面何时不是非常多样化。虽然用户可能不会观看实际违反抖音政策的视频，但该公司表示，观看“非常有限类型的内容……可能会产生负面影响，如果这是某人观看的大部分内容，如关于孤独或减肥的内容。”</p>
<p class="translated"><span>抖音计划推出的另一个策略包括一个新功能，允许人们自己指导算法。他们可以使用这个功能来选择与他们不想在“For You”提要中看到的内容相关的单词或标签。这将是对抖音现有工具的补充，例如通过点击“不感兴趣”来标记你不喜欢的视频。</span></p><p class="piano-inline-promo"/>
<p class="translated">需要说明的是，抖音今天的声明仅仅是展示了其计划的路线图，而不是这些变化和功能的实际发布。相反，这是试图阻止监管机构对其应用程序及其潜在有害影响的进一步调查。它的策略很可能受到在国会听证会和竞争对手听证会上被问到的问题类型的影响。</p>
<p class="translated">抖音指出，实际的实现可能需要时间和反复，才能把事情做好。</p>
<p class="translated">“我们将继续研究如何确保我们的系统提供多样化的建议，”该公司指出。</p>
			</div>

			</div>    
</body>
</html>