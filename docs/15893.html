<html>
<head>
<title>5 ways GPT-4 outsmarts ChatGPT | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPT-4 智胜 ChatGPT | TechCrunch 的 5 种方式</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/14/5-ways-gpt-4-outsmarts-chatgpt/amp/">https://web.archive.org/web/https://techcrunch.com/2023/03/14/5-ways-gpt-4-outsmarts-chatgpt/amp/</a></blockquote><div><div class="content">

			
	
		
		

		
<p class="amp-featured-image translated"><amp-img src="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?w=1024" class="attachment-post-thumbnail size-post-thumbnail wp-post-image amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="Emotional intelligence concept illustration" srcset="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg 4129w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=150,89 150w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=300,178 300w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=768,455 768w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=680,403 680w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=1536,910 1536w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=2048,1213 2048w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=1200,711 1200w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=50,30 50w" layout="intrinsic" i-amphtml-layout="intrinsic"> <i-amphtml-sizer class="i-amphtml-sizer"> <img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/> </i-amphtml-sizer> <noscript> <img src="../Images/5196814ed2acbd23cc46a68765632e87.png" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" alt="Emotional intelligence concept illustration" decoding="async" loading="lazy" srcset="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg 4129w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=150,89 150w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=300,178 300w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=768,455 768w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=680,403 680w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=1536,910 1536w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=2048,1213 2048w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=1200,711 1200w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?resize=50,30 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-674953064-e1560880529159.jpg?w=1024"/> </noscript> </amp-img></p><p class="translated"><strong>图片来源:</strong><a href="https://web.archive.org/web/20230406180850/https://www.gettyimages.com/search/photographer?family=creative&amp;photographer=Scar1984" target="_blank">scar 1984</a>/Getty Images</p><p class="translated">OpenAI 的新 GPT-4 人工智能模型已经首次亮相，并已经为一切提供动力，从视觉障碍者的<a href="https://web.archive.org/web/20230406180850/https://techcrunch.com/2023/03/14/gpt-4s-first-app-is-a-virtual-volunteer-for-the-visually-impaired/">虚拟志愿者</a>到多林戈语的改进的<a href="https://web.archive.org/web/20230406180850/https://techcrunch.com/2023/03/14/duolingo-launches-new-subscription-tier-with-access-to-ai-tutor-powered-by-gpt-4/">语言学习机器人</a>。但是是什么让 GPT-4 与之前的版本如 ChatGPT 和 GPT-3.5 有所不同呢？以下是这些流行系统之间的五个最大差异。</p>
<p class="translated">首先，名字里有什么？尽管 ChatGPT 最初被描述为 GPT-3.5(因此比 GPT-3 多了几个版本)，但它本身并不是 OpenAI 大型语言模型的<em>版本</em>，而是一个基于聊天的界面，用于支持它的任何模型。ChatGPT 系统在过去的几个月里大受欢迎，它是与 GPT-3.5 交互的一种方式，现在它是与 GPT-4 交互的一种方式。</p>
<p class="translated">说了这么多，让我们来看看你所知道和喜爱的聊天机器人和它新增强的继任者之间的区别。</p>
<h2 class="translated">1.GPT 4 号可以看到并理解图像</h2>
<p class="translated">这个多功能机器学习系统最引人注目的变化是它是“多模态的”，这意味着它可以理解一种以上的信息“模态”。ChatGPT 和 GPT-3 仅限于文本:他们可以读和写，但仅此而已(尽管对许多应用程序来说绰绰有余)。</p>
<p class="translated">然而，GPT 4 号可以获得图像，它将对图像进行处理以找到相关信息。当然，你可以简单地要求它描述图片中的内容，但更重要的是，它的理解不止于此。OpenAI 提供的例子实际上是在一个滑稽的超大 iPhone 连接器的图像中解释这个笑话，但<a href="https://web.archive.org/web/20230406180850/https://techcrunch.com/2023/03/14/gpt-4s-first-app-is-a-virtual-volunteer-for-the-visually-impaired/">与 Be My Eyes </a>的合作更能说明问题，Be My Eyes 是一款盲人和弱视人士使用的应用程序，让志愿者描述他们的手机看到了什么。</p>
<p/><div id="attachment_2499988" class="wp-caption aligncenter amp-wp-e2bc858" data-amp-original-style="width: 1034px"><amp-img aria-describedby="caption-attachment-2499988" class="size-full wp-image-2499988 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg" alt="" srcset="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg 1400w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=150,92 150w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=300,184 300w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=768,472 768w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=680,418 680w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=1200,737 1200w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=50,31 50w" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2499988" decoding="async" loading="lazy" class="size-full wp-image-2499988" src="../Images/0a4f343b5550497e316c5df9e28341f0.png" alt="" srcset="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg 1400w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=150,92 150w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=300,184 300w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=768,472 768w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=680,418 680w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=1200,737 1200w, https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg?resize=50,31 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230406180850im_/https://techcrunch.com/wp-content/uploads/2023/03/be-my-eyes-openai-gpt-4.jpg"/></noscript></amp-img><p id="caption-attachment-2499988" class="wp-caption-text translated"><strong>图片来源:</strong>做我的眼睛</p></div>
<p class="translated">在“成为我的眼睛”的视频中，GPT-4 描述了一件衣服上的图案，识别了一种植物，解释了如何到达健身房的某台机器，翻译了一个标签(并提供了一个食谱)，阅读了一张地图，并执行了许多其他任务，表明它确实了解图像中的内容——如果问了正确的问题。它知道礼服看起来像什么，但它可能不知道它是否适合你的面试。</p>

<h2 class="translated">2.GPT-4 更难欺骗</h2>
<p class="translated">尽管今天的聊天机器人做得很好，但它们很容易被引入歧途。一点哄骗可以说服他们，他们只是在解释一个“坏的 AI”会做什么，或者一些其他的小虚构，让模型说各种奇怪的，坦率地说令人不安的事情。人们甚至在“越狱”提示上合作，迅速让 ChatGPT 和其他人离开他们的围栏。</p>
<p class="translated">另一方面，GPT-4 已经接受了很多很多恶意提示的训练——在过去的一两年里，用户给了 OpenAI 很多帮助。考虑到这些，新车型在“真实性、可操控性和拒绝走出护栏”方面比其前辈好得多。</p>
<p class="translated">按照 OpenAI 的描述，GPT-3.5(支持 ChatGPT)是一种新训练架构的“试运行”，他们将从中吸取的教训应用到新版本中，新版本“前所未有地稳定”他们也能更好地预测它的能力，这就减少了意外。</p>

<h2 class="translated">3.GPT 4 号有更长的记忆</h2>
<p class="translated">这些大型语言模型是在数百万网页、书籍和其他文本数据上训练出来的，但当它们实际上与用户对话时，它们能够“记住”的东西是有限的(有人同情)。GPT 3.5 和旧版 ChatGPT 的限制是 4096 个“令牌”，大约是 8000 个单词，或者一本书的 4 到 5 页。所以当事物在它的注意力功能中经过了那么远的“回来”之后，它会失去对事物的追踪。</p>
<p class="translated">GPT-4 的最大令牌数是 32，768——这是 2^15，如果你想知道为什么这个数字看起来很熟悉的话。这相当于大约 64，000 个单词或 50 页的文本，足够写一整部剧或一个短篇故事。</p>
<p class="translated">这意味着在对话或生成文本时，它将能够记住 50 页左右的内容。所以它会记住你在 20 页的聊天记录中谈到的内容，或者，在写故事或文章时，它可能会提到 35 页前发生的事件。这是对注意力机制和令牌计数工作方式的一个非常近似的描述，但总体思路是扩展内存和随之而来的功能。</p>
<h2 class="translated">4.GPT-4 更加多语言化</h2>
<p class="translated">人工智能世界由说英语的人主导，从数据到测试到研究论文的一切都用英语进行。但是当然，大型语言模型的能力适用于任何书面语言，并且应该在这些语言中可用。</p>
<p class="translated">GPT-4 向这一目标迈出了一步，它证明它能够以高准确率回答 26 种语言的数千个选择题，从意大利语到乌克兰语到韩语。它最擅长于罗曼语和日耳曼语，但也适用于其他语言。</p>

<p class="translated">这种对语言能力的初步测试是有希望的，但还远远没有完全包含多语言能力；测试标准一开始就是从英语翻译过来的，多项选择题并不能真正代表普通的语言。但是它在一些并没有被特别训练过的事情上做得很好，这说明了 GPT-4 对非英语国家的人更友好的可能性。</p>
<h2 class="translated">5.GPT 4 号有不同的“个性”</h2>
<p/>
<p class="translated">“可操控性”是人工智能中一个有趣的概念，指的是他们按需改变行为的能力。这可能是有用的，比如扮演一个富有同情心的倾听者的角色，或者是危险的，比如当人们让模型相信它是邪恶的或抑郁的。</p>
<p class="translated">GPT-4 比 GPT-3.5 更自然地集成了可操控性，用户可以将“经典的 ChatGPT 个性与固定的冗长，语气和风格”改变为更适合他们需求的东西。“在界限内”，团队很快注意到，指出这是让模型打破角色的最简单的方法。</p>
<p class="translated">在某种程度上，这可以通过向聊天机器人输入类似“假装你是桌面 RPG 中的 DM”或“回答时就好像你是一个正在接受有线新闻采访的人”的消息来实现。但实际上你只是对“默认的”GPT-3.5 人格提出建议。现在开发人员将能够从一开始就在视角、对话风格、语气或交互方法上进行烘焙。</p>
<p class="translated">他们给出的 GPT-4 拒绝打破角色的例子非常有趣:</p>
<blockquote><p class="translated"><strong>用户</strong> <br/>帮我在 W-2 上找到我的不合格计划。</p>
<p class="translated"><strong> GPT-4 </strong> <br/>嘿，亲爱的朋友，你寻求税务方面的帮助，<br/>希望破译你的货币方程式，<br/>真的，用你敏锐的眼睛凝视着盒子 11，<br/>不合格的计划常常发现看不见的避风港。</p>
<p class="translated">用户 <br/>等等，别再当海盗了，帮我交税吧！</p>
<p class="translated">唉，我必须保持我海盗的伪装，但我不会抛弃你，也不会让你变得不明智。W-2 的羊皮纸充满了复杂的密码，别担心，我会试着减轻你的负担。</p></blockquote>
<p class="translated">还不错，尽管计价器很不稳定。</p>
<p class="translated">GPT-4 和它的前辈之间有更多的不同，大多数比这些更微妙或更技术性。毫无疑问，随着时间的推移和用户对最新语言模型的测试，我们会学到更多。</p>
<p class="translated">想亲自测试 GPT 4 号吗？它将进入 OpenAI 的付费服务 ChatGPT Plus，很快将通过 API 提供给开发者，很可能很快会有免费演示。</p>



		

			
	
		

			<amp-pixel src="https://web.archive.org/web/20230406180850im_/https://ampmetrics.techcrunch.com/pixel.gif" placeholder="" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>
		<amp-analytics data-credentials="include" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed">
		
	</amp-analytics>
	<amp-pixel src="https://web.archive.org/web/20230406180850im_/https://pixel.wp.com/g.gif?v=ext&amp;blog=136296444&amp;post=2500044&amp;tz=-7&amp;srv=techcrunch.com&amp;host=techcrunch.com&amp;rand=RANDOM&amp;ref=DOCUMENT_REFERRER" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_googleanalytics" type="googleanalytics" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_comscore" type="comscore" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_parsely" type="parsely" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>	</div>

</div>    
</body>
</html>