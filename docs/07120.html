<html>
<head>
<title>Google expands Vertex, its managed AI service, with new features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌用新功能扩展了其托管人工智能服务 Vertex</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2022/06/09/google-expands-vertex-its-managed-ai-service-with-new-features/">https://web.archive.org/web/https://techcrunch.com/2022/06/09/google-expands-vertex-its-managed-ai-service-with-new-features/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">大约一年前，谷歌宣布推出 Vertex AI，这是一个托管的人工智能平台，旨在帮助公司加快人工智能模型的部署。为了纪念这项服务的周年纪念日和谷歌应用人工智能峰会的启动，谷歌今天早上宣布了 Vertex 的新功能，包括一个用于人工智能系统训练和“基于实例的”解释的专用服务器。</p>
<p class="translated">谷歌云集团产品经理亨利·塔彭(Henry Tappen)通过电子邮件告诉 TechCrunch 说:“一年前，我们推出了 Vertex AI，目标是实现新一代人工智能，让数据科学家和工程师能够进行令人满意的创造性工作。“我们今天发布的新 Vertex AI 功能将继续加速机器学习模型在组织中的部署，并使人工智能民主化，以便更多人可以在生产中部署模型，持续监控和推动人工智能的业务影响。”</p>
<p class="translated">正如谷歌历史上所说，Vertex 的优势在于它将谷歌人工智能云服务整合在一个统一的 UI 和 API 下。谷歌声称，包括福特、希捷、Wayfair、Cashapp、Cruise 和 Lowe's 在内的客户使用该服务在单一环境中构建、训练和部署机器学习模型——将模型从实验阶段转移到生产阶段。</p>
<p class="translated">Vertex 与亚马逊网络服务和 Azure 等云提供商的托管人工智能平台竞争。从技术上讲，它属于被称为 MLOps 的平台类别，这是一套商业运行人工智能的最佳实践。德勤<a href="https://web.archive.org/web/20230316224002/https://research.aimultiple.com/mlops-best-practices/#:~:text=Due%20to%20its%20potential%20benefits,MLOps%20market%20size%20since%202019.">预测</a>2025 年，MLOps 市场将价值 40 亿美元，自 2019 年以来增长近 12 倍。</p>
<p class="translated"><a href="https://web.archive.org/web/20230316224002/https://www.gartner.com/en/newsroom/press-releases/2020-11-17-gartner-forecasts-worldwide-public-cloud-end-user-spending-to-grow-18-percent-in-2021"> Gartner 预测</a>像 Vertex 这样的托管服务的出现将导致云市场在 2021 年增长 18.4%，预计云将占全球 IT 总支出的 14.2%。“随着企业增加对移动性、协作和其他远程工作技术和基础设施的投资，公共云的增长将持续到 2024 年，”Gartner 在 2020 年 11 月的一份研究中写道。</p>
<h2 class="translated">新功能</h2>
<p class="translated">Vertex 的新功能之一是 AI Training Reduction Server，谷歌称这项技术优化了 Nvidia GPUs 上多系统分布式训练的带宽和延迟。在机器学习中，“分布式训练”是指将训练一个系统的工作分散到多台机器、GPU、CPU 或定制芯片上，减少完成训练所需的时间和资源。</p>
<p class="translated">“这大大减少了大型语言工作负载所需的培训时间，如<a href="https://web.archive.org/web/20230316224002/https://techcrunch.com/2019/10/25/google-brings-in-bert-to-improve-its-search-results/"> BERT </a>，并进一步实现了不同方法之间的成本平衡，”谷歌云人工智能副总裁兼总经理安德鲁·摩尔(Andrew Moore)今天在谷歌云博客上发表的一篇文章中说。在许多任务关键型业务场景中，缩短的训练周期允许数据科学家在部署窗口的限制内训练具有更高预测性能的模型</p><p class="piano-inline-promo"/>
<p class="translated">在 preview 中，Vertex 现在还具有表格工作流功能，旨在为模型创建过程带来更大的可定制性。正如摩尔解释的那样，表格工作流允许用户选择他们希望谷歌的“AutoML”技术处理工作流的哪些部分，而不是他们希望自己设计的部分。AutoML 或自动化机器学习(automated machine learning)并不是 Google Cloud 或 Vertex 所独有的，它包含了任何自动化人工智能开发方面的技术，可以触及从原始数据集开始到构建可供部署的机器学习模型的开发阶段。AutoML 可以节省时间，但并不总是比得上人工触摸——尤其是在需要精确的地方。</p>
<p class="translated">“表格工作流的元素也可以集成到你现有的顶点人工智能管道中，”摩尔说。“我们增加了新的管理算法，包括像 TabNet 这样的高级研究模型、用于特征选择的新算法、模型提取等等。”</p>
<p class="translated">与开发管道密切相关的是，Vertex 也获得了与无服务器 Spark 的集成(预览版)，这是由 Apache 维护的用于数据处理的开源分析引擎的<a href="https://web.archive.org/web/20230316224002/https://techcrunch.com/tag/serverless/">无服务器</a>版本。现在，Vertex 用户可以启动一个无服务器的 Spark 会话来交互式地开发代码。</p>
<p class="translated">在其他地方，客户可以分析 Neo4j 平台上的数据特征，然后通过与 Neo4j 的新合作伙伴关系使用 Vertex 部署模型。由于谷歌和 Labelbox 的合作，现在可以更容易地从 Vertex 仪表板访问 Labelbox 的图像、文本、音频和视频数据标签服务。标签是大多数 AI 模型学习预测所必需的；模型训练以识别标签(也称为注释)和示例数据(例如，标题“青蛙”和青蛙的照片)之间的关系。</p>
<p class="translated">在数据被错误标注的情况下，摩尔提供了基于实例的解释作为解决方案。预览版中提供的新折点功能利用“基于示例”的解释来帮助诊断和处理数据问题。当然，没有一种可解释的人工智能技术能捕捉到每一个错误；计算语言学家流浪者高塔姆警告不要过度信任用于解释人工智能的工具和技术。</p>
<p class="translated">“谷歌有一些关于局限性的文档和一份关于可解释人工智能的更详细的白皮书，但这些都没有在任何地方提到(今天的 Vertex 人工智能公告)，”他们通过电子邮件告诉 TechCrunch。“公告强调‘技能熟练程度不应成为参与的门槛标准’，它们提供的新功能可以‘为非软件专家扩展人工智能’。”我担心的是，非专家对人工智能和人工智能可解释性的信心超过了他们应有的水平，现在各种谷歌客户可以更快地建立和部署模型，而不会停下来问一问这是不是一个首先需要机器学习解决方案的问题，并在不知道他们特定情况下的限制的完整程度的情况下，称他们的模型是可解释的(因此是可信的和好的)。"</p>
<p class="translated">不过，Moore 建议，基于实例的解释在与其他模型审计实践结合使用时，可能是一个有用的工具。</p>
<p class="translated">“数据科学家不应该成为基础设施工程师或运营工程师，以在不断变化的环境中保持模型准确、可解释、可扩展、抗灾难和安全，”Moore 补充道。“我们的客户需要工具来轻松管理和维护机器学习模型。”</p>
			</div>

			</div>    
</body>
</html>