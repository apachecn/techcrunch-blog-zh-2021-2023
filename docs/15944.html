<html>
<head>
<title>OpenAI releases GPT-4, a multimodal AI that it claims is state-of-the-art | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenAI 发布了 GPT-4，一个据称是最先进的多模态人工智能</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/amp/">https://web.archive.org/web/https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/amp/</a></blockquote><div><div class="content">

			
	
		
		

		
<p class="amp-featured-image translated"><amp-img src="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?w=799" class="attachment-post-thumbnail size-post-thumbnail wp-post-image amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="Sam Altman" srcset="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg 799w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=150,100 150w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=300,200 300w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=768,512 768w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=680,454 680w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=50,33 50w" layout="intrinsic" i-amphtml-layout="intrinsic"> <i-amphtml-sizer class="i-amphtml-sizer"> <img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/> </i-amphtml-sizer> <noscript> <img src="../Images/ab1fa2e4c92351146b0f9b9f9a8e20a0.png" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" alt="Sam Altman" decoding="async" loading="lazy" srcset="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg 799w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=150,100 150w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=300,200 300w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=768,512 768w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=680,454 680w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?resize=50,33 50w" sizes="(max-width: 799px) 100vw, 799px" data-original-src="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/01/52625345016_2165b2c4fe_c.jpg?w=799"/> </noscript> </amp-img></p><p class="translated"><strong>图片来源:</strong> <a href="https://web.archive.org/web/20230402181408/http://www.danipadgett.com/" target="_blank">达尼·帕吉特·沃森</a> / StrictlyVC</p><p class="translated">OpenAI 已经<a href="https://web.archive.org/web/20230402181408/https://openai.com/research/gpt-4" target="_blank" rel="noopener">发布了</a>一个强大的新的图像和文本理解人工智能模型，GPT-4，该公司称之为“其扩大深度学习努力的最新里程碑”</p>
<p class="translated">GPT-4 今天通过<a href="https://web.archive.org/web/20230402181408/https://techcrunch.com/2023/02/01/openai-launches-chatgpt-plus-starting-at-20-per-month/"> ChatGPT Plus </a>向 OpenAI 的付费用户开放(有使用上限)，开发者可以在<a href="https://web.archive.org/web/20230402181408/https://openai.com/waitlist/gpt-4-api" target="_blank" rel="noopener">的等待名单</a>上注册以访问该 API。</p>
<p class="translated">定价为每 1000 个“提示”令牌(约 750 个单词)0.03 美元，每 1000 个“完成”令牌(同样约 750 个单词)0.06 美元。令牌表示原始文本；例如，单词“fantastic”将被拆分为标记“fan”、“tas”和“tic”提示令牌是输入到 GPT-4 的单词的一部分，而完成令牌是由 GPT-4 生成的内容<em>。</em></p>
<p class="translated">事实证明，GPT 4 号一直藏在众目睽睽之下。微软<a href="https://web.archive.org/web/20230402181408/https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4" target="_blank" rel="noopener">今天证实</a>与 OpenAI 联合开发的聊天机器人技术<a href="https://web.archive.org/web/20230402181408/https://techcrunch.com/2023/02/08/hands-on-with-the-new-bing/"> Bing Chat </a>正在 GPT-4 上运行。</p>
<p class="translated">其他早期采用者包括 Stripe，这是<a href="https://web.archive.org/web/20230402181408/https://openai.com/customer-stories/stripe" target="_blank" rel="noopener">使用</a> GPT-4 扫描商业网站并向客户支持人员提供摘要。Duolingo <a href="https://web.archive.org/web/20230402181408/https://blog.duolingo.com/duolingo-max/" target="_blank" rel="noopener">将</a> GPT-4 打造成了一个新的语言学习订阅层。摩根士丹利正在创建一个 GPT-4 驱动的系统，该系统将从公司文件中检索信息，并提供给金融分析师。可汗学院正在利用 GPT-4 建造某种自动导师。</p>

<p class="translated">GPT-4 可以生成文本并接受图像和文本输入——相对于其前任 GPT-3.5(仅接受文本)有所改进——并在各种专业和学术基准上表现出“人类水平”。例如，GPT-4 通过了一次模拟律师考试，分数约为前 10%的考生；相比之下，GPT-3.5 的分数在倒数 10%左右。</p>
<p class="translated">据该公司称，OpenAI 花了六个月的时间，利用内部对抗性测试项目和 ChatGPT 的经验教训，“反复调整”GPT-4，在真实性、可操纵性和拒绝走出护栏方面取得了“有史以来最好的结果”。像以前的 GPT 模型一样，GPT-4 使用公开可用的数据进行训练，包括来自公共网页的数据，以及 OpenAI 许可的数据。</p>
<p class="translated">OpenAI 与微软合作，在 Azure cloud 中从头开发了一台“超级计算机”，用于训练 GPT-4。</p>
<p class="translated">“在一次随意的交谈中，GPT-3.5 和 GPT-4 之间的区别可能是微妙的，”OpenAI 在宣布 GPT-4 的博客帖子中写道。“当任务的复杂性达到足够的阈值时，差异就会显现出来——GPT-4 比 GPT-3.5 更可靠，更有创造力，能够处理更多细微的指令。”</p>
<p class="translated">毫无疑问，GPT 4 号更有趣的方面之一是它理解图像和文本的能力。GPT-4 可以为相对复杂的图像添加字幕，甚至解释这些图像，例如从插入电源的 iPhone 图片中识别闪电线适配器。</p>
<p class="translated">图像理解功能目前还不是对所有 OpenAI 客户开放——open ai 首先与一个合作伙伴“做我的眼睛”进行测试。由 GPT-4 驱动，成为我的眼睛的新虚拟志愿者功能可以回答关于发送给它的图像的问题。该公司在一篇博客文章中解释了它是如何运作的:</p>
<p class="translated">“例如，如果用户发送一张他们冰箱内部的图片，虚拟志愿者不仅能够正确识别里面有什么，还能推断和分析用这些成分可以准备什么。该工具还可以为这些成分提供许多食谱，并发送如何制作它们的分步指南。”</p>
<p class="translated">GPT-4 的一个更有意义的改进可能是前面提到的可操纵性工具。在 GPT-4 中，OpenAI 引入了一个新的 API 功能，“系统”消息，允许开发者通过描述特定的方向来指定风格和任务。系统消息，也将在未来出现在<a href="https://web.archive.org/web/20230402181408/https://techcrunch.com/2023/03/23/chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot/"> ChatGPT 上，本质上是为人工智能的下一次交互设定基调——并建立边界——的指令。</a></p>
<p class="translated">例如，一条系统消息可能是这样的:“你是一位总是以苏格拉底式的方式回答问题的教师。你<em>从不</em>给学生答案，但总是试图问恰到好处的问题，以帮助他们学会独立思考。你应该始终根据学生的兴趣和知识来调整你的问题，将问题分解成更简单的部分，直到达到适合他们的水平。”</p>
<p class="translated">然而，即使有系统信息和其他升级，OpenAI 也承认 GPT 4 号远非完美。它仍然“幻觉”事实，并犯推理错误，有时非常自信。在 OpenAI 引用的一个例子中，GPT-4 将猫王描述为“一个演员的儿子”——这是一个明显的失误。</p>
<p class="translated">“GPT-4 通常缺乏对绝大多数数据切断(2021 年 9 月)后发生的事件的了解，也没有从经验中吸取教训，”OpenAI 写道。“它有时会犯一些简单的推理错误，这些错误似乎与它在如此多领域的能力不相称，或者过于轻信用户的明显错误陈述。有时，它可能会像人类一样在困难的问题上失败，例如在其生成的代码中引入安全漏洞。”</p>
<p class="translated">不过，OpenAI 确实指出，它在某些特定领域做出了改进；例如，GPT-4 不太可能拒绝如何合成危险化学品的请求。该公司表示，与 GPT-3.5 相比，GPT-4 整体上对“禁止”内容的请求做出回应的可能性降低了 82%，而根据 OpenAI 的政策，对敏感请求——例如医疗建议和任何与自残有关的请求——做出回应的可能性增加了 29%。</p>
<p/><div id="attachment_2500017" class="wp-caption aligncenter amp-wp-e2bc858" data-amp-original-style="width: 1034px"><amp-img aria-describedby="caption-attachment-2500017" class="size-full wp-image-2500017 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png" alt="OpenAI GPT-4" srcset="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png 2120w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=150,122 150w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=300,244 300w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=768,625 768w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=680,553 680w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=1536,1249 1536w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=2048,1665 2048w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=1200,976 1200w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=50,41 50w" layout="intrinsic" i-amphtml-layout="intrinsic"><i-amphtml-sizer class="i-amphtml-sizer"><img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src=""/></i-amphtml-sizer><noscript><img aria-describedby="caption-attachment-2500017" decoding="async" loading="lazy" class="size-full wp-image-2500017" src="../Images/71c1d4c42b0b4e4444c242d40887b100.png" alt="OpenAI GPT-4" srcset="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png 2120w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=150,122 150w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=300,244 300w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=768,625 768w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=680,553 680w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=1536,1249 1536w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=2048,1665 2048w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=1200,976 1200w, https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png?resize=50,41 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230402181408im_/https://techcrunch.com/wp-content/uploads/2023/03/gpt-4.png"/></noscript></amp-img><p id="caption-attachment-2500017" class="wp-caption-text translated"><strong>图片来源:</strong> OpenAI</p></div>
<p class="translated">很明显，GPT 4 号有很多东西需要解开。但是 OpenAI，就其本身而言，正在全速前进——显然对它所做的改进很有信心。</p>
<p class="translated">“我们期待 GPT-4 成为一个有价值的工具，通过为许多应用提供动力来改善人们的生活，”OpenAI 写道。“还有很多工作要做，我们期待着通过社区的集体努力来完善这一模式，在此基础上构建、探索和贡献这一模式。”</p>


		

			
	
		

			<amp-pixel src="https://web.archive.org/web/20230402181408im_/https://ampmetrics.techcrunch.com/pixel.gif" placeholder="" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>
		<amp-analytics data-credentials="include" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed">
		
	</amp-analytics>
	<amp-pixel src="https://web.archive.org/web/20230402181408im_/https://pixel.wp.com/g.gif?v=ext&amp;blog=136296444&amp;post=2499800&amp;tz=-7&amp;srv=techcrunch.com&amp;host=techcrunch.com&amp;rand=RANDOM&amp;ref=DOCUMENT_REFERRER" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_googleanalytics" type="googleanalytics" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_comscore" type="comscore" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/><amp-analytics id="tc_parsely" type="parsely" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" i-amphtml-layout="fixed"/>	</div>

</div>    
</body>
</html>