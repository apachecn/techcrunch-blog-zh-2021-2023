<html>
<head>
<title>Google's AI-powered 'multisearch,' which combines text and images in a single query, goes global | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌人工智能驱动的“多重搜索”将文本和图像结合在一个单一的查询中，走向全球</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2023/02/08/googles-a-i-powered-multisearch-which-combines-text-and-images-in-a-single-query-goes-global/?tpcc=tcplustwitter">https://web.archive.org/web/https://techcrunch.com/2023/02/08/googles-a-i-powered-multisearch-which-combines-text-and-images-in-a-single-query-goes-global/?tpcc=tcplustwitter</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">在其他以人工智能为重点的公告中，谷歌今天分享了其更新的“<a href="https://web.archive.org/web/20230403231230/https://blog.google/products/search/multisearch/" target="_blank" rel="noopener">多搜索</a>功能，现在全球用户可以在移动设备上使用谷歌镜头，只要谷歌镜头已经可用。允许用户同时使用文本和图像进行搜索的搜索功能<a href="https://web.archive.org/web/20230403231230/https://techcrunch.com/2022/04/07/googles-multisearch-search-using-text-images/">于去年 4 月</a>首次推出，作为更新谷歌搜索的一种方式，以更好地利用智能手机的功能。在此基础上的另一个版本“<a href="https://web.archive.org/web/20230403231230/https://blog.google/products/search/searching-for-holiday-meals/" target="_blank" rel="noopener"> multisearch near me </a>”针对本地企业的搜索，也将在未来几个月内在全球范围内推出，同样推出的还有面向网络的 multisearch 和面向安卓用户的新镜头功能。</p>
<p class="translated">正如谷歌之前<a href="https://web.archive.org/web/20230403231230/https://techcrunch.com/2021/09/29/google-introduces-a-new-way-to-search-that-combines-images-and-text-into-one-query/">解释的</a>，multisearch 由一种名为多任务统一模型(或<a href="https://web.archive.org/web/20230403231230/https://www.blog.google/products/search/introducing-MUM/" target="_blank" rel="noopener"> MUM </a>的人工智能技术提供支持，它可以理解各种格式的信息，包括文本、照片和视频，然后得出主题、概念和想法之间的见解和联系。谷歌让 MUM 在其谷歌镜头视觉搜索功能中工作，允许用户向视觉搜索查询添加文本。</p>
<p class="translated">“通过引入 Lens，我们重新定义了搜索的含义。谷歌负责搜索、助理、地理、广告、商务和支付产品的 SVP Prabhakar Raghavan 在巴黎的新闻发布会上说。</p>
<p class="translated">例如，用户可以在谷歌搜索中找到他们喜欢的衬衫的照片，然后问 Lens 他们在哪里可以找到相同的图案，但在不同类型的服装上，如裙子或袜子。或者，他们可以将手机对准自行车上的一个破损部分，在谷歌搜索中输入类似“如何修理”的查询。这种文字和图像的结合可以帮助谷歌处理和理解搜索查询，这是它以前无法处理的，或者说单独使用文本输入会更加困难。</p>
<p class="translated">这项技术对购物搜索最有帮助，在那里你可以找到你喜欢的衣服，但颜色或款式不同。或者你可以给一件家具拍张照片，比如一套餐具，找到与之相配的物品，比如一张咖啡桌。谷歌<a href="https://web.archive.org/web/20230403231230/https://techcrunch.com/2022/04/07/googles-multisearch-search-using-text-images/">称</a>在多重搜索中，用户还可以通过品牌、颜色和视觉属性来缩小和细化搜索结果。</p>
<p class="translated">这项功能于去年 10 月提供给美国用户，然后<a href="https://web.archive.org/web/20230403231230/https://techcrunch.com/2022/12/19/google-brings-multi-search-and-in-video-search-features-to-india/">于 12 月</a>扩展到印度。截至今天，谷歌表示，multisearch 对全球所有移动用户开放，支持所有语言和 Lens 可用的国家。</p>
<p class="translated">谷歌今天表示,“我附近的多搜索”也将很快扩展。</p><p class="piano-inline-promo"/>
<p class="translated">谷歌去年 5 月宣布，它可以将多搜索查询定向到当地企业(又名“我附近的多搜索”)，这将返回用户正在寻找的与当地零售商或其他企业的库存相匹配的商品的搜索结果。例如，在自行车零件损坏的情况下，您可以将文本“在我附近”添加到带有照片的搜索查询中，以查找当地自行车商店或五金店，它们有您需要的替换零件。</p>
<p class="translated">谷歌表示，这一功能将在未来几个月内在 Lens 可用的所有语言和国家可用。未来几个月，它还将扩展到移动设备之外，支持网络多搜索。</p>
<p class="translated">在新的搜索产品方面，搜索巨头取笑了即将推出的谷歌镜头功能，指出 Android 用户很快就可以在手机上搜索他们在应用程序和网站上看到的照片和视频，同时仍然保留在应用程序或网站上。谷歌称之为“搜索你的屏幕”，并表示无论哪里提供 Lens，它都将可用。</p>
<p class="translated">谷歌也分享了谷歌眼镜的一个新里程碑，指出人们现在每月使用这项技术超过 100 亿次。</p>
			</div>

			</div>    
</body>
</html>